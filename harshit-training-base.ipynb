{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38eb2c5a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-29T07:07:25.734985Z",
     "iopub.status.busy": "2022-05-29T07:07:25.734375Z",
     "iopub.status.idle": "2022-05-29T07:07:25.752516Z",
     "shell.execute_reply": "2022-05-29T07:07:25.751718Z"
    },
    "papermill": {
     "duration": 0.027719,
     "end_time": "2022-05-29T07:07:25.755912",
     "exception": false,
     "start_time": "2022-05-29T07:07:25.728193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/us-patent-phrase-to-phrase-matching/sample_submission.csv\n",
      "/kaggle/input/us-patent-phrase-to-phrase-matching/train.csv\n",
      "/kaggle/input/us-patent-phrase-to-phrase-matching/test.csv\n",
      "/kaggle/input/cpc-codes/titles.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d72557f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T07:07:25.765694Z",
     "iopub.status.busy": "2022-05-29T07:07:25.765437Z",
     "iopub.status.idle": "2022-05-29T07:07:31.942729Z",
     "shell.execute_reply": "2022-05-29T07:07:31.941903Z"
    },
    "papermill": {
     "duration": 6.1843,
     "end_time": "2022-05-29T07:07:31.945078",
     "exception": false,
     "start_time": "2022-05-29T07:07:25.760778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version: 4.18.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../input/transformers/src\")\n",
    "import transformers\n",
    "\n",
    "print(f\"Transformers version: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcb402fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T07:07:31.956530Z",
     "iopub.status.busy": "2022-05-29T07:07:31.954855Z",
     "iopub.status.idle": "2022-05-29T07:07:42.340669Z",
     "shell.execute_reply": "2022-05-29T07:07:42.339406Z"
    },
    "papermill": {
     "duration": 10.392462,
     "end_time": "2022-05-29T07:07:42.342389",
     "exception": false,
     "start_time": "2022-05-29T07:07:31.949927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.18.0)\r\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.53)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.6.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.5.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.11.4)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.27.1)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.0.12)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.9)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.5.18.1)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.1.0)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.4)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dc6a5ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T07:07:42.352767Z",
     "iopub.status.busy": "2022-05-29T07:07:42.352452Z",
     "iopub.status.idle": "2022-05-29T07:07:43.735048Z",
     "shell.execute_reply": "2022-05-29T07:07:43.734255Z"
    },
    "papermill": {
     "duration": 1.390687,
     "end_time": "2022-05-29T07:07:43.737793",
     "exception": false,
     "start_time": "2022-05-29T07:07:42.347106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import shutil\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import datasets, transformers\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f57ab7",
   "metadata": {
    "papermill": {
     "duration": 0.006853,
     "end_time": "2022-05-29T07:07:43.752167",
     "exception": false,
     "start_time": "2022-05-29T07:07:43.745314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ac55745",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T07:07:43.767906Z",
     "iopub.status.busy": "2022-05-29T07:07:43.766997Z",
     "iopub.status.idle": "2022-05-29T07:07:43.772327Z",
     "shell.execute_reply": "2022-05-29T07:07:43.771695Z"
    },
    "papermill": {
     "duration": 0.016631,
     "end_time": "2022-05-29T07:07:43.775750",
     "exception": false,
     "start_time": "2022-05-29T07:07:43.759119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    input_path = '../input/us-patent-phrase-to-phrase-matching/'\n",
    "    model_path = 'microsoft/deberta-v3-base'\n",
    "    \n",
    "    learning_rate = 2e-5\n",
    "    weight_decay = 0.01\n",
    "    num_fold = 5\n",
    "    epochs = 5\n",
    "    batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8ea5b89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T07:07:43.790878Z",
     "iopub.status.busy": "2022-05-29T07:07:43.790548Z",
     "iopub.status.idle": "2022-05-29T07:07:44.667318Z",
     "shell.execute_reply": "2022-05-29T07:07:44.666516Z"
    },
    "papermill": {
     "duration": 0.886524,
     "end_time": "2022-05-29T07:07:44.669398",
     "exception": false,
     "start_time": "2022-05-29T07:07:43.782874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f\"{CFG.input_path}train.csv\")\n",
    "titles = pd.read_csv('../input/cpc-codes/titles.csv')\n",
    "train_df = train_df.merge(titles, left_on='context', right_on='code')\n",
    "\n",
    "# https://www.kaggle.com/code/abhishek/phrase-matching-folds\n",
    "def create_folds(data, num_splits):\n",
    "    # we create a new column called kfold and fill it with -1\n",
    "    data[\"fold\"] = -1\n",
    "    \n",
    "    # the next step is to randomize the rows of the data\n",
    "    # data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # calculate number of bins by Sturge's rule\n",
    "    # I take the floor of the value, you can also\n",
    "    # just round it\n",
    "    # num_bins = int(np.floor(1 + np.log2(len(data))))\n",
    "    \n",
    "    # bin targets\n",
    "    data.loc[:, \"bins\"] = pd.cut(\n",
    "        data[\"score\"], bins=5, labels=False\n",
    "    )\n",
    "    \n",
    "    # initiate the kfold class from model_selection module\n",
    "    kf = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    # fill the new kfold column\n",
    "    # note that, instead of targets, we use bins!\n",
    "    for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n",
    "        data.loc[v_, 'fold'] = f\n",
    "    \n",
    "    # drop the bins column\n",
    "    data = data.drop(\"bins\", axis=1)\n",
    "\n",
    "    # return dataframe with folds\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33a5aca1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T07:07:44.680146Z",
     "iopub.status.busy": "2022-05-29T07:07:44.679599Z",
     "iopub.status.idle": "2022-05-29T07:07:44.728061Z",
     "shell.execute_reply": "2022-05-29T07:07:44.727324Z"
    },
    "papermill": {
     "duration": 0.055603,
     "end_time": "2022-05-29T07:07:44.729802",
     "exception": false,
     "start_time": "2022-05-29T07:07:44.674199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['input'] = train_df['title']+' '+train_df['anchor']\n",
    "train_df = create_folds(train_df, CFG.num_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c745525c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T07:07:44.739643Z",
     "iopub.status.busy": "2022-05-29T07:07:44.739338Z",
     "iopub.status.idle": "2022-05-29T07:07:49.819466Z",
     "shell.execute_reply": "2022-05-29T07:07:49.818538Z"
    },
    "papermill": {
     "duration": 5.087147,
     "end_time": "2022-05-29T07:07:49.821365",
     "exception": false,
     "start_time": "2022-05-29T07:07:44.734218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91d04b0a0f0145e68c5d7efe31cea3cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be1e6a3562f84ef6a79df70403d13099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5627269bbd64da998c974ff2b90702d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.35M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(CFG.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cf55eb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T07:07:49.832436Z",
     "iopub.status.busy": "2022-05-29T07:07:49.832158Z",
     "iopub.status.idle": "2022-05-29T07:07:49.838573Z",
     "shell.execute_reply": "2022-05-29T07:07:49.837698Z"
    },
    "papermill": {
     "duration": 0.013838,
     "end_time": "2022-05-29T07:07:49.840368",
     "exception": false,
     "start_time": "2022-05-29T07:07:49.826530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.inputs = df['input'].values.astype(str)\n",
    "        self.targets = df['target'].values.astype(str)\n",
    "        self.label = df['score'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = self.inputs[item]\n",
    "        targets = self.targets[item]\n",
    "        label = self.label[item]\n",
    "        \n",
    "        return {\n",
    "        **tokenizer( inputs, targets ),\n",
    "        'label':label.astype(np.float32)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbf86349",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T07:07:49.850807Z",
     "iopub.status.busy": "2022-05-29T07:07:49.850531Z",
     "iopub.status.idle": "2022-05-29T07:07:49.855615Z",
     "shell.execute_reply": "2022-05-29T07:07:49.854936Z"
    },
    "papermill": {
     "duration": 0.012267,
     "end_time": "2022-05-29T07:07:49.857404",
     "exception": false,
     "start_time": "2022-05-29T07:07:49.845137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = predictions.reshape(len(predictions))\n",
    "    return {\n",
    "        'pearson': np.corrcoef(predictions, labels)[0][1]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cafbe58f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T07:07:49.868007Z",
     "iopub.status.busy": "2022-05-29T07:07:49.867492Z",
     "iopub.status.idle": "2022-05-29T09:18:44.621729Z",
     "shell.execute_reply": "2022-05-29T09:18:44.620767Z"
    },
    "papermill": {
     "duration": 7854.762271,
     "end_time": "2022-05-29T09:18:44.624435",
     "exception": false,
     "start_time": "2022-05-29T07:07:49.862164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "729798244d304a11b619b8467bc451ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/354M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.weight', 'pooler.dense.weight', 'classifier.bias', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 29178\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9120' max='9120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9120/9120 25:58, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.025272</td>\n",
       "      <td>0.822891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>0.020138</td>\n",
       "      <td>0.842127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.014400</td>\n",
       "      <td>0.019757</td>\n",
       "      <td>0.847506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.021683</td>\n",
       "      <td>0.852718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>0.020005</td>\n",
       "      <td>0.856185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 7295\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/uspppm/checkpoint-1824\n",
      "Configuration saved in /tmp/uspppm/checkpoint-1824/config.json\n",
      "Model weights saved in /tmp/uspppm/checkpoint-1824/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/uspppm/checkpoint-1824/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/uspppm/checkpoint-1824/special_tokens_map.json\n",
      "added tokens file saved in /tmp/uspppm/checkpoint-1824/added_tokens.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7295\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/uspppm/checkpoint-3648\n",
      "Configuration saved in /tmp/uspppm/checkpoint-3648/config.json\n",
      "Model weights saved in /tmp/uspppm/checkpoint-3648/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/uspppm/checkpoint-3648/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/uspppm/checkpoint-3648/special_tokens_map.json\n",
      "added tokens file saved in /tmp/uspppm/checkpoint-3648/added_tokens.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7295\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/uspppm/checkpoint-5472\n",
      "Configuration saved in /tmp/uspppm/checkpoint-5472/config.json\n",
      "Model weights saved in /tmp/uspppm/checkpoint-5472/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/uspppm/checkpoint-5472/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/uspppm/checkpoint-5472/special_tokens_map.json\n",
      "added tokens file saved in /tmp/uspppm/checkpoint-5472/added_tokens.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7295\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/uspppm/checkpoint-7296\n",
      "Configuration saved in /tmp/uspppm/checkpoint-7296/config.json\n",
      "Model weights saved in /tmp/uspppm/checkpoint-7296/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/uspppm/checkpoint-7296/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/uspppm/checkpoint-7296/special_tokens_map.json\n",
      "added tokens file saved in /tmp/uspppm/checkpoint-7296/added_tokens.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7295\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/uspppm/checkpoint-9120\n",
      "Configuration saved in /tmp/uspppm/checkpoint-9120/config.json\n",
      "Model weights saved in /tmp/uspppm/checkpoint-9120/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/uspppm/checkpoint-9120/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/uspppm/checkpoint-9120/special_tokens_map.json\n",
      "added tokens file saved in /tmp/uspppm/checkpoint-9120/added_tokens.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp/uspppm/checkpoint-9120 (score: 0.8561852821918592).\n",
      "Saving model checkpoint to uspppm_0\n",
      "Configuration saved in uspppm_0/config.json\n",
      "Model weights saved in uspppm_0/pytorch_model.bin\n",
      "tokenizer config file saved in uspppm_0/tokenizer_config.json\n",
      "Special tokens file saved in uspppm_0/special_tokens_map.json\n",
      "added tokens file saved in uspppm_0/added_tokens.json\n",
      "***** Running Prediction *****\n",
      "  Num examples = 7295\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='456' max='456' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [456/456 00:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/322954555e18d37b9f98196875590497a8b33244551ec195e00fcdb831878224.f80cec19a933132f8b9636fbb3b736b2f4b9c8deaa45dfe4dd6e40a4d9970f44\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.weight', 'pooler.dense.weight', 'classifier.bias', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 29178\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9120' max='9120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9120/9120 25:45, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.022401</td>\n",
       "      <td>0.825186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.024039</td>\n",
       "      <td>0.839431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.022751</td>\n",
       "      <td>0.845142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.023379</td>\n",
       "      <td>0.847263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>0.021488</td>\n",
       "      <td>0.849624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 7295\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/uspppm/checkpoint-1824\n",
      "Configuration saved in /tmp/uspppm/checkpoint-1824/config.json\n",
      "Model weights saved in /tmp/uspppm/checkpoint-1824/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/uspppm/checkpoint-1824/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/uspppm/checkpoint-1824/special_tokens_map.json\n",
      "added tokens file saved in /tmp/uspppm/checkpoint-1824/added_tokens.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7295\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/uspppm/checkpoint-3648\n",
      "Configuration saved in /tmp/uspppm/checkpoint-3648/config.json\n",
      "Model weights saved in /tmp/uspppm/checkpoint-3648/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/uspppm/checkpoint-3648/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/uspppm/checkpoint-3648/special_tokens_map.json\n",
      "added tokens file saved in /tmp/uspppm/checkpoint-3648/added_tokens.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7295\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/uspppm/checkpoint-5472\n",
      "Configuration saved in /tmp/uspppm/checkpoint-5472/config.json\n",
      "Model weights saved in /tmp/uspppm/checkpoint-5472/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/uspppm/checkpoint-5472/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/uspppm/checkpoint-5472/special_tokens_map.json\n",
      "added tokens file saved in /tmp/uspppm/checkpoint-5472/added_tokens.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7295\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/uspppm/checkpoint-7296\n",
      "Configuration saved in /tmp/uspppm/checkpoint-7296/config.json\n",
      "Model weights saved in /tmp/uspppm/checkpoint-7296/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/uspppm/checkpoint-7296/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/uspppm/checkpoint-7296/special_tokens_map.json\n",
      "added tokens file saved in /tmp/uspppm/checkpoint-7296/added_tokens.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7295\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/uspppm/checkpoint-9120\n",
      "Configuration saved in /tmp/uspppm/checkpoint-9120/config.json\n",
      "Model weights saved in /tmp/uspppm/checkpoint-9120/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/uspppm/checkpoint-9120/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/uspppm/checkpoint-9120/special_tokens_map.json\n",
      "added tokens file saved in /tmp/uspppm/checkpoint-9120/added_tokens.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp/uspppm/checkpoint-9120 (score: 0.8496240631356783).\n",
      "Saving model checkpoint to uspppm_1\n",
      "Configuration saved in uspppm_1/config.json\n",
      "Model weights saved in uspppm_1/pytorch_model.bin\n",
      "tokenizer config file saved in uspppm_1/tokenizer_config.json\n",
      "Special tokens file saved in uspppm_1/special_tokens_map.json\n",
      "added tokens file saved in uspppm_1/added_tokens.json\n",
      "***** Running Prediction *****\n",
      "  Num examples = 7295\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='456' max='456' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [456/456 00:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/322954555e18d37b9f98196875590497a8b33244551ec195e00fcdb831878224.f80cec19a933132f8b9636fbb3b736b2f4b9c8deaa45dfe4dd6e40a4d9970f44\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.weight', 'pooler.dense.weight', 'classifier.bias', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 29178\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9120' max='9120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9120/9120 25:42, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.026732</td>\n",
       "      <td>0.822289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.021876</td>\n",
       "      <td>0.845285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.019981</td>\n",
       "      <td>0.851279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>0.019349</td>\n",
       "      <td>0.855336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.019769</td>\n",
       "      <td>0.854760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 7295\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/uspppm/checkpoint-1824\n",
      "Configuration saved in /tmp/uspppm/checkpoint-1824/config.json\n",
      "Model weights saved in /tmp/uspppm/checkpoint-1824/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/uspppm/checkpoint-1824/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/uspppm/checkpoint-1824/special_tokens_map.json\n",
      "added tokens file saved in /tmp/uspppm/checkpoint-1824/added_tokens.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7295\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/uspppm/checkpoint-3648\n",
      "Configuration saved in /tmp/uspppm/checkpoint-3648/config.json\n",
      "Model weights saved in /tmp/uspppm/checkpoint-3648/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/uspppm/checkpoint-3648/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/uspppm/checkpoint-3648/special_tokens_map.json\n",
      "added tokens file saved in /tmp/uspppm/checkpoint-3648/added_tokens.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7295\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/uspppm/checkpoint-5472\n",
      "Configuration saved in /tmp/uspppm/checkpoint-5472/config.json\n",
      "Model weights saved in /tmp/uspppm/checkpoint-5472/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/uspppm/checkpoint-5472/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/uspppm/checkpoint-5472/special_tokens_map.json\n",
      "added tokens file saved in /tmp/uspppm/checkpoint-5472/added_tokens.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7295\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/uspppm/checkpoint-7296\n",
      "Configuration saved in /tmp/uspppm/checkpoint-7296/config.json\n",
      "Model weights saved in /tmp/uspppm/checkpoint-7296/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/uspppm/checkpoint-7296/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/uspppm/checkpoint-7296/special_tokens_map.json\n",
      "added tokens file saved in /tmp/uspppm/checkpoint-7296/added_tokens.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7295\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/uspppm/checkpoint-9120\n",
      "Configuration saved in /tmp/uspppm/checkpoint-9120/config.json\n",
      "Model weights saved in /tmp/uspppm/checkpoint-9120/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/uspppm/checkpoint-9120/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/uspppm/checkpoint-9120/special_tokens_map.json\n",
      "added tokens file saved in /tmp/uspppm/checkpoint-9120/added_tokens.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp/uspppm/checkpoint-7296 (score: 0.8553364370439466).\n",
      "Saving model checkpoint to uspppm_2\n",
      "Configuration saved in uspppm_2/config.json\n",
      "Model weights saved in uspppm_2/pytorch_model.bin\n",
      "tokenizer config file saved in uspppm_2/tokenizer_config.json\n",
      "Special tokens file saved in uspppm_2/special_tokens_map.json\n",
      "added tokens file saved in uspppm_2/added_tokens.json\n",
      "***** Running Prediction *****\n",
      "  Num examples = 7295\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='456' max='456' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [456/456 00:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/322954555e18d37b9f98196875590497a8b33244551ec195e00fcdb831878224.f80cec19a933132f8b9636fbb3b736b2f4b9c8deaa45dfe4dd6e40a4d9970f44\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.weight', 'pooler.dense.weight', 'classifier.bias', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 29179\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9120' max='9120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9120/9120 25:42, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.025523</td>\n",
       "      <td>0.826377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>0.020682</td>\n",
       "      <td>0.842683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>0.022045</td>\n",
       "      <td>0.855853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.018537</td>\n",
       "      <td>0.857531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>0.019367</td>\n",
       "      <td>0.858540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 7294\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/uspppm/checkpoint-1824\n",
      "Configuration saved in /tmp/uspppm/checkpoint-1824/config.json\n",
      "Model weights saved in /tmp/uspppm/checkpoint-1824/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/uspppm/checkpoint-1824/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/uspppm/checkpoint-1824/special_tokens_map.json\n",
      "added tokens file saved in /tmp/uspppm/checkpoint-1824/added_tokens.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7294\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/uspppm/checkpoint-3648\n",
      "Configuration saved in /tmp/uspppm/checkpoint-3648/config.json\n",
      "Model weights saved in /tmp/uspppm/checkpoint-3648/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/uspppm/checkpoint-3648/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/uspppm/checkpoint-3648/special_tokens_map.json\n",
      "added tokens file saved in /tmp/uspppm/checkpoint-3648/added_tokens.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7294\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/uspppm/checkpoint-5472\n",
      "Configuration saved in /tmp/uspppm/checkpoint-5472/config.json\n",
      "Model weights saved in /tmp/uspppm/checkpoint-5472/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/uspppm/checkpoint-5472/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/uspppm/checkpoint-5472/special_tokens_map.json\n",
      "added tokens file saved in /tmp/uspppm/checkpoint-5472/added_tokens.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7294\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/uspppm/checkpoint-7296\n",
      "Configuration saved in /tmp/uspppm/checkpoint-7296/config.json\n",
      "Model weights saved in /tmp/uspppm/checkpoint-7296/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/uspppm/checkpoint-7296/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/uspppm/checkpoint-7296/special_tokens_map.json\n",
      "added tokens file saved in /tmp/uspppm/checkpoint-7296/added_tokens.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7294\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/uspppm/checkpoint-9120\n",
      "Configuration saved in /tmp/uspppm/checkpoint-9120/config.json\n",
      "Model weights saved in /tmp/uspppm/checkpoint-9120/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/uspppm/checkpoint-9120/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/uspppm/checkpoint-9120/special_tokens_map.json\n",
      "added tokens file saved in /tmp/uspppm/checkpoint-9120/added_tokens.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp/uspppm/checkpoint-9120 (score: 0.8585399507877635).\n",
      "Saving model checkpoint to uspppm_3\n",
      "Configuration saved in uspppm_3/config.json\n",
      "Model weights saved in uspppm_3/pytorch_model.bin\n",
      "tokenizer config file saved in uspppm_3/tokenizer_config.json\n",
      "Special tokens file saved in uspppm_3/special_tokens_map.json\n",
      "added tokens file saved in uspppm_3/added_tokens.json\n",
      "***** Running Prediction *****\n",
      "  Num examples = 7294\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='456' max='456' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [456/456 00:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/322954555e18d37b9f98196875590497a8b33244551ec195e00fcdb831878224.f80cec19a933132f8b9636fbb3b736b2f4b9c8deaa45dfe4dd6e40a4d9970f44\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.weight', 'pooler.dense.weight', 'classifier.bias', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 29179\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9120' max='9120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9120/9120 25:42, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>0.026488</td>\n",
       "      <td>0.818809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>0.021986</td>\n",
       "      <td>0.837338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>0.021073</td>\n",
       "      <td>0.846394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>0.020533</td>\n",
       "      <td>0.851212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>0.019474</td>\n",
       "      <td>0.854555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 7294\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/uspppm/checkpoint-1824\n",
      "Configuration saved in /tmp/uspppm/checkpoint-1824/config.json\n",
      "Model weights saved in /tmp/uspppm/checkpoint-1824/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/uspppm/checkpoint-1824/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/uspppm/checkpoint-1824/special_tokens_map.json\n",
      "added tokens file saved in /tmp/uspppm/checkpoint-1824/added_tokens.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7294\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/uspppm/checkpoint-3648\n",
      "Configuration saved in /tmp/uspppm/checkpoint-3648/config.json\n",
      "Model weights saved in /tmp/uspppm/checkpoint-3648/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/uspppm/checkpoint-3648/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/uspppm/checkpoint-3648/special_tokens_map.json\n",
      "added tokens file saved in /tmp/uspppm/checkpoint-3648/added_tokens.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7294\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/uspppm/checkpoint-5472\n",
      "Configuration saved in /tmp/uspppm/checkpoint-5472/config.json\n",
      "Model weights saved in /tmp/uspppm/checkpoint-5472/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/uspppm/checkpoint-5472/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/uspppm/checkpoint-5472/special_tokens_map.json\n",
      "added tokens file saved in /tmp/uspppm/checkpoint-5472/added_tokens.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7294\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/uspppm/checkpoint-7296\n",
      "Configuration saved in /tmp/uspppm/checkpoint-7296/config.json\n",
      "Model weights saved in /tmp/uspppm/checkpoint-7296/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/uspppm/checkpoint-7296/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/uspppm/checkpoint-7296/special_tokens_map.json\n",
      "added tokens file saved in /tmp/uspppm/checkpoint-7296/added_tokens.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7294\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/uspppm/checkpoint-9120\n",
      "Configuration saved in /tmp/uspppm/checkpoint-9120/config.json\n",
      "Model weights saved in /tmp/uspppm/checkpoint-9120/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/uspppm/checkpoint-9120/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/uspppm/checkpoint-9120/special_tokens_map.json\n",
      "added tokens file saved in /tmp/uspppm/checkpoint-9120/added_tokens.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp/uspppm/checkpoint-9120 (score: 0.8545546892002062).\n",
      "Saving model checkpoint to uspppm_4\n",
      "Configuration saved in uspppm_4/config.json\n",
      "Model weights saved in uspppm_4/pytorch_model.bin\n",
      "tokenizer config file saved in uspppm_4/tokenizer_config.json\n",
      "Special tokens file saved in uspppm_4/special_tokens_map.json\n",
      "added tokens file saved in uspppm_4/added_tokens.json\n",
      "***** Running Prediction *****\n",
      "  Num examples = 7294\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='456' max='456' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [456/456 00:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "oof_df = pd.DataFrame()\n",
    "for fold in range(CFG.num_fold):\n",
    "    \n",
    "    tr_data = train_df[train_df['fold']!=fold].reset_index(drop=True)\n",
    "    va_data = train_df[train_df['fold']==fold].reset_index(drop=True)\n",
    "    tr_dataset = TrainDataset(tr_data)\n",
    "    va_dataset = TrainDataset(va_data)\n",
    "    \n",
    "    args = TrainingArguments(\n",
    "        output_dir=f\"/tmp/uspppm\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=CFG.learning_rate,\n",
    "        per_device_train_batch_size=CFG.batch_size,\n",
    "        per_device_eval_batch_size=CFG.batch_size,\n",
    "        num_train_epochs=CFG.epochs,\n",
    "        weight_decay=CFG.weight_decay,\n",
    "        metric_for_best_model=\"pearson\",\n",
    "        load_best_model_at_end=True,\n",
    "    )\n",
    "    \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(CFG.model_path, num_labels=1)\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=tr_dataset,\n",
    "        eval_dataset=va_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    shutil.rmtree(f\"/tmp/uspppm\")\n",
    "    trainer.save_model(f\"uspppm_{fold}\")\n",
    "    \n",
    "    outputs = trainer.predict(va_dataset)\n",
    "    predictions = outputs.predictions.reshape(-1)\n",
    "    va_data['preds'] = predictions\n",
    "    oof_df = pd.concat([oof_df, va_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcca21b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T09:18:45.599373Z",
     "iopub.status.busy": "2022-05-29T09:18:45.598424Z",
     "iopub.status.idle": "2022-05-29T09:18:45.608795Z",
     "shell.execute_reply": "2022-05-29T09:18:45.607972Z"
    },
    "papermill": {
     "duration": 0.936853,
     "end_time": "2022-05-29T09:18:45.610681",
     "exception": false,
     "start_time": "2022-05-29T09:18:44.673828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pearson': 0.8543242077660633}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = oof_df['preds'].values\n",
    "label = oof_df['score'].values\n",
    "eval_pred = predictions, label\n",
    "compute_metrics(eval_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47dc9a5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T09:18:45.664947Z",
     "iopub.status.busy": "2022-05-29T09:18:45.664691Z",
     "iopub.status.idle": "2022-05-29T09:18:46.109701Z",
     "shell.execute_reply": "2022-05-29T09:18:46.108873Z"
    },
    "papermill": {
     "duration": 0.474254,
     "end_time": "2022-05-29T09:18:46.111679",
     "exception": false,
     "start_time": "2022-05-29T09:18:45.637425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "oof_df.to_csv('oof_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f268372e",
   "metadata": {
    "papermill": {
     "duration": 0.026267,
     "end_time": "2022-05-29T09:18:46.165025",
     "exception": false,
     "start_time": "2022-05-29T09:18:46.138758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7891.042844,
   "end_time": "2022-05-29T09:18:48.939710",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-29T07:07:17.896866",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00a94d1440834f079441c437b204d35d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_872dfd78cada4195a3cf8f8493bec334",
       "max": 579.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6f7d69fc2d3d423fa2a771339cc8dc48",
       "value": 579.0
      }
     },
     "0718bdaa31414e939a063a7625a1abe6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "084317397f6e4867b47911d9e4e6a2ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c13e9b2a18de4775929788e980476150",
       "placeholder": "​",
       "style": "IPY_MODEL_c9b6f70bb1284123a600bbfa85943e05",
       "value": "Downloading: 100%"
      }
     },
     "0badd650398444bbbb0c95b9d62bee64": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2775a5a9956e4a02999f193c0f9dca3a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_454c6e00799f44d2ab8fca1438a23404",
       "placeholder": "​",
       "style": "IPY_MODEL_df056f18254f462b9ff710d1c7999bb3",
       "value": "Downloading: 100%"
      }
     },
     "2e71661062a04898baa5608ec1e7d251": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3f8ad382a6d14e47bd0b507933074928": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "454c6e00799f44d2ab8fca1438a23404": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "46916a07e15c498a8fc48515e281240e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "507e4aa8fb04484caeb2fb40f5cc6428": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b048f29976ad4c099a22c43be215e634",
       "max": 52.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c5d33c2e662d41fa8cd825f9d2ddf08c",
       "value": 52.0
      }
     },
     "55a6b00b262849f1b557069639062da7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "59c0815094ee4da481d8156f035ce6c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6e33c240210c41aeafa1e446e1992efb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6f7d69fc2d3d423fa2a771339cc8dc48": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "71c1447898044c66ad6058fad9b6a2e4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "71ce0a736fcd4a4f8ca851b540f7dae7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0718bdaa31414e939a063a7625a1abe6",
       "placeholder": "​",
       "style": "IPY_MODEL_dba9b2fd48d743a8a525c16c3ae2a66c",
       "value": "Downloading: 100%"
      }
     },
     "729798244d304a11b619b8467bc451ac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2775a5a9956e4a02999f193c0f9dca3a",
        "IPY_MODEL_934d05ade9cd44cf9f3ecc63a3c435df",
        "IPY_MODEL_73ce23be53a14394ac2cd70c7d6ffc50"
       ],
       "layout": "IPY_MODEL_cdcf688e66614d0996ed20480113302c"
      }
     },
     "73ce23be53a14394ac2cd70c7d6ffc50": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a810633cc59c4123a9cf6b45c11479ce",
       "placeholder": "​",
       "style": "IPY_MODEL_f1e1d8288e4741069cc99890f66ca3c2",
       "value": " 354M/354M [00:07&lt;00:00, 50.9MB/s]"
      }
     },
     "80f42466d4584ccfa694bc151c669680": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "872dfd78cada4195a3cf8f8493bec334": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8bec331f31c043b382a9b093ebb8979c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d99272bfe82d4a85a8f9ae4cfa660e8c",
       "max": 2464616.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f4c1b10c09eb4f5faa84acd1772af15c",
       "value": 2464616.0
      }
     },
     "8fbcee5b688e4f02872631bf15e8ab13": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2e71661062a04898baa5608ec1e7d251",
       "placeholder": "​",
       "style": "IPY_MODEL_59c0815094ee4da481d8156f035ce6c2",
       "value": " 2.35M/2.35M [00:00&lt;00:00, 11.1MB/s]"
      }
     },
     "91d04b0a0f0145e68c5d7efe31cea3cc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_084317397f6e4867b47911d9e4e6a2ce",
        "IPY_MODEL_507e4aa8fb04484caeb2fb40f5cc6428",
        "IPY_MODEL_dd9e4e80e51441f5b4ec0ae51ee5abf9"
       ],
       "layout": "IPY_MODEL_80f42466d4584ccfa694bc151c669680"
      }
     },
     "934d05ade9cd44cf9f3ecc63a3c435df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c0294b18d8654aa8a3bb0ac9f0d4e7d0",
       "max": 371146213.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_46916a07e15c498a8fc48515e281240e",
       "value": 371146213.0
      }
     },
     "a810633cc59c4123a9cf6b45c11479ce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b048f29976ad4c099a22c43be215e634": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b72abff07b1940898ebcb860d7f34f22": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "be1e6a3562f84ef6a79df70403d13099": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_71ce0a736fcd4a4f8ca851b540f7dae7",
        "IPY_MODEL_00a94d1440834f079441c437b204d35d",
        "IPY_MODEL_fcce40eb9b4749eb8670589e77af8b81"
       ],
       "layout": "IPY_MODEL_3f8ad382a6d14e47bd0b507933074928"
      }
     },
     "c0294b18d8654aa8a3bb0ac9f0d4e7d0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c13e9b2a18de4775929788e980476150": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c5627269bbd64da998c974ff2b90702d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f04627000dc345f793fa975b7fb26ffe",
        "IPY_MODEL_8bec331f31c043b382a9b093ebb8979c",
        "IPY_MODEL_8fbcee5b688e4f02872631bf15e8ab13"
       ],
       "layout": "IPY_MODEL_71c1447898044c66ad6058fad9b6a2e4"
      }
     },
     "c5d33c2e662d41fa8cd825f9d2ddf08c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c9b6f70bb1284123a600bbfa85943e05": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "cdcf688e66614d0996ed20480113302c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d99272bfe82d4a85a8f9ae4cfa660e8c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dba9b2fd48d743a8a525c16c3ae2a66c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "dd9e4e80e51441f5b4ec0ae51ee5abf9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f5897b6d77834e52a5b97069b5ca26cb",
       "placeholder": "​",
       "style": "IPY_MODEL_ec130e88422748d190c63beeca02d49f",
       "value": " 52.0/52.0 [00:00&lt;00:00, 2.01kB/s]"
      }
     },
     "df056f18254f462b9ff710d1c7999bb3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ec130e88422748d190c63beeca02d49f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f04627000dc345f793fa975b7fb26ffe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_55a6b00b262849f1b557069639062da7",
       "placeholder": "​",
       "style": "IPY_MODEL_6e33c240210c41aeafa1e446e1992efb",
       "value": "Downloading: 100%"
      }
     },
     "f1e1d8288e4741069cc99890f66ca3c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f4c1b10c09eb4f5faa84acd1772af15c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f5897b6d77834e52a5b97069b5ca26cb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fcce40eb9b4749eb8670589e77af8b81": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0badd650398444bbbb0c95b9d62bee64",
       "placeholder": "​",
       "style": "IPY_MODEL_b72abff07b1940898ebcb860d7f34f22",
       "value": " 579/579 [00:00&lt;00:00, 23.5kB/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
