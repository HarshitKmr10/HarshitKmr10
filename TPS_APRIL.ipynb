{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPS_APRIL.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOcNVVq0zOXef7mfCq9xzt2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarshitKmr10/TPS-APRIL/blob/main/TPS_APRIL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNKdI4daOdao"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "nux1XTjcQ3YY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "aU9370GdLYNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "qiKoUw8NLbUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle competitions download tabular-playground-series-apr-2022"
      ],
      "metadata": {
        "id": "XxF0_klULf_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip tabular-playground-series-apr-2022"
      ],
      "metadata": {
        "id": "igjHnNw7Os8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "id": "iYVVP1KLL-8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd\n",
        "train=pd.read_csv(\"train.csv\")\n",
        "test=pd.read_csv(\"test.csv\")"
      ],
      "metadata": {
        "id": "UcE5QIJpNL6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import time, logging, gc\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
        "from sklearn.metrics import roc_auc_score\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from sklearn.model_selection import KFold, GroupKFold\n",
        "from tensorflow.keras.metrics import AUC\n",
        "import matplotlib.pyplot as plt   \n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "import sklearn\n",
        "\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
        "\n",
        "!pip install keras-self-attention\n",
        "from keras_self_attention import SeqSelfAttention"
      ],
      "metadata": {
        "id": "veJsBUVLNQrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels=pd.read_csv(\"train_labels.csv\")"
      ],
      "metadata": {
        "id": "v8fkjV9LPHKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features  = [col for col in test.columns if col not in (\"sequence\",\"step\",\"subject\")]\n",
        "\n",
        "train = pd.merge(train, train_labels,how='left', on=\"sequence\")\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        " \n",
        "def addFeatures(df):  \n",
        "    for feature in features:\n",
        "        df[feature + '_lag1'] = df.groupby('sequence')[feature].shift(1)\n",
        "        df.fillna(0, inplace=True)\n",
        "        df[feature + '_diff1'] = df[feature] - df[feature + '_lag1']    \n",
        "    return df\n",
        "\n",
        "\n",
        "train = addFeatures(train)\n",
        "test = addFeatures(test)\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "train\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "train.info()\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "a=train.groupby(sort=False,by=\"sequence\").mean()\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "a=train.subject.unique()\n",
        "a=np.array(a)\n",
        "len(a)\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "a.sort()\n",
        "l=a==[i for i in range(0,672)]\n",
        "if l.all():\n",
        "    print(\"TRue\")\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "train_labels\n",
        "train[[\"sequence\",\"subject\"]].iloc[60:60+60] \n",
        "#implication --> sequence corresponds to an explicit subjects\n",
        "#train=train.drop(\"subject\",axis=1)\n",
        "train\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "train_sequence=[]\n",
        "train_labels\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "for i in train.groupby(sort=False,by=\"sequence\"):\n",
        "    train_sequence.append(i)\n",
        "train_sequence[1][1].head()\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "def call(df,seq):\n",
        "    return df[seq][1]\n",
        "call(train_sequence,1).head()\n",
        "\n",
        "# %% [markdown]\n",
        "# # seperating indexes for 1's and 0's reading to understand the data\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "train_labels\n",
        "zeros_index=[]\n",
        "ones_index=[]\n",
        "for i in range(len(train_labels)):\n",
        "    if train_labels[\"state\"].iloc[i]==1:\n",
        "        ones_index.append(i)\n",
        "    else:\n",
        "        zeros_index.append(i)\n",
        "print(len(ones_index),len(zeros_index))\n",
        "\n",
        "# %% [markdown]\n",
        "# almost equal ones and zeros to train :)\n",
        "\n",
        "# %% [markdown]\n",
        "# # visualising senosory data\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "features_sen=[i for i in train.columns if \"sensor\" in i]\n",
        "#call(train_sequence,j)[\"sensor_00\"]\n",
        "\n",
        "# %% [markdown]\n",
        "# # superimposed reading\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "def super_imp(arr,tt=train_sequence):\n",
        "    for i in features_sen:\n",
        "        plt.figure(figsize=(18, 3))\n",
        "        for j in arr:#add any to the bracket for comparing in one\n",
        "            l=call(tt,j)\n",
        "            l=l.set_index(\"step\")\n",
        "            plt.plot(l[i])#x=60,y=values of column\n",
        "        plt.legend(arr)\n",
        "        plt.title(str(i))\n",
        "        plt.show()\n",
        "\n",
        "# %% [markdown]\n",
        "# # comparsion\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "from random import shuffle\n",
        "\n",
        "# %% [markdown]\n",
        "# # displaying ones\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "train_df=train.copy()\n",
        "features=features_sen\n",
        "shuffle(ones_index)\n",
        "sequences = ones_index[:4]#[0, 1, 2, 8364, 15404,]\n",
        "figure, axes = plt.subplots(13, len(sequences), sharex=True, figsize=(16, 16))\n",
        "for i, sequence in enumerate(sequences):\n",
        "    for sensor in range(13):\n",
        "        sensor_name = f\"sensor_{sensor:02d}\"\n",
        "        plt.subplot(13, len(sequences), sensor * len(sequences) + i + 1)\n",
        "        plt.plot(range(60), train_df[train_df.sequence == sequence][sensor_name],\n",
        "                color=plt.rcParams['axes.prop_cycle'].by_key()['color'][i % 10])\n",
        "        if sensor == 0: plt.title(f\"Sequence {sequence}\")\n",
        "        if sequence == sequences[0]: plt.ylabel(sensor_name)\n",
        "figure.tight_layout(w_pad=0.1)\n",
        "plt.suptitle('Selected Time Series', y=1.02)\n",
        "plt.show()\n",
        "print(train_labels.loc[sequences,[\"state\"]])\n",
        "sequences_1=sequences\n",
        "\n",
        "# %% [markdown]\n",
        "# # displaying zeros\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "train_df=train.copy()\n",
        "features=features_sen\n",
        "shuffle(zeros_index)\n",
        "sequences_0 = zeros_index[:8]#[0, 1, 2, 8364, 15404,]\n",
        "sequences=sequences_0\n",
        "figure, axes = plt.subplots(13, len(sequences), sharex=True, figsize=(16, 16))\n",
        "for i, sequence in enumerate(sequences):\n",
        "    for sensor in range(13):\n",
        "        sensor_name = f\"sensor_{sensor:02d}\"\n",
        "        plt.subplot(13, len(sequences), sensor * len(sequences) + i + 1)\n",
        "        plt.plot(range(60), train_df[train_df.sequence == sequence][sensor_name],\n",
        "                color=plt.rcParams['axes.prop_cycle'].by_key()['color'][i % 10])\n",
        "        if sensor == 0: plt.title(f\"Sequence {sequence}\")\n",
        "        if sequence == sequences[0]: plt.ylabel(sensor_name)\n",
        "figure.tight_layout(w_pad=0.1)\n",
        "plt.suptitle('Selected Time Series', y=1.02)\n",
        "plt.show()\n",
        "print(train_labels.loc[sequences_0,[\"state\"]])\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "super_imp(sequences_0)\n",
        "\n",
        "# %% [markdown]\n",
        "# pass data through a function to remove noise while maintsing integrity of the data\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "transform = VarianceThreshold(threshold=0.05)\n",
        "# transform the input data\n",
        "X_sel = transform.fit_transform(train_df)\n",
        "X_sel\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from numpy import log\n",
        "mydata = pd.read_csv('train.csv', names = ['value'], header = 0) \n",
        "mydata\n",
        "print(1)\n",
        "#res=adfuller(mydata.value.dropna())\n",
        "print(2)\n",
        "\n",
        "#res\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "#dickey fuller test for stationarity since applying arima model p<0.005\n",
        "no_adfs=[]\n",
        "for i in range(25968):\n",
        "    re=adfuller(mydata[\"value\"][i])\n",
        "    if re[1]<=0.005:\n",
        "        pass\n",
        "    else:\n",
        "        no_adfs.append(i)\n",
        "    if i in [25968,int(25968*(0.75)),int(25968*(0.5)),int(25968*(0.25)),0]:\n",
        "        print(i,end=\" \")\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "len(no_adfs),len(train)\n",
        "len(mydata.value[0])\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "train[\"index\"]=range(len(train))\n",
        "a=train.set_index(\"sequence\",False).drop(no_adfs,axis=0)\n",
        "b=train.set_index(\"index\")\n",
        "tt=[]\n",
        "for i in b.groupby(sort=False,by=\"sequence\"):\n",
        "    tt.append(i)\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "train_2=a\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "#copied code for testing\n",
        "def BuildNN():\n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Input(shape=(60, 87)),\n",
        "        keras.layers.Conv1D(32, 5),\n",
        "        \n",
        "        keras.layers.Bidirectional(keras.layers.LSTM(768, return_sequences=True)),\n",
        "        keras.layers.Bidirectional(keras.layers.LSTM(512, return_sequences=True)),\n",
        "        keras.layers.Bidirectional(GRU(units=256,return_sequences=True)),\n",
        "        keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True)),\n",
        "        keras.layers.MaxPooling1D(),\n",
        "        keras.layers.Conv1D(64, 3),\n",
        "        keras.layers.GlobalMaxPooling1D(),\n",
        "        keras.layers.Dense(150, activation=\"selu\"),\n",
        "        keras.layers.Dense(100, activation='selu'),\n",
        "        keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[keras.metrics.AUC()])\n",
        "    return model\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "def dnn_model():\n",
        "\n",
        "    x_input = Input(shape=(60,42))\n",
        "    \n",
        "   \n",
        "    x = Bidirectional(LSTM(512, return_sequences=True), name='BiLSTM1')(x_input)\n",
        "    x = Bidirectional(LSTM(384, return_sequences=True), name='BiLSTM2')(x)\n",
        "    #x = SeqSelfAttention(attention_activation='selu',name='attention_weight')(x)\n",
        "    x = GlobalAveragePooling1D()(x)\n",
        "    \n",
        "    x_output = Dense(units=1, activation=\"sigmoid\")(x)\n",
        "    \n",
        "    model = Model(inputs=x_input, outputs=x_output, name='alstm_model')\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = dnn_model()\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from IPython.display import display\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "'''tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)'''\n",
        "\n",
        "# %% [markdown]\n",
        "# # modifying feature 2 in train_2 and test\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "train_2.head()\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "\"\"\"a=train_2.corr()\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(12,12))\n",
        "sns.heatmap(a,annot=True)\n",
        "R_2_n=[]\n",
        "for i in range(4,len(a[\"sensor_02\"])):\n",
        "    if (a[\"sensor_02\"][i]**2)**(0.5)>0.001:\n",
        "        R_2_n.append(i-4)\n",
        "R_2_n=R_2_n[:-1]\n",
        "R_2_n\"\"\"\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "\"\"\"s_2_n=[list(train_2[\"sensor_02\"])]+[list(train_2[\"sensor_0\"+str(i)]) for i in R_2_n]\n",
        "trial=train_2.copy()\n",
        "k=list(np.array(s_2_n[0])*(np.array(s_2_n[1])+(0.2)*np.array(s_2_n[2])))\n",
        "trial[\"sensor_02\"]=k\n",
        "#/np.array(s_2_n[3])))\n",
        "plt.figure(figsize=(12,13))\n",
        "sns.heatmap(trial.corr(),annot=True)\n",
        "trial\"\"\"\n",
        "\n",
        "# %% [markdown]\n",
        "# GOOD CORR IN 2 OBTAINED ,THERFORE NOT GOING TO DROP SENS-2\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "'''train_2[\"sensor_02\"]=k\n",
        "s_2_n=[list(test[\"sensor_02\"])]\n",
        "s_2_n+=[list(test[\"sensor_0\"+str(i)]) for i in R_2_n]\n",
        "test[\"sensor_02\"]=list(np.array(s_2_n[0])*(np.array(s_2_n[1])+(0.2)*np.array(s_2_n[2])))\n",
        "train_2.head()\n",
        "train_2=train_2.drop(\"index\",axis=1)\n",
        "train_2.head()'''\n",
        "\n",
        "# %% [markdown]\n",
        "# not doing any cahnges with sensor 2 as it leads to over fitting\n",
        "\n",
        "# %% [markdown]\n",
        "# # Adding other features\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "#sumation of different columns\n",
        "s=train_2[\"sensor_00\"]+train_2[\"sensor_01\"]+train_2[\"sensor_06\"]+train_2[\"sensor_09\"]\n",
        "s1=train_2[\"sensor_02\"]+train_2[\"sensor_03\"]+train_2[\"sensor_07\"]+train_2[\"sensor_12\"]\n",
        "d=s-s1\n",
        "train_2[\"sum_1\"]=s\n",
        "train_2[\"sum_2\"]=s1\n",
        "train_2[\"diff\"]=d\n",
        "\"\"\"plt.figure(figsize=(16,16))\n",
        "sns.heatmap(train_2.corr(),annot=True)\"\"\"\n",
        "\n",
        "# %% [markdown]\n",
        "# good results converting test too\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "s=test[\"sensor_00\"]+test[\"sensor_01\"]+test[\"sensor_06\"]+test[\"sensor_09\"]\n",
        "s1=test[\"sensor_02\"]+test[\"sensor_03\"]+test[\"sensor_07\"]+test[\"sensor_12\"]\n",
        "d=s-s1\n",
        "test[\"sum_1\"]=s\n",
        "test[\"sum_2\"]=s1\n",
        "test[\"diff\"]=d\n",
        "\n",
        "# %% [markdown]\n",
        "# # scalling data(standardization)\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "train_2=train_2.drop(\"index\",axis=1)\n",
        "train_2=train_2.drop(\"state\",axis=1)\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "cul=train_2.columns\n",
        "len(cul)\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "train_2.columns\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "b=sc.fit_transform(train_2)\n",
        "a=sc.transform(test)\n",
        "a=pd.DataFrame(a)\n",
        "b=pd.DataFrame(b)\n",
        "test=a.set_axis(cul,axis=\"columns\")\n",
        "train_2=b.set_axis(cul,axis=\"columns\")\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA()\n",
        "train_pca = pca.fit_transform(train_2)\n",
        "\n",
        "# Convert to dataframe\n",
        "component_names = [f\"PC{i+1}\" for i in range(train_pca.shape[1])]\n",
        "train_pca = pd.DataFrame(train_pca, columns=component_names)\n",
        "pca = PCA()\n",
        "\n",
        "test_pca = pca.fit_transform(test)\n",
        "component_names = [f\"PC{i+1}\" for i in range(test_pca.shape[1])]\n",
        "test_pca = pd.DataFrame(test_pca, columns=component_names)\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "train_2=pd.concat([train_2,train_pca],axis=1)\n",
        "test=pd.concat([test,test_pca],axis=1)\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "test.head()\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "train=train_2\n",
        "groups = train[\"sequence\"]\n",
        "train = train.drop([\"sequence\",\"subject\", \"step\"], inplace=False, axis=1).values\n",
        "test = test.drop([\"sequence\", \"subject\", \"step\"], inplace=False, axis=1).values\n",
        "labels = train_labels[\"state\"]\n",
        "labels=labels.drop(no_adfs,axis=0)\n",
        "train = train.reshape(int(len(train)/60), 60, 87)\n",
        "test = test.reshape(int(len(test)/60), 60, 87)\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "train.shape\n",
        "len(train)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gvbHa7xdPSs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_score = 0\n",
        "test_preds = []\n",
        "kf = GroupKFold(n_splits=5)\n",
        "for fold_idx, (train_idx, valid_idx) in enumerate(kf.split(train, labels, groups.unique())):\n",
        "    \n",
        "    print(\"*\"*15, f\"Fold {fold_idx+1}\", \"*\"*15)\n",
        "    \n",
        "    X_train, X_valid = train[train_idx], train[valid_idx]\n",
        "    y_train, y_valid = labels.iloc[train_idx].values, labels.iloc[valid_idx].values\n",
        "    \n",
        "    model = BuildNN()\n",
        "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics='AUC')\n",
        "    model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=50, batch_size=256, \n",
        "              callbacks=[keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])\n",
        "    \n",
        "    cv_score += roc_auc_score(y_valid, model.predict(X_valid).squeeze())\n",
        "    \n",
        "    test_preds.append(model.predict(test).squeeze())\n",
        "    \n",
        "print(cv_score/5)"
      ],
      "metadata": {
        "id": "hxJ-dmfgP4Ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission=pd.read_csv(\"sample_submission.csv\")\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "submission[\"state\"] = sum(test_preds)/5\n",
        "ans=[]\n",
        "for i in submission[\"state\"]:\n",
        "    ans.append(i)\n",
        "\n",
        "# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n",
        "submission.to_csv(\"submission.csv_36\", index=False)\n",
        "submission"
      ],
      "metadata": {
        "id": "9sagpYMDQE2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "M4H8vaowQNI-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}