{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04abbc02",
   "metadata": {
    "papermill": {
     "duration": 0.022628,
     "end_time": "2022-06-05T18:43:06.904981",
     "exception": false,
     "start_time": "2022-06-05T18:43:06.882353",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Overview\n",
    "\n",
    "Guide: Baseline Guide<br>\n",
    "Inference: USPPPM: DeBERTa V3 Small [Inference]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829d3038",
   "metadata": {
    "papermill": {
     "duration": 0.020728,
     "end_time": "2022-06-05T18:43:06.947608",
     "exception": false,
     "start_time": "2022-06-05T18:43:06.926880",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d54d1a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T18:43:07.001809Z",
     "iopub.status.busy": "2022-06-05T18:43:07.001031Z",
     "iopub.status.idle": "2022-06-05T18:43:10.807462Z",
     "shell.execute_reply": "2022-06-05T18:43:10.806895Z",
     "shell.execute_reply.started": "2022-06-05T18:42:31.917443Z"
    },
    "papermill": {
     "duration": 3.837204,
     "end_time": "2022-06-05T18:43:10.807615",
     "exception": false,
     "start_time": "2022-06-05T18:43:06.970411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -q -y transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e63210e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-06-05T18:43:10.863666Z",
     "iopub.status.busy": "2022-06-05T18:43:10.862890Z",
     "iopub.status.idle": "2022-06-05T18:43:15.848059Z",
     "shell.execute_reply": "2022-06-05T18:43:15.847562Z",
     "shell.execute_reply.started": "2022-06-05T18:42:35.540816Z"
    },
    "papermill": {
     "duration": 5.018266,
     "end_time": "2022-06-05T18:43:15.848192",
     "exception": false,
     "start_time": "2022-06-05T18:43:10.829926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../input/torch-components-library/torch-components-main\")\n",
    "sys.path.append(\"../input/transformers/src\")\n",
    "sys.path.append(\"../input/mixout-github-code/mixout\")\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import transformers\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "from torch_components import Configuration as Config, Timer, Averager\n",
    "from torch_components.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from torch_components.utils import seed_everything, get_lr, get_optimizer, get_scheduler\n",
    "from torch_components.import_utils import wandb_run_exists\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from mixout import MixLinear, Mixout\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display\n",
    "from datetime import timedelta\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import wandb\n",
    "import os\n",
    "import shutil\n",
    "import gc\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "\n",
    "os.environ[\"EXPERIMENT_NAME\"] = \"microsoft/deberta-v3-large\"\n",
    "\n",
    "EXPERIMENT_NAME = os.environ.get(\"EXPERIMENT_NAME\")\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "WANDB = False\n",
    "DEBUG = True\n",
    "USER_SECRETS = UserSecretsClient()\n",
    "\n",
    "\n",
    "if WANDB:\n",
    "    os.environ[\"WANDB_PROJECT\"] = \"uspppm\"\n",
    "    os.environ[\"WANDB_ENTITY\"] = \"uspppm\"\n",
    "    os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "    \n",
    "    wandb_secret_name = \"wandb_api_key\"\n",
    "    wandb_key = USER_SECRETS.get_secret(wandb_secret_name)\n",
    "    \n",
    "    EXPERIMENT_NAME = EXPERIMENT_NAME if EXPERIMENT_NAME != \"none\" else wandb.util.generate_id()\n",
    "    wandb.login(key=wandb_key)\n",
    "    \n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754a97ed",
   "metadata": {
    "papermill": {
     "duration": 0.022299,
     "end_time": "2022-06-05T18:43:15.892263",
     "exception": false,
     "start_time": "2022-06-05T18:43:15.869964",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90dbaddd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T18:43:15.944326Z",
     "iopub.status.busy": "2022-06-05T18:43:15.942791Z",
     "iopub.status.idle": "2022-06-05T18:43:15.944913Z",
     "shell.execute_reply": "2022-06-05T18:43:15.945307Z",
     "shell.execute_reply.started": "2022-06-05T18:42:40.481372Z"
    },
    "papermill": {
     "duration": 0.031583,
     "end_time": "2022-06-05T18:43:15.945429",
     "exception": false,
     "start_time": "2022-06-05T18:43:15.913846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = Config(model=dict(model_path=\"microsoft/deberta-v3-large\"),\n",
    "                optimizer=dict(name=\"AdamW\", parameters=dict(lr=1e-5, weight_decay=0.01)),\n",
    "                scheduler=dict(name=\"get_cosine_with_hard_restarts_schedule_with_warmup\", \n",
    "                               parameters=dict(num_cycles=2, last_epoch=-1)),\n",
    "                warmup=0.1,\n",
    "                scheduling_after=\"step\",\n",
    "                seed=42,\n",
    "                max_length=64,\n",
    "                batch_size=16,\n",
    "                epochs=5,\n",
    "                num_workers=4,\n",
    "                pin_memory=True,\n",
    "                folds=4,\n",
    "                validation_steps=200, \n",
    "                gradient_accumulation_steps=1,\n",
    "                gradient_norm=1.0,\n",
    "                gradient_scaling=True,\n",
    "                delta=1e-4,\n",
    "                verbose=100,\n",
    "                save_model=False,\n",
    "                device=DEVICE,\n",
    "                input_directory=\"./\",\n",
    "                output_directory=\"./\",\n",
    "                cv_monitor_value=\"pearson\",\n",
    "                amp=True, \n",
    "                debug=True,\n",
    "                decimals=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4af7144f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T18:43:15.992718Z",
     "iopub.status.busy": "2022-06-05T18:43:15.992175Z",
     "iopub.status.idle": "2022-06-05T18:43:15.998142Z",
     "shell.execute_reply": "2022-06-05T18:43:15.998513Z",
     "shell.execute_reply.started": "2022-06-05T18:42:40.492908Z"
    },
    "papermill": {
     "duration": 0.031068,
     "end_time": "2022-06-05T18:43:15.998630",
     "exception": false,
     "start_time": "2022-06-05T18:43:15.967562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config.seed = seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b372674",
   "metadata": {
    "papermill": {
     "duration": 0.021341,
     "end_time": "2022-06-05T18:43:16.042406",
     "exception": false,
     "start_time": "2022-06-05T18:43:16.021065",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f57d62e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T18:43:16.093514Z",
     "iopub.status.busy": "2022-06-05T18:43:16.092958Z",
     "iopub.status.idle": "2022-06-05T18:43:16.095636Z",
     "shell.execute_reply": "2022-06-05T18:43:16.095236Z",
     "shell.execute_reply.started": "2022-06-05T18:42:40.507297Z"
    },
    "papermill": {
     "duration": 0.031691,
     "end_time": "2022-06-05T18:43:16.095739",
     "exception": false,
     "start_time": "2022-06-05T18:43:16.064048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_directory(directory, overwriting=False):\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)\n",
    "    else:\n",
    "        if overwriting:\n",
    "            shutil.rmtree(directory)\n",
    "            os.mkdir(directory)\n",
    "\n",
    "            \n",
    "def create_folds(data_frame, targets, groups, folds=4, seed=42, shuffle=True, fold_column=\"fold\"):\n",
    "    cv_strategy = StratifiedGroupKFold(n_splits=folds, random_state=seed, shuffle=shuffle)\n",
    "    folds = cv_strategy.split(X=data_frame, y=targets, groups=groups)\n",
    "    for fold, (train_indexes, validation_indexes) in enumerate(folds):\n",
    "        data_frame.loc[validation_indexes, fold_column] =  int(fold+1)\n",
    "        \n",
    "    data_frame[fold_column] = data_frame[fold_column].astype(int)\n",
    "    \n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "497c1a75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T18:43:16.158712Z",
     "iopub.status.busy": "2022-06-05T18:43:16.147992Z",
     "iopub.status.idle": "2022-06-05T18:43:16.206549Z",
     "shell.execute_reply": "2022-06-05T18:43:16.206134Z",
     "shell.execute_reply.started": "2022-06-05T18:42:40.516715Z"
    },
    "papermill": {
     "duration": 0.089605,
     "end_time": "2022-06-05T18:43:16.206645",
     "exception": false,
     "start_time": "2022-06-05T18:43:16.117040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training_loop(train_loader, \n",
    "                  model,\n",
    "                  optimizer,\n",
    "                  scheduler=None,\n",
    "                  scheduling_after=\"step\",\n",
    "                  epochs=1,\n",
    "                  validation_loader=None, \n",
    "                  gradient_accumulation_steps=1, \n",
    "                  gradient_scaling=False,\n",
    "                  gradient_norm=1,\n",
    "                  validation_steps=\"epoch\", \n",
    "                  amp=False,\n",
    "                  recalculate_metrics_at_end=True, \n",
    "                  return_validation_outputs=True,\n",
    "                  debug=True, \n",
    "                  teacher_model=None,\n",
    "                  pseudo_loader=None,\n",
    "                  verbose=100, \n",
    "                  device=\"cpu\", \n",
    "                  time_format=\"{hours}:{minutes}:{seconds}\", \n",
    "                  logger=[\"print\", \"wandb\"], \n",
    "                  decimals=4):\n",
    "    \n",
    "    training_steps = len(train_loader) * epochs\n",
    "    \n",
    "    if isinstance(validation_steps, float):\n",
    "        validation_steps = int(training_steps * validation_steps)\n",
    "    elif validation_steps == \"epoch\":\n",
    "        validation_steps = len(train_loader)\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Epochs: {epochs}\")\n",
    "        print(f\"Auto Mixed Precision: {amp}\")\n",
    "        print(f\"Gradient norm: {gradient_norm}\")\n",
    "        print(f\"Gradient scaling: {gradient_scaling}\")\n",
    "        print(f\"Gradient accumulation steps: {gradient_accumulation_steps}\")\n",
    "        print(f\"Validation steps: {validation_steps}\")\n",
    "        print(f\"Device: {device}\")\n",
    "        print()\n",
    "        \n",
    "    if wandb_run_exists() and \"wandb\" in logger:\n",
    "        print(f\"Weights & Biases Run: {wandb.run.get_url()}\", end=\"\\n\"*2)\n",
    "        \n",
    "    passed_steps = 1\n",
    "    train_loss, train_metrics = Averager(), Averager()\n",
    "    scaler = GradScaler() if gradient_scaling else None\n",
    "    best_validation_loss, best_validation_metrics, best_validation_outputs = None, None, None\n",
    "    total_time = timedelta(seconds=0)\n",
    "    \n",
    "    if device is not None: \n",
    "        model.to(device)\n",
    "        \n",
    "        if teacher_model is not None: teacher_model.to(device)\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        if \"tqdm\" in logger:\n",
    "            bar_format = \"{l_bar} {bar} {n_fmt}/{total_fmt} - remain: {remaining}{postfix}\"\n",
    "            train_loader = tqdm(iterable=train_loader, \n",
    "                                total=len(train_loader),\n",
    "                                colour=\"#000\",\n",
    "                                bar_format=bar_format)\n",
    "            \n",
    "            train_loader.set_description_str(f\"Epoch {epoch}/{epochs}\")\n",
    "        \n",
    "        if \"print\" in logger:\n",
    "            print(f\"\\nEpoch {epoch}/{epochs}\", end=\"\\n\"*2)\n",
    "            \n",
    "        epoch_train_loss, epoch_train_metrics = Averager(), Averager()\n",
    "        timer = Timer(time_format)\n",
    "        steps = len(train_loader)    \n",
    "        \n",
    "        model.zero_grad()\n",
    "        for step, batch in enumerate(train_loader, 1):\n",
    "            batch_size = train_loader.batch_size\n",
    "            \n",
    "            step_timer =  Timer(time_format)\n",
    "            pseudo_batch = next(iter(pseudo_loader)) if pseudo_loader is not None else None\n",
    "            batch_loss, batch_metrics = training_step(batch=batch, \n",
    "                                                      model=model, \n",
    "                                                      optimizer=optimizer,\n",
    "                                                      gradient_norm=gradient_norm,\n",
    "                                                      gradient_accumulation_steps=gradient_accumulation_steps, \n",
    "                                                      amp=amp, \n",
    "                                                      scaler=scaler, \n",
    "                                                      device=device, \n",
    "                                                      overall_loss=epoch_train_loss.average, \n",
    "                                                      overall_metrics=epoch_train_metrics.average,\n",
    "                                                      step=passed_steps, \n",
    "                                                      epoch=epoch, \n",
    "                                                      teacher_model=teacher_model,\n",
    "                                                      pseudo_batch=pseudo_batch)\n",
    "            \n",
    "            lr_key = \"lr\"\n",
    "            lr = get_lr(optimizer, only_last=True, key=lr_key)\n",
    "            \n",
    "            if step % gradient_accumulation_steps == 0:\n",
    "                optimization_step(model=model, optimizer=optimizer, scaler=scaler)\n",
    "    \n",
    "                if scheduling_after == \"step\":\n",
    "                    scheduling_step(scheduler, loop=\"training\")\n",
    "            \n",
    "            elapsed, remain = step_timer(1/1)\n",
    "            step_seconds = step_timer.elapsed_time.total_seconds()\n",
    "            sample_seconds = step_seconds / batch_size\n",
    "            \n",
    "            if wandb_run_exists() and \"wandb\" in logger:\n",
    "                logs = {\"train/seconds vs step\": step_seconds, \n",
    "                        \"train/seconds vs sample\": sample_seconds}\n",
    "                \n",
    "                wandb.log(logs, step=passed_steps)\n",
    "            \n",
    "            train_loss.update(batch_loss, n=batch_size)\n",
    "            epoch_train_loss.update(batch_loss, n=batch_size)\n",
    "            train_metrics.update(batch_metrics, n=batch_size)\n",
    "            epoch_train_metrics.update(batch_metrics, n=batch_size)\n",
    "            \n",
    "            \n",
    "            logs = {\"train/loss\": train_loss.average, \n",
    "                    \"train/loss vs batch\": batch_loss, \n",
    "                    \"train/loss vs epoch\": epoch_train_loss.average,\n",
    "                    \"lr\": lr}\n",
    "            \n",
    "            for metric in batch_metrics:\n",
    "                logs.update({f\"train/{metric}\": train_metrics.average[metric], \n",
    "                             f\"train/{metric} vs batch\": batch_metrics[metric], \n",
    "                             f\"train/{metric} vs epoch\": epoch_train_metrics.average[metric]})\n",
    "                \n",
    "            if wandb_run_exists() and \"wandb\" in logger:\n",
    "                wandb.log(logs, step=passed_steps) \n",
    "            \n",
    "            if \"tqdm\" in logger:\n",
    "                train_loader.set_postfix_str(f\"loss: {epoch_train_loss.average:.{decimals}}\"\n",
    "                                             f\"{format_metrics(epoch_train_metrics.average, decimals=decimals)}\")\n",
    "            if \"print\" in logger:\n",
    "                 if step % verbose == 0 or step == steps and verbose > 0:\n",
    "                    elapsed, remain = timer(step/steps)\n",
    "                    print(f\"{step}/{steps} - \"\n",
    "                          f\"remain: {remain} - \"\n",
    "                          f\"loss: {epoch_train_loss.average:.{decimals}}\"\n",
    "                          f\"{format_metrics(epoch_train_metrics.average, decimals=decimals)} - \"\n",
    "                          f\"lr: {lr}\")\n",
    "                    \n",
    "            \n",
    "            if validation_loader is not None:\n",
    "                if (passed_steps % validation_steps) == 0:\n",
    "                    if step > validation_steps: print()\n",
    "                    validation_loop_steps = len(validation_loader)\n",
    "                    validation_batch_size = validation_loader.batch_size\n",
    "                    \n",
    "                    validation_timer =  Timer(time_format)\n",
    "                    validation_loss, validation_metrics, validation_outputs = validation_loop(loader=validation_loader, \n",
    "                                                                                              model=model,\n",
    "                                                                                              gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "                                                                                              amp=amp, \n",
    "                                                                                              return_outputs=True, \n",
    "                                                                                              verbose=verbose, \n",
    "                                                                                              recalculate_metrics_at_end=True, \n",
    "                                                                                              device=device, \n",
    "                                                                                              logger=logger)\n",
    "                    \n",
    "                    \n",
    "                    elapsed, remain = validation_timer(1/1)\n",
    "                    validation_seconds = validation_timer.elapsed_time.total_seconds()\n",
    "                    validation_step_seconds = validation_seconds / validation_loop_steps\n",
    "                    validation_sample_seconds = validation_step_seconds / validation_batch_size\n",
    "            \n",
    "                    if wandb_run_exists() and \"wandb\" in logger:\n",
    "                        logs = {\"validation/seconds vs step\": validation_step_seconds, \n",
    "                                \"validation/seconds vs sample\": validation_sample_seconds}\n",
    "                \n",
    "                        wandb.log(logs, step=passed_steps)\n",
    "                    \n",
    "                    \n",
    "                    logs = {\"validation/loss\": validation_loss, \n",
    "                            \"train/loss vs validation steps\": epoch_train_loss.average}\n",
    "    \n",
    "                    for metric, value in validation_metrics.items():\n",
    "                        logs.update({f\"validation/{metric}\": value, \n",
    "                                     f\"train/{metric} vs validation steps\": epoch_train_metrics.average[metric]})\n",
    "                    \n",
    "                    if wandb_run_exists() and \"wandb\" in logger:\n",
    "                        wandb.log(logs, step=passed_steps)\n",
    "                    \n",
    "                    is_checkpoint_saved = model_checkpointing(loss=validation_loss, \n",
    "                                                              metrics=validation_metrics,\n",
    "                                                              model=model, \n",
    "                                                              optimizer=optimizer, \n",
    "                                                              scheduler=scheduler, \n",
    "                                                              step=passed_steps, \n",
    "                                                              best_loss=best_validation_loss, \n",
    "                                                              best_metrics=validation_metrics)\n",
    "                    \n",
    "                    if is_checkpoint_saved:\n",
    "                        best_validation_loss = validation_loss\n",
    "                        best_validation_metrics = validation_metrics\n",
    "                        best_validation_outputs = validation_outputs\n",
    "                        \n",
    "                    scheduling_step(scheduler, loss=validation_loss, loop=\"validation\")\n",
    "                    print()\n",
    "            \n",
    "            passed_steps += 1\n",
    "        \n",
    "        if scheduling_after == \"epoch\":\n",
    "            scheduling_step(scheduler, loop=\"training\")\n",
    "        \n",
    "        on_epoch_end(model=model, \n",
    "                     step=passed_steps, \n",
    "                     epoch=epoch)\n",
    "        \n",
    "        if \"tqdm\" in logger and \"print\" not in logger:\n",
    "            elapsed, remain = timer(1/1)\n",
    "        \n",
    "        epoch_elapsed_seconds = timer.elapsed_time.total_seconds()\n",
    "        total_time += timedelta(seconds=epoch_elapsed_seconds)\n",
    "        \n",
    "        if wandb_run_exists() and \"wandb\" in logger:\n",
    "            wandb.log({\"epoch\": epoch}, step=passed_steps)\n",
    "        \n",
    "        if \"tqdm\" in logger: train_loader.close()\n",
    "            \n",
    "        print(f\"\\nTraining loss: {epoch_train_loss.average:.{decimals}}\"\n",
    "              f\"{format_metrics(epoch_train_metrics.average, decimals=decimals)}\")\n",
    "        \n",
    "        if validation_loader is not None:\n",
    "            print(f\"Validation loss: {best_validation_loss:.{decimals}}\"\n",
    "                  f\"{format_metrics(best_validation_metrics, decimals=decimals)}\")\n",
    "        \n",
    "        total_time_string = Timer.format_time(total_time, time_format=time_format)\n",
    "        print(f\"Total time: {total_time_string}\")\n",
    "    \n",
    "    if validation_loader is not None:\n",
    "        if return_validation_outputs:\n",
    "            return (epoch_train_loss.average, epoch_train_metrics.average), (best_validation_loss, best_validation_metrics, best_validation_outputs)\n",
    "        \n",
    "        return (epoch_train_loss.average, epoch_train_metrics.average), (best_validation_loss, best_validation_metrics)\n",
    "\n",
    "    return (epoch_train_loss.average, epoch_train_metrics.average)\n",
    "        \n",
    "def validation_loop(loader, \n",
    "                    model, \n",
    "                    gradient_accumulation_steps=1,\n",
    "                    amp=False, \n",
    "                    return_outputs=True, \n",
    "                    recalculate_metrics_at_end=True, \n",
    "                    verbose=1, \n",
    "                    device=\"cpu\", \n",
    "                    time_format=\"{hours}:{minutes}:{seconds}\",\n",
    "                    logger=[\"print\"], \n",
    "                    decimals=4):\n",
    "    \n",
    "    model.eval()\n",
    "    loss, metrics = Averager(), Averager()\n",
    "    timer = Timer(time_format)\n",
    "    outputs, targets = [], []\n",
    "    steps = len(loader)\n",
    "    \n",
    "    if \"tqdm\" in logger:\n",
    "        bar_format = \"{l_bar} {bar} {n_fmt}/{total_fmt} - remain: {remaining}{postfix}\"\n",
    "        loader = tqdm(iterable=loader, \n",
    "                      total=len(loader),\n",
    "                      colour=\"#000\",\n",
    "                      bar_format=bar_format)\n",
    "            \n",
    "        loader.set_description_str(\"[Validation]\")\n",
    "    \n",
    "    is_targets = False\n",
    "    for step, batch in enumerate(loader, 1):\n",
    "        with torch.no_grad():\n",
    "            with autocast(enabled=amp):\n",
    "                batch_loss, batch_outputs = calculate_loss(batch=batch, model=model, return_outputs=True, device=device)\n",
    "                \n",
    "                batch_loss /= gradient_accumulation_steps\n",
    "                loss.update(batch_loss.item(), n=len(batch))\n",
    "                \n",
    "                batch_targets = get_targets(batch)\n",
    "                batch_metrics = calculate_metrics(predictions=batch_outputs, targets=batch_targets, device=device)\n",
    "                metrics.update(batch_metrics, n=len(batch))\n",
    "                \n",
    "                if batch_targets is not None:\n",
    "                    if isinstance(batch_targets, dict):\n",
    "                        targets.append(batch_targets)\n",
    "                    else:\n",
    "                        targets.extend(batch_targets.to(\"cpu\").tolist())\n",
    "                        \n",
    "                    is_targets = True\n",
    "                \n",
    "                outputs.extend(batch_outputs.to(\"cpu\").tolist())\n",
    "                \n",
    "                if step == steps and recalculate_metrics_at_end and is_targets:\n",
    "                    outputs = torch.tensor(outputs)\n",
    "                    targets = torch.tensor(targets)\n",
    "                        \n",
    "                    metrics = Averager(calculate_metrics(predictions=outputs, targets=targets))\n",
    "                \n",
    "                if \"tqdm\" in logger:\n",
    "                    loader.set_postfix_str(f\"loss: {loss.average:.{decimals}}\"\n",
    "                                           f\"{format_metrics(metrics.average, decimals=decimals)}\")\n",
    "                \n",
    "                if \"print\" in logger:\n",
    "                    if step % verbose == 0 or step == steps and verbose > 0:\n",
    "                        elapsed, remain = timer(step/steps)\n",
    "\n",
    "                        print(f\"[Validation] \"\n",
    "                              f\"{step}/{steps} - \"\n",
    "                              f\"remain: {remain} - \"\n",
    "                              f\"loss: {loss.average:.{decimals}}\"\n",
    "                              f\"{format_metrics(metrics.average, decimals=decimals)}\")\n",
    "                    \n",
    "    if not recalculate_metrics_at_end: \n",
    "        outputs = torch.tensor(outputs)\n",
    "        \n",
    "    if \"tqdm\" in logger:\n",
    "        loader.close()\n",
    "        \n",
    "    return (loss.average, metrics.average, outputs) if return_outputs else (loss.average, metrics.average)\n",
    "\n",
    "\n",
    "def format_metrics(metrics, sep=\" - \", add_sep_to_start=True, decimals=4):\n",
    "    if metrics != {}:\n",
    "        string = sep.join([f\"{k}: {v:.{decimals}}\" for k, v in metrics.items()])\n",
    "        return sep + string if add_sep_to_start else string \n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "    \n",
    "def training_step(batch, \n",
    "                  model, \n",
    "                  optimizer, \n",
    "                  gradient_norm=1.0, \n",
    "                  amp=False, \n",
    "                  gradient_accumulation_steps=1, \n",
    "                  scaler=None, \n",
    "                  device=\"cpu\", \n",
    "                  overall_loss=None, \n",
    "                  overall_metrics=None, \n",
    "                  step=None, \n",
    "                  epoch=None,\n",
    "                  teacher_model=None,\n",
    "                  pseudo_batch=None):\n",
    "    \n",
    "    model.train()\n",
    "    with autocast(enabled=amp):\n",
    "        loss, outputs = calculate_loss(batch=batch, model=model, return_outputs=True, device=device)\n",
    "        targets = get_targets(batch)\n",
    "        metrics = calculate_metrics(predictions=outputs, targets=targets, device=device)\n",
    "        \n",
    "        loss /= gradient_accumulation_steps\n",
    "        loss = backward_step(loss=loss, optimizer=optimizer, scaler=scaler)\n",
    "        \n",
    "        adversarial_loss = adversarial_step(batch=batch, \n",
    "                                            model=model, \n",
    "                                            device=device, \n",
    "                                            loss=overall_loss, \n",
    "                                            metrics=overall_metrics, \n",
    "                                            step=step, \n",
    "                                            epoch=epoch)\n",
    "        \n",
    "        if adversarial_loss is not None:\n",
    "            adversarial_loss = backward_step(loss=adversarial_loss, optimizer=optimizer, scaler=scaler)\n",
    "        \n",
    "        if pseudo_batch is not None and teacher_model is not None:\n",
    "            pseudo_loss = pseudo_labeling_step(batch=batch,\n",
    "                                               pseudo_batch=pseudo_batch,\n",
    "                                               model=model, \n",
    "                                               teacher_model=teacher_model, \n",
    "                                               loss=loss, \n",
    "                                               metrics=metrics,\n",
    "                                               step=step, \n",
    "                                               epoch=epoch, \n",
    "                                               device=device)\n",
    "        \n",
    "            if pseudo_loss is not None:\n",
    "                pseudo_loss = backward_step(loss=pseudo_loss, optimizer=optimizer, scaler=scaler)\n",
    "            \n",
    "    if gradient_norm > 0:\n",
    "        if scaler is not None:\n",
    "            scaler.unscale_(optimizer)\n",
    "                            \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=gradient_norm)\n",
    "        \n",
    "    return loss.detach(), metrics\n",
    "\n",
    "def backward_step(loss, optimizer, scaler=None):\n",
    "    if scaler is not None:\n",
    "        scaler.scale(loss).backward()\n",
    "    else:\n",
    "        loss.backward()\n",
    "        \n",
    "    return loss\n",
    "        \n",
    "\n",
    "def optimization_step(model, optimizer, scaler=None):                        \n",
    "    if scaler is not None:\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "    else:\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.zero_grad()\n",
    "        \n",
    "\n",
    "def scheduling_step(scheduler=None, loss=None, loop=\"training\"):\n",
    "    if scheduler is not None:\n",
    "        if loop == \"validation\":\n",
    "            if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau):\n",
    "                scheduler.step(loss)\n",
    "        else:\n",
    "            if not isinstance(scheduler, lr_scheduler.ReduceLROnPlateau):\n",
    "                scheduler.step()\n",
    "\n",
    "                \n",
    "def adversarial_step(batch, \n",
    "                     model, \n",
    "                     device=\"cpu\", \n",
    "                     loss=None, \n",
    "                     metrics=None, \n",
    "                     step=None, \n",
    "                     epoch=None):\n",
    "    pass\n",
    "\n",
    "                \n",
    "    \n",
    "def calculate_loss(batch, model, return_outputs=True, device=\"cpu\"):\n",
    "    raise NotImplementedError(f\"`calculate_loss` function is not implemented.\")\n",
    "                \n",
    "def calculate_metrics(predictions, targets, device=\"cpu\"):\n",
    "    return dict()\n",
    "\n",
    "def get_targets(batch):\n",
    "    return []\n",
    "\n",
    "\n",
    "def on_epoch_end(model=None, step=None, epoch=None):\n",
    "    pass\n",
    "\n",
    "\n",
    "def model_checkpointing(loss, \n",
    "                        metrics, \n",
    "                        model, \n",
    "                        optimizer=None, \n",
    "                        scheduler=None, \n",
    "                        step=None, \n",
    "                        best_loss=None, \n",
    "                        best_metrics=None):\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "def pseudo_labeling_step(batch, \n",
    "                         pseudo_batch, \n",
    "                         model, \n",
    "                         teacher_model, \n",
    "                         loss=None, \n",
    "                         metrics=None, \n",
    "                         step=None, \n",
    "                         epoch=None, \n",
    "                         device=\"cpu\"):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1daf23c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T18:43:16.258803Z",
     "iopub.status.busy": "2022-06-05T18:43:16.258230Z",
     "iopub.status.idle": "2022-06-05T18:43:16.261522Z",
     "shell.execute_reply": "2022-06-05T18:43:16.261919Z",
     "shell.execute_reply.started": "2022-06-05T18:42:40.583961Z"
    },
    "papermill": {
     "duration": 0.033641,
     "end_time": "2022-06-05T18:43:16.262040",
     "exception": false,
     "start_time": "2022-06-05T18:43:16.228399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_loss(batch, model, return_outputs=True, device=\"cpu\"):\n",
    "    input_ids, attention_mask, targets = batch\n",
    "    \n",
    "    input_ids = input_ids.to(device).long()\n",
    "    attention_mask = attention_mask.to(device).long()\n",
    "    targets = targets.to(device).float()\n",
    "    \n",
    "    outputs = model(input_ids, attention_mask)\n",
    "    outputs = outputs.sigmoid().squeeze(dim=-1)\n",
    "    loss = F.mse_loss(outputs, targets, reduction=\"mean\")\n",
    "    \n",
    "    return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "def calculate_metrics(predictions, targets, device=\"cpu\"):\n",
    "    predictions = predictions.sigmoid().detach().view(-1).to(\"cpu\").float().numpy()\n",
    "    targets = targets.view(-1).to(\"cpu\").float().numpy()\n",
    "    \n",
    "    return dict(pearson=scipy.stats.pearsonr(predictions, targets)[0])\n",
    "\n",
    "\n",
    "def get_targets(batch):\n",
    "    *_, targets = batch\n",
    "    return targets\n",
    "\n",
    "\n",
    "def model_checkpointing(loss, \n",
    "                        metrics, \n",
    "                        model, \n",
    "                        optimizer=None, \n",
    "                        scheduler=None, \n",
    "                        step=None, \n",
    "                        best_loss=None, \n",
    "                        best_metrics=None):\n",
    "    \n",
    "    is_saved_checkpoint = model_checkpoint(value=metrics[\"pearson\"], \n",
    "                                           model=model, \n",
    "                                           optimizer=optimizer, \n",
    "                                           scheduler=scheduler, \n",
    "                                           step=step)\n",
    "    return is_saved_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbf9473",
   "metadata": {
    "papermill": {
     "duration": 0.021451,
     "end_time": "2022-06-05T18:43:16.305134",
     "exception": false,
     "start_time": "2022-06-05T18:43:16.283683",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "214779d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T18:43:16.358821Z",
     "iopub.status.busy": "2022-06-05T18:43:16.358024Z",
     "iopub.status.idle": "2022-06-05T18:43:16.359969Z",
     "shell.execute_reply": "2022-06-05T18:43:16.360333Z",
     "shell.execute_reply.started": "2022-06-05T18:42:40.598052Z"
    },
    "papermill": {
     "duration": 0.033939,
     "end_time": "2022-06-05T18:43:16.360529",
     "exception": false,
     "start_time": "2022-06-05T18:43:16.326590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DynamicPadding:\n",
    "    def __init__(self, tokenizer, max_length=None, padding=True, pad_to_multiple_of=None, return_tensors=\"pt\"):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.padding = padding\n",
    "        self.pad_to_multiple_of = pad_to_multiple_of\n",
    "        self.return_tensors = return_tensors\n",
    "    \n",
    "    def __call__(self, tokenized):\n",
    "        max_length = max(len(_[\"input_ids\"]) for _ in tokenized)\n",
    "        max_length = min(max_length, self.max_length) if self.max_length is not None else max_length\n",
    "                \n",
    "        padded = self.tokenizer.pad(encoded_inputs=tokenized,\n",
    "                                    max_length=max_length,\n",
    "                                    padding=self.padding, \n",
    "                                    pad_to_multiple_of=self.pad_to_multiple_of, \n",
    "                                    return_tensors=self.return_tensors)\n",
    "        \n",
    "        return padded\n",
    "    \n",
    "    \n",
    "    \n",
    "class Collator:\n",
    "    def __init__(self, return_targets=True, **kwargs):\n",
    "        self.dynamic_padding = DynamicPadding(**kwargs)\n",
    "        self.return_targets = return_targets\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        all_tokenized, all_targets = [], []\n",
    "        for sample in batch:\n",
    "            if self.return_targets:\n",
    "                tokenized, target = sample\n",
    "                all_targets.append(target)\n",
    "            else:\n",
    "                tokenized = sample\n",
    "                \n",
    "            all_tokenized.append(tokenized)\n",
    "        \n",
    "        tokenized = self.dynamic_padding(all_tokenized)\n",
    "        \n",
    "        input_ids = torch.tensor(tokenized.input_ids)\n",
    "        attention_mask = torch.tensor(tokenized.attention_mask)\n",
    "        \n",
    "        if self.return_targets:\n",
    "            all_targets = torch.tensor(all_targets)\n",
    "        \n",
    "            return input_ids, attention_mask, all_targets\n",
    "        \n",
    "        return input_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2d3616f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T18:43:16.412647Z",
     "iopub.status.busy": "2022-06-05T18:43:16.412052Z",
     "iopub.status.idle": "2022-06-05T18:43:16.414696Z",
     "shell.execute_reply": "2022-06-05T18:43:16.414276Z",
     "shell.execute_reply.started": "2022-06-05T18:42:40.611348Z"
    },
    "papermill": {
     "duration": 0.032049,
     "end_time": "2022-06-05T18:43:16.414824",
     "exception": false,
     "start_time": "2022-06-05T18:43:16.382775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, texts, pair_texts, tokenizer, contexts=None, sep=None, targets=None, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.pair_texts = pair_texts\n",
    "        self.contexts = contexts\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.sep = sep if sep is not None else self.tokenizer.sep_token\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.texts[index].lower()\n",
    "        pair_text = self.pair_texts[index].lower()\n",
    "        \n",
    "        if self.contexts is not None:\n",
    "            context = self.contexts[index].lower()\n",
    "            text = text + self.sep + context\n",
    "    \n",
    "        \n",
    "        tokenized = self.tokenizer(text=text, \n",
    "                                   text_pair=pair_text, \n",
    "                                   add_special_tokens=True,\n",
    "                                   #max_length=self.max_length,\n",
    "                                   #padding=\"max_length\",\n",
    "                                   #truncation=True,\n",
    "                                   return_attention_mask=True,\n",
    "                                   return_token_type_ids=False,\n",
    "                                   return_offsets_mapping=False)\n",
    "        \n",
    "        \n",
    "        if self.targets is not None:\n",
    "            target = self.targets[index]\n",
    "            \n",
    "            return tokenized, target\n",
    "            \n",
    "        return tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9c865d",
   "metadata": {
    "papermill": {
     "duration": 0.021377,
     "end_time": "2022-06-05T18:43:16.457660",
     "exception": false,
     "start_time": "2022-06-05T18:43:16.436283",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa18db35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T18:43:16.517738Z",
     "iopub.status.busy": "2022-06-05T18:43:16.516940Z",
     "iopub.status.idle": "2022-06-05T18:43:16.518804Z",
     "shell.execute_reply": "2022-06-05T18:43:16.519477Z",
     "shell.execute_reply.started": "2022-06-05T18:42:40.626151Z"
    },
    "papermill": {
     "duration": 0.040492,
     "end_time": "2022-06-05T18:43:16.519595",
     "exception": false,
     "start_time": "2022-06-05T18:43:16.479103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, model_path=\"microsoft/deberta-large\", config_path=None, config_updates={}, reinitialization_layers=0, mixout=0.0):\n",
    "        super(Model, self).__init__()\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(model_path)\n",
    "        else:\n",
    "            self.config = AutoConfig.from_pretrained(config_path)\n",
    "        \n",
    "        self.config.output_hidden_states = True\n",
    "        self.config.update(config_updates)\n",
    "        \n",
    "        if config_path is None:\n",
    "            self.model = AutoModel.from_pretrained(model_path, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel.from_config(self.config)\n",
    "        \n",
    "        self.model.gradient_checkpointing_enable()\n",
    "        print(f\"Gradient Checkpointing: {self.model.is_gradient_checkpointing}\")\n",
    "        \n",
    "        if mixout > 0:\n",
    "            for module in self.model.modules():\n",
    "                for name, submodule in module.named_children():\n",
    "                    if isinstance(submodule, nn.Dropout):\n",
    "                        module.p = 0.0\n",
    "                    if isinstance(submodule, nn.Linear):\n",
    "                        target_state_dict = submodule.state_dict()\n",
    "                        bias = True if submodule.bias is not None else False\n",
    "                        \n",
    "                        new_module = MixLinear(in_features=submodule.in_features, \n",
    "                                               out_features=submodule.out_features, \n",
    "                                               bias=bias, \n",
    "                                               target=target_state_dict[\"weight\"], \n",
    "                                               p=mixout)\n",
    "                        \n",
    "                        new_module.load_state_dict(target_state_dict)\n",
    "                        setattr(module, name, new_module)\n",
    "                \n",
    "            print(f\"Initialized Mixout (p={mixout}) Regularization\")\n",
    "        \n",
    "        if reinitialization_layers > 0:\n",
    "            layers = ...\n",
    "            for layer in layers[-reinitialization_layers:]:\n",
    "                for name, module in layer.named_modules():\n",
    "                    self.init_weights(module, std=self.config.initializer_range)\n",
    "            \n",
    "            print(f\"Reinitializated last {n} layers.\")\n",
    "\n",
    "        self.head = nn.Linear(in_features=self.config.hidden_size, out_features=1)\n",
    "        self.init_weights(self.head, std=self.config.initializer_range)\n",
    "            \n",
    "    \n",
    "    def init_weights(self, module, std=0.02):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=std)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=std)\n",
    "            if module.padding_idx is not None:\n",
    "                 module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "    \n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        transformer_outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        features = transformer_outputs.hidden_states[-1]\n",
    "        features = features[:, 0, :]\n",
    "        outputs = self.head(features)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c0eb6c",
   "metadata": {
    "papermill": {
     "duration": 0.021508,
     "end_time": "2022-06-05T18:43:16.562463",
     "exception": false,
     "start_time": "2022-06-05T18:43:16.540955",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "068ff2f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T18:43:16.609451Z",
     "iopub.status.busy": "2022-06-05T18:43:16.608824Z",
     "iopub.status.idle": "2022-06-05T18:43:16.611411Z",
     "shell.execute_reply": "2022-06-05T18:43:16.610989Z",
     "shell.execute_reply.started": "2022-06-05T18:42:40.645371Z"
    },
    "papermill": {
     "duration": 0.027547,
     "end_time": "2022-06-05T18:43:16.611510",
     "exception": false,
     "start_time": "2022-06-05T18:43:16.583963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = \"../input/us-patent-phrase-to-phrase-matching/train.csv\"\n",
    "test_path = \"../input/us-patent-phrase-to-phrase-matching/test.csv\"\n",
    "sample_submission_path = \"../input/us-patent-phrase-to-phrase-matching/sample_submission.csv\"\n",
    "cpc_codes_path = \"../input/cpc-codes/titles.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc52f4dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T18:43:16.657372Z",
     "iopub.status.busy": "2022-06-05T18:43:16.656592Z",
     "iopub.status.idle": "2022-06-05T18:43:17.580082Z",
     "shell.execute_reply": "2022-06-05T18:43:17.580530Z",
     "shell.execute_reply.started": "2022-06-05T18:42:40.655704Z"
    },
    "papermill": {
     "duration": 0.947731,
     "end_time": "2022-06-05T18:43:17.580671",
     "exception": false,
     "start_time": "2022-06-05T18:43:16.632940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "      <th>code</th>\n",
       "      <th>title</th>\n",
       "      <th>section</th>\n",
       "      <th>class</th>\n",
       "      <th>subclass</th>\n",
       "      <th>group</th>\n",
       "      <th>main_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>abatement</td>\n",
       "      <td>abatement of pollution</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>A47</td>\n",
       "      <td>FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...</td>\n",
       "      <td>A</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7b9652b17b68b7a4</td>\n",
       "      <td>abatement</td>\n",
       "      <td>act of abating</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.75</td>\n",
       "      <td>A47</td>\n",
       "      <td>FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...</td>\n",
       "      <td>A</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36d72442aefd8232</td>\n",
       "      <td>abatement</td>\n",
       "      <td>active catalyst</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "      <td>A47</td>\n",
       "      <td>FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...</td>\n",
       "      <td>A</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5296b0c19e1ce60e</td>\n",
       "      <td>abatement</td>\n",
       "      <td>eliminating process</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>A47</td>\n",
       "      <td>FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...</td>\n",
       "      <td>A</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54c1e3b9184cb5b6</td>\n",
       "      <td>abatement</td>\n",
       "      <td>forest region</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>A47</td>\n",
       "      <td>FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...</td>\n",
       "      <td>A</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36468</th>\n",
       "      <td>718f1c6953e3942f</td>\n",
       "      <td>undulation</td>\n",
       "      <td>undulatory swimmers</td>\n",
       "      <td>B31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>B31</td>\n",
       "      <td>MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...</td>\n",
       "      <td>B</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36469</th>\n",
       "      <td>4dc407e6d0aa7844</td>\n",
       "      <td>undulation</td>\n",
       "      <td>voltage fluctuate</td>\n",
       "      <td>B31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>B31</td>\n",
       "      <td>MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...</td>\n",
       "      <td>B</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36470</th>\n",
       "      <td>de69548ad79caccc</td>\n",
       "      <td>web transfer</td>\n",
       "      <td>transfer from web</td>\n",
       "      <td>B31</td>\n",
       "      <td>0.75</td>\n",
       "      <td>B31</td>\n",
       "      <td>MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...</td>\n",
       "      <td>B</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36471</th>\n",
       "      <td>6620317413e6e03f</td>\n",
       "      <td>web transfer</td>\n",
       "      <td>transfer to web</td>\n",
       "      <td>B31</td>\n",
       "      <td>0.25</td>\n",
       "      <td>B31</td>\n",
       "      <td>MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...</td>\n",
       "      <td>B</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36472</th>\n",
       "      <td>96946de83b530746</td>\n",
       "      <td>web transfer</td>\n",
       "      <td>transfer web</td>\n",
       "      <td>B31</td>\n",
       "      <td>0.75</td>\n",
       "      <td>B31</td>\n",
       "      <td>MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...</td>\n",
       "      <td>B</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36473 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id        anchor                  target context  score  \\\n",
       "0      37d61fd2272659b1     abatement  abatement of pollution     A47   0.50   \n",
       "1      7b9652b17b68b7a4     abatement          act of abating     A47   0.75   \n",
       "2      36d72442aefd8232     abatement         active catalyst     A47   0.25   \n",
       "3      5296b0c19e1ce60e     abatement     eliminating process     A47   0.50   \n",
       "4      54c1e3b9184cb5b6     abatement           forest region     A47   0.00   \n",
       "...                 ...           ...                     ...     ...    ...   \n",
       "36468  718f1c6953e3942f    undulation     undulatory swimmers     B31   0.00   \n",
       "36469  4dc407e6d0aa7844    undulation       voltage fluctuate     B31   0.00   \n",
       "36470  de69548ad79caccc  web transfer       transfer from web     B31   0.75   \n",
       "36471  6620317413e6e03f  web transfer         transfer to web     B31   0.25   \n",
       "36472  96946de83b530746  web transfer            transfer web     B31   0.75   \n",
       "\n",
       "      code                                              title section  class  \\\n",
       "0      A47  FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...       A   47.0   \n",
       "1      A47  FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...       A   47.0   \n",
       "2      A47  FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...       A   47.0   \n",
       "3      A47  FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...       A   47.0   \n",
       "4      A47  FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...       A   47.0   \n",
       "...    ...                                                ...     ...    ...   \n",
       "36468  B31  MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...       B   31.0   \n",
       "36469  B31  MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...       B   31.0   \n",
       "36470  B31  MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...       B   31.0   \n",
       "36471  B31  MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...       B   31.0   \n",
       "36472  B31  MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...       B   31.0   \n",
       "\n",
       "      subclass  group  main_group  \n",
       "0          NaN    NaN         NaN  \n",
       "1          NaN    NaN         NaN  \n",
       "2          NaN    NaN         NaN  \n",
       "3          NaN    NaN         NaN  \n",
       "4          NaN    NaN         NaN  \n",
       "...        ...    ...         ...  \n",
       "36468      NaN    NaN         NaN  \n",
       "36469      NaN    NaN         NaN  \n",
       "36470      NaN    NaN         NaN  \n",
       "36471      NaN    NaN         NaN  \n",
       "36472      NaN    NaN         NaN  \n",
       "\n",
       "[36473 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cpc_codes = pd.read_csv(cpc_codes_path)\n",
    "train = pd.read_csv(train_path)\n",
    "train = train.merge(cpc_codes, left_on=\"context\", right_on=\"code\")\n",
    "\n",
    "if DEBUG:\n",
    "    display(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66ffad85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T18:43:17.630078Z",
     "iopub.status.busy": "2022-06-05T18:43:17.629449Z",
     "iopub.status.idle": "2022-06-05T18:43:17.684526Z",
     "shell.execute_reply": "2022-06-05T18:43:17.684073Z",
     "shell.execute_reply.started": "2022-06-05T18:42:41.544015Z"
    },
    "papermill": {
     "duration": 0.08146,
     "end_time": "2022-06-05T18:43:17.684646",
     "exception": false,
     "start_time": "2022-06-05T18:43:17.603186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cpc_texts = torch.load(\"../input/foldsdump/cpc_texts_fixed.pth\")\n",
    "train['context_text'] = train['context'].map(cpc_texts)\n",
    "train['text'] = train['anchor'] + '[SEP]' + train['target'] + '[SEP]'  + train['context_text']\n",
    "train['text'] = train['text'].apply(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "514b97f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T18:43:17.746719Z",
     "iopub.status.busy": "2022-06-05T18:43:17.745913Z",
     "iopub.status.idle": "2022-06-05T18:43:17.758252Z",
     "shell.execute_reply": "2022-06-05T18:43:17.757819Z",
     "shell.execute_reply.started": "2022-06-05T18:42:41.605963Z"
    },
    "papermill": {
     "duration": 0.051009,
     "end_time": "2022-06-05T18:43:17.758358",
     "exception": false,
     "start_time": "2022-06-05T18:43:17.707349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "      <th>code</th>\n",
       "      <th>title</th>\n",
       "      <th>section</th>\n",
       "      <th>class</th>\n",
       "      <th>subclass</th>\n",
       "      <th>group</th>\n",
       "      <th>main_group</th>\n",
       "      <th>context_text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>abatement</td>\n",
       "      <td>abatement of pollution</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>A47</td>\n",
       "      <td>FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...</td>\n",
       "      <td>A</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
       "      <td>abatement[sep]abatement of pollution[sep]human...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7b9652b17b68b7a4</td>\n",
       "      <td>abatement</td>\n",
       "      <td>act of abating</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.75</td>\n",
       "      <td>A47</td>\n",
       "      <td>FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...</td>\n",
       "      <td>A</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
       "      <td>abatement[sep]act of abating[sep]human necessi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36d72442aefd8232</td>\n",
       "      <td>abatement</td>\n",
       "      <td>active catalyst</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "      <td>A47</td>\n",
       "      <td>FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...</td>\n",
       "      <td>A</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
       "      <td>abatement[sep]active catalyst[sep]human necess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5296b0c19e1ce60e</td>\n",
       "      <td>abatement</td>\n",
       "      <td>eliminating process</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>A47</td>\n",
       "      <td>FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...</td>\n",
       "      <td>A</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
       "      <td>abatement[sep]eliminating process[sep]human ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54c1e3b9184cb5b6</td>\n",
       "      <td>abatement</td>\n",
       "      <td>forest region</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>A47</td>\n",
       "      <td>FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...</td>\n",
       "      <td>A</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
       "      <td>abatement[sep]forest region[sep]human necessit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36468</th>\n",
       "      <td>718f1c6953e3942f</td>\n",
       "      <td>undulation</td>\n",
       "      <td>undulatory swimmers</td>\n",
       "      <td>B31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>B31</td>\n",
       "      <td>MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...</td>\n",
       "      <td>B</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PERFORMING OPERATIONS; TRANSPORTING. MAKING AR...</td>\n",
       "      <td>undulation[sep]undulatory swimmers[sep]perform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36469</th>\n",
       "      <td>4dc407e6d0aa7844</td>\n",
       "      <td>undulation</td>\n",
       "      <td>voltage fluctuate</td>\n",
       "      <td>B31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>B31</td>\n",
       "      <td>MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...</td>\n",
       "      <td>B</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PERFORMING OPERATIONS; TRANSPORTING. MAKING AR...</td>\n",
       "      <td>undulation[sep]voltage fluctuate[sep]performin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36470</th>\n",
       "      <td>de69548ad79caccc</td>\n",
       "      <td>web transfer</td>\n",
       "      <td>transfer from web</td>\n",
       "      <td>B31</td>\n",
       "      <td>0.75</td>\n",
       "      <td>B31</td>\n",
       "      <td>MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...</td>\n",
       "      <td>B</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PERFORMING OPERATIONS; TRANSPORTING. MAKING AR...</td>\n",
       "      <td>web transfer[sep]transfer from web[sep]perform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36471</th>\n",
       "      <td>6620317413e6e03f</td>\n",
       "      <td>web transfer</td>\n",
       "      <td>transfer to web</td>\n",
       "      <td>B31</td>\n",
       "      <td>0.25</td>\n",
       "      <td>B31</td>\n",
       "      <td>MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...</td>\n",
       "      <td>B</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PERFORMING OPERATIONS; TRANSPORTING. MAKING AR...</td>\n",
       "      <td>web transfer[sep]transfer to web[sep]performin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36472</th>\n",
       "      <td>96946de83b530746</td>\n",
       "      <td>web transfer</td>\n",
       "      <td>transfer web</td>\n",
       "      <td>B31</td>\n",
       "      <td>0.75</td>\n",
       "      <td>B31</td>\n",
       "      <td>MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...</td>\n",
       "      <td>B</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PERFORMING OPERATIONS; TRANSPORTING. MAKING AR...</td>\n",
       "      <td>web transfer[sep]transfer web[sep]performing o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36473 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id        anchor                  target context  score  \\\n",
       "0      37d61fd2272659b1     abatement  abatement of pollution     A47   0.50   \n",
       "1      7b9652b17b68b7a4     abatement          act of abating     A47   0.75   \n",
       "2      36d72442aefd8232     abatement         active catalyst     A47   0.25   \n",
       "3      5296b0c19e1ce60e     abatement     eliminating process     A47   0.50   \n",
       "4      54c1e3b9184cb5b6     abatement           forest region     A47   0.00   \n",
       "...                 ...           ...                     ...     ...    ...   \n",
       "36468  718f1c6953e3942f    undulation     undulatory swimmers     B31   0.00   \n",
       "36469  4dc407e6d0aa7844    undulation       voltage fluctuate     B31   0.00   \n",
       "36470  de69548ad79caccc  web transfer       transfer from web     B31   0.75   \n",
       "36471  6620317413e6e03f  web transfer         transfer to web     B31   0.25   \n",
       "36472  96946de83b530746  web transfer            transfer web     B31   0.75   \n",
       "\n",
       "      code                                              title section  class  \\\n",
       "0      A47  FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...       A   47.0   \n",
       "1      A47  FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...       A   47.0   \n",
       "2      A47  FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...       A   47.0   \n",
       "3      A47  FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...       A   47.0   \n",
       "4      A47  FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...       A   47.0   \n",
       "...    ...                                                ...     ...    ...   \n",
       "36468  B31  MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...       B   31.0   \n",
       "36469  B31  MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...       B   31.0   \n",
       "36470  B31  MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...       B   31.0   \n",
       "36471  B31  MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...       B   31.0   \n",
       "36472  B31  MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...       B   31.0   \n",
       "\n",
       "      subclass  group  main_group  \\\n",
       "0          NaN    NaN         NaN   \n",
       "1          NaN    NaN         NaN   \n",
       "2          NaN    NaN         NaN   \n",
       "3          NaN    NaN         NaN   \n",
       "4          NaN    NaN         NaN   \n",
       "...        ...    ...         ...   \n",
       "36468      NaN    NaN         NaN   \n",
       "36469      NaN    NaN         NaN   \n",
       "36470      NaN    NaN         NaN   \n",
       "36471      NaN    NaN         NaN   \n",
       "36472      NaN    NaN         NaN   \n",
       "\n",
       "                                            context_text  \\\n",
       "0      HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...   \n",
       "1      HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...   \n",
       "2      HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...   \n",
       "3      HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...   \n",
       "4      HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...   \n",
       "...                                                  ...   \n",
       "36468  PERFORMING OPERATIONS; TRANSPORTING. MAKING AR...   \n",
       "36469  PERFORMING OPERATIONS; TRANSPORTING. MAKING AR...   \n",
       "36470  PERFORMING OPERATIONS; TRANSPORTING. MAKING AR...   \n",
       "36471  PERFORMING OPERATIONS; TRANSPORTING. MAKING AR...   \n",
       "36472  PERFORMING OPERATIONS; TRANSPORTING. MAKING AR...   \n",
       "\n",
       "                                                    text  \n",
       "0      abatement[sep]abatement of pollution[sep]human...  \n",
       "1      abatement[sep]act of abating[sep]human necessi...  \n",
       "2      abatement[sep]active catalyst[sep]human necess...  \n",
       "3      abatement[sep]eliminating process[sep]human ne...  \n",
       "4      abatement[sep]forest region[sep]human necessit...  \n",
       "...                                                  ...  \n",
       "36468  undulation[sep]undulatory swimmers[sep]perform...  \n",
       "36469  undulation[sep]voltage fluctuate[sep]performin...  \n",
       "36470  web transfer[sep]transfer from web[sep]perform...  \n",
       "36471  web transfer[sep]transfer to web[sep]performin...  \n",
       "36472  web transfer[sep]transfer web[sep]performing o...  \n",
       "\n",
       "[36473 rows x 14 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb629e2",
   "metadata": {
    "papermill": {
     "duration": 0.022942,
     "end_time": "2022-06-05T18:43:17.804302",
     "exception": false,
     "start_time": "2022-06-05T18:43:17.781360",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cross-Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "895b7341",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T18:43:17.856890Z",
     "iopub.status.busy": "2022-06-05T18:43:17.855014Z",
     "iopub.status.idle": "2022-06-05T18:43:30.402026Z",
     "shell.execute_reply": "2022-06-05T18:43:30.401523Z"
    },
    "papermill": {
     "duration": 12.574937,
     "end_time": "2022-06-05T18:43:30.402173",
     "exception": false,
     "start_time": "2022-06-05T18:43:17.827236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold\n",
       "1    9119\n",
       "2    9118\n",
       "3    9118\n",
       "4    9118\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train[\"score_bin\"] = pd.cut(train[\"score\"], bins=4, labels=False)\n",
    "train = create_folds(data_frame=train, \n",
    "                     targets=train[\"score_bin\"].values,\n",
    "                     groups=train[\"text\"].values,\n",
    "                     folds=config.folds, \n",
    "                     seed=config.seed, \n",
    "                     shuffle=True)\n",
    "\n",
    "if DEBUG:\n",
    "    folds_samples_count = train.groupby(\"fold\").size()\n",
    "    display(folds_samples_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240f0edb",
   "metadata": {
    "papermill": {
     "duration": 0.023637,
     "end_time": "2022-06-05T18:43:30.452041",
     "exception": false,
     "start_time": "2022-06-05T18:43:30.428404",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36bfed9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T18:43:30.504578Z",
     "iopub.status.busy": "2022-06-05T18:43:30.503844Z",
     "iopub.status.idle": "2022-06-05T18:43:37.764586Z",
     "shell.execute_reply": "2022-06-05T18:43:37.764104Z"
    },
    "papermill": {
     "duration": 7.28888,
     "end_time": "2022-06-05T18:43:37.764733",
     "exception": false,
     "start_time": "2022-06-05T18:43:30.475853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070b9e459d5e42c890a0ddca039c6b1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13db8a20295947ed8b2841228541540c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/580 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "024cb3356abf449a8346145acde368e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.35M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer: PreTrainedTokenizerFast(name_or_path='microsoft/deberta-v3-large', vocab_size=128000, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config.model.model_path)\n",
    "tokenizer_path = os.path.join(config.output_directory, \"tokenizer/\")\n",
    "tokenizer_files = tokenizer.save_pretrained(tokenizer_path)\n",
    "\n",
    "if DEBUG:\n",
    "    print(f\"Tokenizer: {tokenizer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84733b2a",
   "metadata": {
    "papermill": {
     "duration": 0.028901,
     "end_time": "2022-06-05T18:43:37.822923",
     "exception": false,
     "start_time": "2022-06-05T18:43:37.794022",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d90c6b8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T18:43:37.906422Z",
     "iopub.status.busy": "2022-06-05T18:43:37.905630Z",
     "iopub.status.idle": "2022-06-06T01:59:44.406580Z",
     "shell.execute_reply": "2022-06-06T01:59:44.407007Z"
    },
    "papermill": {
     "duration": 26166.555126,
     "end_time": "2022-06-06T01:59:44.407175",
     "exception": false,
     "start_time": "2022-06-05T18:43:37.852049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/4\n",
      "\n",
      "Train samples: 27354\n",
      "Validation samples: 9119\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c726d26e5fd4906b9dcf605b765b21a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/833M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Checkpointing: True\n",
      "Epochs: 5\n",
      "Auto Mixed Precision: True\n",
      "Gradient norm: 1.0\n",
      "Gradient scaling: True\n",
      "Gradient accumulation steps: 1\n",
      "Validation steps: 200\n",
      "Device: cuda\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "\n",
      "100/1710 - remain: 0:14:8 - loss: 0.07203 - pearson: 0.07073 - lr: 1.1578947368421053e-06\n",
      "200/1710 - remain: 0:12:54 - loss: 0.06662 - pearson: 0.1527 - lr: 2.3274853801169592e-06\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.05449 - pearson: 0.4747\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.05668 - pearson: 0.4625\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.05746 - pearson: 0.4191\n",
      "'best_value' is improved by inf! New 'best_value': 0.41909209180835155. Checkpoint path: './fold_1/checkpoints/checkpoint.pth'.\n",
      "\n",
      "300/1710 - remain: 0:16:31 - loss: 0.06206 - pearson: 0.2426 - lr: 3.497076023391813e-06\n",
      "400/1710 - remain: 0:14:15 - loss: 0.05831 - pearson: 0.3277 - lr: 4.666666666666667e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.03665 - pearson: 0.6976\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.03762 - pearson: 0.6894\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.03912 - pearson: 0.6787\n",
      "'best_value' is improved by 0.2595949151005665! New 'best_value': 0.678687006908918. Checkpoint path: './fold_1/checkpoints/checkpoint.pth'.\n",
      "\n",
      "500/1710 - remain: 0:14:55 - loss: 0.05419 - pearson: 0.3893 - lr: 5.836257309941521e-06\n",
      "600/1710 - remain: 0:12:56 - loss: 0.05108 - pearson: 0.439 - lr: 7.005847953216375e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.03006 - pearson: 0.752\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.03039 - pearson: 0.7503\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.03117 - pearson: 0.7463\n",
      "'best_value' is improved by 0.06761724119821999! New 'best_value': 0.746304248107138. Checkpoint path: './fold_1/checkpoints/checkpoint.pth'.\n",
      "\n",
      "700/1710 - remain: 0:12:49 - loss: 0.04861 - pearson: 0.4781 - lr: 8.175438596491229e-06\n",
      "800/1710 - remain: 0:11:4 - loss: 0.04641 - pearson: 0.5113 - lr: 9.345029239766083e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.02808 - pearson: 0.7752\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.02781 - pearson: 0.7784\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.0283 - pearson: 0.7879\n",
      "'best_value' is improved by 0.04160309499543724! New 'best_value': 0.7879073431025753. Checkpoint path: './fold_1/checkpoints/checkpoint.pth'.\n",
      "\n",
      "900/1710 - remain: 0:10:29 - loss: 0.04439 - pearson: 0.5371 - lr: 9.99677342967605e-06\n",
      "1000/1710 - remain: 0:8:52 - loss: 0.04276 - pearson: 0.5578 - lr: 9.965477115326678e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.02388 - pearson: 0.7931\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.02336 - pearson: 0.7993\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02389 - pearson: 0.8063\n",
      "'best_value' is improved by 0.018424948996729862! New 'best_value': 0.8063322920993051. Checkpoint path: './fold_1/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1100/1710 - remain: 0:7:59 - loss: 0.04135 - pearson: 0.5766 - lr: 9.901093437208395e-06\n",
      "1200/1710 - remain: 0:6:28 - loss: 0.04004 - pearson: 0.5947 - lr: 9.804051414754617e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.02433 - pearson: 0.8147\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.02378 - pearson: 0.8169\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02446 - pearson: 0.8214\n",
      "'best_value' is improved by 0.015038563769497193! New 'best_value': 0.8213708558688023. Checkpoint path: './fold_1/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1300/1710 - remain: 0:5:25 - loss: 0.0388 - pearson: 0.6087 - lr: 9.67499768566465e-06\n",
      "1400/1710 - remain: 0:3:59 - loss: 0.03788 - pearson: 0.6217 - lr: 9.51479219704548e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.0214 - pearson: 0.8166\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.02098 - pearson: 0.8206\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02167 - pearson: 0.8245\n",
      "'best_value' is improved by 0.003158875070725431! New 'best_value': 0.8245297309395277. Checkpoint path: './fold_1/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1500/1710 - remain: 0:2:47 - loss: 0.03692 - pearson: 0.6334 - lr: 9.324502475170332e-06\n",
      "1600/1710 - remain: 0:1:25 - loss: 0.03617 - pearson: 0.6428 - lr: 9.10539651203735e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.0222 - pearson: 0.8238\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.02158 - pearson: 0.8269\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02221 - pearson: 0.8297\n",
      "'best_value' is improved by 0.005178416772310568! New 'best_value': 0.8297081477118383. Checkpoint path: './fold_1/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1700/1710 - remain: 0:0:7 - loss: 0.03537 - pearson: 0.6526 - lr: 8.85893431612864e-06\n",
      "1710/1710 - remain: 0:0:0 - loss: 0.03526 - pearson: 0.654 - lr: 8.832845209850547e-06\n",
      "\n",
      "Training loss: 0.03526 - pearson: 0.654\n",
      "Validation loss: 0.02221 - pearson: 0.8297\n",
      "Total time: 0:22:34\n",
      "\n",
      "Epoch 2/5\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01982 - pearson: 0.8348\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01996 - pearson: 0.8348\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02075 - pearson: 0.8391\n",
      "'best_value' is improved by 0.009353027453530616! New 'best_value': 0.8390611751653689. Checkpoint path: './fold_1/checkpoints/checkpoint.pth'.\n",
      "\n",
      "100/1710 - remain: 0:29:24 - loss: 0.01868 - pearson: 0.8286 - lr: 8.558194707848636e-06\n",
      "200/1710 - remain: 0:19:59 - loss: 0.01857 - pearson: 0.8391 - lr: 8.2598342420457e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.02196 - pearson: 0.831\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.02157 - pearson: 0.8317\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02231 - pearson: 0.8352\n",
      "\n",
      "300/1710 - remain: 0:19:44 - loss: 0.01862 - pearson: 0.8401 - lr: 7.939751931818186e-06\n",
      "400/1710 - remain: 0:16:27 - loss: 0.01864 - pearson: 0.8399 - lr: 7.600080639646077e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.02004 - pearson: 0.8354\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01977 - pearson: 0.8366\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02062 - pearson: 0.8404\n",
      "'best_value' is improved by 0.0012934424703151537! New 'best_value': 0.8403546176356841. Checkpoint path: './fold_1/checkpoints/checkpoint.pth'.\n",
      "\n",
      "500/1710 - remain: 0:16:35 - loss: 0.01845 - pearson: 0.8426 - lr: 7.243083758823699e-06\n",
      "600/1710 - remain: 0:14:13 - loss: 0.01822 - pearson: 0.8447 - lr: 6.871140131380888e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.02097 - pearson: 0.8419\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.02077 - pearson: 0.842\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02154 - pearson: 0.8451\n",
      "'best_value' is improved by 0.004725246856651988! New 'best_value': 0.8450798644923361. Checkpoint path: './fold_1/checkpoints/checkpoint.pth'.\n",
      "\n",
      "700/1710 - remain: 0:13:42 - loss: 0.01798 - pearson: 0.8465 - lr: 6.486728196713679e-06\n",
      "800/1710 - remain: 0:11:44 - loss: 0.01789 - pearson: 0.8486 - lr: 6.0924094765497985e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01888 - pearson: 0.8439\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01889 - pearson: 0.8437\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01953 - pearson: 0.8488\n",
      "'best_value' is improved by 0.0037177628544262653! New 'best_value': 0.8487976273467623. Checkpoint path: './fold_1/checkpoints/checkpoint.pth'.\n",
      "\n",
      "900/1710 - remain: 0:10:56 - loss: 0.01789 - pearson: 0.8481 - lr: 5.690811506296609e-06\n",
      "1000/1710 - remain: 0:9:12 - loss: 0.01771 - pearson: 0.85 - lr: 5.284610326508117e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01834 - pearson: 0.846\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01803 - pearson: 0.8484\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01877 - pearson: 0.8528\n",
      "'best_value' is improved by 0.004033754436451487! New 'best_value': 0.8528313817832138. Checkpoint path: './fold_1/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1100/1710 - remain: 0:8:13 - loss: 0.01762 - pearson: 0.8512 - lr: 4.87651265113887e-06\n",
      "1200/1710 - remain: 0:6:39 - loss: 0.01758 - pearson: 0.8522 - lr: 4.469237831406198e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01819 - pearson: 0.8443\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01831 - pearson: 0.844\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01898 - pearson: 0.8497\n",
      "\n",
      "1300/1710 - remain: 0:5:26 - loss: 0.01758 - pearson: 0.8519 - lr: 4.065499735444305e-06\n",
      "1400/1710 - remain: 0:3:59 - loss: 0.01761 - pearson: 0.8518 - lr: 3.667988664494785e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01738 - pearson: 0.8527\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01752 - pearson: 0.8522\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01824 - pearson: 0.8567\n",
      "'best_value' is improved by 0.003853784945832106! New 'best_value': 0.8566851667290459. Checkpoint path: './fold_1/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1500/1710 - remain: 0:2:46 - loss: 0.01754 - pearson: 0.8521 - lr: 3.279353426134673e-06\n",
      "1600/1710 - remain: 0:1:25 - loss: 0.01744 - pearson: 0.8531 - lr: 2.9021836839967644e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01669 - pearson: 0.8573\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01668 - pearson: 0.8572\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01735 - pearson: 0.8627\n",
      "'best_value' is improved by 0.006053764330415934! New 'best_value': 0.8627389310594619. Checkpoint path: './fold_1/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1700/1710 - remain: 0:0:7 - loss: 0.0173 - pearson: 0.8543 - lr: 2.5389927015944937e-06\n",
      "1710/1710 - remain: 0:0:0 - loss: 0.0173 - pearson: 0.8542 - lr: 2.5035365042804726e-06\n",
      "\n",
      "Training loss: 0.0173 - pearson: 0.8542\n",
      "Validation loss: 0.01735 - pearson: 0.8627\n",
      "Total time: 0:45:13\n",
      "\n",
      "Epoch 3/5\n",
      "\n",
      "100/1710 - remain: 0:13:29 - loss: 0.01169 - pearson: 0.9029 - lr: 2.158513320853839e-06\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01702 - pearson: 0.8564\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01697 - pearson: 0.8567\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01758 - pearson: 0.8622\n",
      "\n",
      "200/1710 - remain: 0:18:2 - loss: 0.01156 - pearson: 0.9039 - lr: 1.8324243307008454e-06\n",
      "300/1710 - remain: 0:15:9 - loss: 0.01184 - pearson: 0.9023 - lr: 1.5274424217006701e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01735 - pearson: 0.8569\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.0174 - pearson: 0.8563\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.018 - pearson: 0.8613\n",
      "\n",
      "400/1710 - remain: 0:15:40 - loss: 0.0117 - pearson: 0.904 - lr: 1.2455998350925042e-06\n",
      "500/1710 - remain: 0:13:35 - loss: 0.01159 - pearson: 0.9052 - lr: 9.88774623674112e-07\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01674 - pearson: 0.8585\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01686 - pearson: 0.8575\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01748 - pearson: 0.8626\n",
      "\n",
      "600/1710 - remain: 0:13:16 - loss: 0.01156 - pearson: 0.9045 - lr: 7.586781374321844e-07\n",
      "700/1710 - remain: 0:11:33 - loss: 0.01152 - pearson: 0.9047 - lr: 5.568436199937521e-07\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01661 - pearson: 0.8592\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01675 - pearson: 0.8581\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01738 - pearson: 0.863\n",
      "'best_value' is improved by 0.0002993768564307775! New 'best_value': 0.8630383079158926. Checkpoint path: './fold_1/checkpoints/checkpoint.pth'.\n",
      "\n",
      "800/1710 - remain: 0:11:17 - loss: 0.01163 - pearson: 0.9033 - lr: 3.8461599188598707e-07\n",
      "900/1710 - remain: 0:9:41 - loss: 0.01168 - pearson: 0.9022 - lr: 2.431428886834575e-07\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01668 - pearson: 0.8593\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.0168 - pearson: 0.8582\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01744 - pearson: 0.8632\n",
      "'best_value' is improved by 0.0001255891051423763! New 'best_value': 0.863163897021035. Checkpoint path: './fold_1/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1000/1710 - remain: 0:9:0 - loss: 0.01161 - pearson: 0.9028 - lr: 1.333670137599713e-07\n",
      "1100/1710 - remain: 0:7:29 - loss: 0.01165 - pearson: 0.9017 - lr: 5.601985660229514e-08\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01671 - pearson: 0.8593\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01683 - pearson: 0.8582\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01747 - pearson: 0.8631\n",
      "\n",
      "1200/1710 - remain: 0:6:25 - loss: 0.0116 - pearson: 0.9026 - lr: 1.161681854366048e-08\n",
      "1300/1710 - remain: 0:5:1 - loss: 0.01161 - pearson: 0.9023 - lr: 9.99954622160337e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01799 - pearson: 0.8499\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01768 - pearson: 0.8526\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01838 - pearson: 0.8564\n",
      "\n",
      "1400/1710 - remain: 0:3:51 - loss: 0.01184 - pearson: 0.9015 - lr: 9.97739487912983e-06\n",
      "1500/1710 - remain: 0:2:33 - loss: 0.01197 - pearson: 0.9003 - lr: 9.922076759091456e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01889 - pearson: 0.8425\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01909 - pearson: 0.8406\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01988 - pearson: 0.8437\n",
      "\n",
      "1600/1710 - remain: 0:1:21 - loss: 0.01217 - pearson: 0.8982 - lr: 9.833960472745178e-06\n",
      "1700/1710 - remain: 0:0:7 - loss: 0.01235 - pearson: 0.8967 - lr: 9.713633181314904e-06\n",
      "1710/1710 - remain: 0:0:0 - loss: 0.01237 - pearson: 0.8964 - lr: 9.699857883137968e-06\n",
      "\n",
      "Training loss: 0.01237 - pearson: 0.8964\n",
      "Validation loss: 0.01744 - pearson: 0.8632\n",
      "Total time: 1:5:59\n",
      "\n",
      "Epoch 4/5\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01773 - pearson: 0.8507\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01783 - pearson: 0.8482\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01849 - pearson: 0.8532\n",
      "\n",
      "100/1710 - remain: 0:25:1 - loss: 0.01297 - pearson: 0.895 - lr: 9.545032675245814e-06\n",
      "200/1710 - remain: 0:17:57 - loss: 0.01268 - pearson: 0.8955 - lr: 9.35992172723751e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.02127 - pearson: 0.8472\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.02115 - pearson: 0.8476\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02205 - pearson: 0.8488\n",
      "\n",
      "300/1710 - remain: 0:18:30 - loss: 0.01297 - pearson: 0.8918 - lr: 9.145758522448522e-06\n",
      "400/1710 - remain: 0:15:40 - loss: 0.01316 - pearson: 0.8881 - lr: 8.903970133383297e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01776 - pearson: 0.8495\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01782 - pearson: 0.8494\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01857 - pearson: 0.854\n",
      "\n",
      "500/1710 - remain: 0:15:20 - loss: 0.01319 - pearson: 0.8886 - lr: 8.636167712444374e-06\n",
      "600/1710 - remain: 0:13:16 - loss: 0.01317 - pearson: 0.8886 - lr: 8.344135756048513e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.0171 - pearson: 0.8526\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01717 - pearson: 0.8521\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01784 - pearson: 0.8578\n",
      "\n",
      "700/1710 - remain: 0:12:36 - loss: 0.0133 - pearson: 0.8877 - lr: 8.029820213668239e-06\n",
      "800/1710 - remain: 0:10:54 - loss: 0.01324 - pearson: 0.8887 - lr: 7.695315521033981e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01652 - pearson: 0.8581\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01688 - pearson: 0.8551\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01762 - pearson: 0.8598\n",
      "\n",
      "900/1710 - remain: 0:10:1 - loss: 0.01313 - pearson: 0.8893 - lr: 7.3428506439008e-06\n",
      "1000/1710 - remain: 0:8:30 - loss: 0.01302 - pearson: 0.8903 - lr: 6.974774225376823e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01672 - pearson: 0.8592\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01729 - pearson: 0.8561\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01791 - pearson: 0.8599\n",
      "\n",
      "1100/1710 - remain: 0:7:30 - loss: 0.01304 - pearson: 0.8906 - lr: 6.593538935783872e-06\n",
      "1200/1710 - remain: 0:6:5 - loss: 0.01288 - pearson: 0.8918 - lr: 6.201685129334714e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01662 - pearson: 0.8603\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01721 - pearson: 0.8552\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01788 - pearson: 0.8596\n",
      "\n",
      "1300/1710 - remain: 0:5:0 - loss: 0.01295 - pearson: 0.892 - lr: 5.801823916530332e-06\n",
      "1400/1710 - remain: 0:3:42 - loss: 0.0129 - pearson: 0.8923 - lr: 5.396619765073997e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01669 - pearson: 0.8589\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01687 - pearson: 0.8564\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01754 - pearson: 0.8619\n",
      "\n",
      "1500/1710 - remain: 0:2:33 - loss: 0.01282 - pearson: 0.8925 - lr: 4.988772745240638e-06\n",
      "1600/1710 - remain: 0:1:19 - loss: 0.01279 - pearson: 0.8927 - lr: 4.581000538009112e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01635 - pearson: 0.8605\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01643 - pearson: 0.8598\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01714 - pearson: 0.8651\n",
      "'best_value' is improved by 0.001897173624992643! New 'best_value': 0.8650610706460277. Checkpoint path: './fold_1/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1700/1710 - remain: 0:0:7 - loss: 0.01273 - pearson: 0.8927 - lr: 4.176020325845912e-06\n",
      "1710/1710 - remain: 0:0:0 - loss: 0.01272 - pearson: 0.8929 - lr: 4.135780017681404e-06\n",
      "\n",
      "Training loss: 0.01272 - pearson: 0.8929\n",
      "Validation loss: 0.01714 - pearson: 0.8651\n",
      "Total time: 1:27:1\n",
      "\n",
      "Epoch 5/5\n",
      "\n",
      "100/1710 - remain: 0:13:25 - loss: 0.008351 - pearson: 0.9333 - lr: 3.736986603840017e-06\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01628 - pearson: 0.8622\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01632 - pearson: 0.862\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01706 - pearson: 0.8664\n",
      "'best_value' is improved by 0.0012974828173791808! New 'best_value': 0.8663585534634068. Checkpoint path: './fold_1/checkpoints/checkpoint.pth'.\n",
      "\n",
      "200/1710 - remain: 0:20:53 - loss: 0.007877 - pearson: 0.9374 - lr: 3.346609256111345e-06\n",
      "300/1710 - remain: 0:16:52 - loss: 0.008098 - pearson: 0.9343 - lr: 2.967249246641334e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01597 - pearson: 0.8635\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01623 - pearson: 0.8623\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01697 - pearson: 0.8665\n",
      "'best_value' is improved by 0.00018557676609454177! New 'best_value': 0.8665441302295014. Checkpoint path: './fold_1/checkpoints/checkpoint.pth'.\n",
      "\n",
      "400/1710 - remain: 0:18:3 - loss: 0.008084 - pearson: 0.9341 - lr: 2.601434433748771e-06\n",
      "500/1710 - remain: 0:15:20 - loss: 0.008242 - pearson: 0.9339 - lr: 2.2516024175887065e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01573 - pearson: 0.8659\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01593 - pearson: 0.8644\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01672 - pearson: 0.8685\n",
      "'best_value' is improved by 0.0019860045282292793! New 'best_value': 0.8685301347577307. Checkpoint path: './fold_1/checkpoints/checkpoint.pth'.\n",
      "\n",
      "600/1710 - remain: 0:15:6 - loss: 0.008262 - pearson: 0.9332 - lr: 1.9200842972494793e-06\n",
      "700/1710 - remain: 0:12:59 - loss: 0.008116 - pearson: 0.9329 - lr: 1.6090891375175916e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01627 - pearson: 0.8652\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01649 - pearson: 0.8634\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01732 - pearson: 0.8672\n",
      "\n",
      "800/1710 - remain: 0:12:0 - loss: 0.008069 - pearson: 0.9329 - lr: 1.3206892488158751e-06\n",
      "900/1710 - remain: 0:10:15 - loss: 0.008087 - pearson: 0.9326 - lr: 1.0568063784017952e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01593 - pearson: 0.8663\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01614 - pearson: 0.8647\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01691 - pearson: 0.8688\n",
      "'best_value' is improved by 0.00024635526222427373! New 'best_value': 0.8687764900199549. Checkpoint path: './fold_1/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1000/1710 - remain: 0:9:23 - loss: 0.008102 - pearson: 0.9323 - lr: 8.191989048405902e-07\n",
      "1100/1710 - remain: 0:7:46 - loss: 0.008059 - pearson: 0.9327 - lr: 6.094501210826336e-07\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01583 - pearson: 0.8671\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01606 - pearson: 0.8653\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01681 - pearson: 0.8695\n",
      "'best_value' is improved by 0.0006972462503125332! New 'best_value': 0.8694737362702675. Checkpoint path: './fold_1/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1200/1710 - remain: 0:6:44 - loss: 0.008047 - pearson: 0.9328 - lr: 4.289576842205062e-07\n",
      "1300/1710 - remain: 0:5:16 - loss: 0.008025 - pearson: 0.9331 - lr: 2.7892430222713596e-07\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01572 - pearson: 0.8674\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01594 - pearson: 0.8656\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01669 - pearson: 0.8698\n",
      "'best_value' is improved by 0.0003065154943995285! New 'best_value': 0.869780251764667. Checkpoint path: './fold_1/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1400/1710 - remain: 0:4:7 - loss: 0.007998 - pearson: 0.9329 - lr: 1.6034971973374337e-07\n",
      "1500/1710 - remain: 0:2:43 - loss: 0.007949 - pearson: 0.9334 - lr: 7.402405625021314e-08\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01576 - pearson: 0.8673\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01599 - pearson: 0.8655\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01674 - pearson: 0.8696\n",
      "\n",
      "1600/1710 - remain: 0:1:26 - loss: 0.007944 - pearson: 0.9336 - lr: 2.052254121853725e-08\n",
      "1700/1710 - remain: 0:0:8 - loss: 0.007973 - pearson: 0.9334 - lr: 2.0168098219974787e-10\n",
      "1710/1710 - remain: 0:0:0 - loss: 0.007973 - pearson: 0.9335 - lr: 1.6667960894833912e-12\n",
      "\n",
      "Training loss: 0.007973 - pearson: 0.9335\n",
      "Validation loss: 0.01669 - pearson: 0.8698\n",
      "Total time: 1:48:55\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Fold 2/4\n",
      "\n",
      "Train samples: 27355\n",
      "Validation samples: 9118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Checkpointing: True\n",
      "Epochs: 5\n",
      "Auto Mixed Precision: True\n",
      "Gradient norm: 1.0\n",
      "Gradient scaling: True\n",
      "Gradient accumulation steps: 1\n",
      "Validation steps: 200\n",
      "Device: cuda\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "\n",
      "100/1710 - remain: 0:13:44 - loss: 0.1271 - pearson: 0.07667 - lr: 1.1578947368421053e-06\n",
      "200/1710 - remain: 0:12:50 - loss: 0.0948 - pearson: 0.1942 - lr: 2.3274853801169592e-06\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.05038 - pearson: 0.5626\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.0541 - pearson: 0.5587\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.05581 - pearson: 0.5124\n",
      "'best_value' is improved by inf! New 'best_value': 0.5123825234419976. Checkpoint path: './fold_2/checkpoints/checkpoint.pth'.\n",
      "\n",
      "300/1710 - remain: 0:16:33 - loss: 0.07958 - pearson: 0.2923 - lr: 3.497076023391813e-06\n",
      "400/1710 - remain: 0:14:17 - loss: 0.07051 - pearson: 0.3699 - lr: 4.666666666666667e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.03692 - pearson: 0.6852\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.03696 - pearson: 0.6873\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.0382 - pearson: 0.6733\n",
      "'best_value' is improved by 0.16090050835606406! New 'best_value': 0.6732830317980617. Checkpoint path: './fold_2/checkpoints/checkpoint.pth'.\n",
      "\n",
      "500/1710 - remain: 0:15:13 - loss: 0.06404 - pearson: 0.4284 - lr: 5.836257309941521e-06\n",
      "600/1710 - remain: 0:13:11 - loss: 0.05957 - pearson: 0.4657 - lr: 7.005847953216375e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.03317 - pearson: 0.7489\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.03303 - pearson: 0.7554\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.03356 - pearson: 0.7519\n",
      "'best_value' is improved by 0.0786204784854242! New 'best_value': 0.7519035102834859. Checkpoint path: './fold_2/checkpoints/checkpoint.pth'.\n",
      "\n",
      "700/1710 - remain: 0:13:2 - loss: 0.05578 - pearson: 0.4981 - lr: 8.175438596491229e-06\n",
      "800/1710 - remain: 0:11:14 - loss: 0.05311 - pearson: 0.5227 - lr: 9.345029239766083e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.02683 - pearson: 0.7734\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.02656 - pearson: 0.7782\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02778 - pearson: 0.7759\n",
      "'best_value' is improved by 0.02397245161984729! New 'best_value': 0.7758759619033332. Checkpoint path: './fold_2/checkpoints/checkpoint.pth'.\n",
      "\n",
      "900/1710 - remain: 0:10:37 - loss: 0.05053 - pearson: 0.5489 - lr: 9.99677342967605e-06\n",
      "1000/1710 - remain: 0:8:58 - loss: 0.04847 - pearson: 0.5673 - lr: 9.965477115326678e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.02498 - pearson: 0.785\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.02505 - pearson: 0.7896\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02613 - pearson: 0.7854\n",
      "'best_value' is improved by 0.009553358861810746! New 'best_value': 0.7854293207651439. Checkpoint path: './fold_2/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1100/1710 - remain: 0:8:4 - loss: 0.04637 - pearson: 0.5872 - lr: 9.901093437208395e-06\n",
      "1200/1710 - remain: 0:6:32 - loss: 0.04478 - pearson: 0.6012 - lr: 9.804051414754617e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.02294 - pearson: 0.8007\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.0224 - pearson: 0.8067\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02342 - pearson: 0.807\n",
      "'best_value' is improved by 0.021577799059977587! New 'best_value': 0.8070071198251215. Checkpoint path: './fold_2/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1300/1710 - remain: 0:5:28 - loss: 0.04322 - pearson: 0.6162 - lr: 9.67499768566465e-06\n",
      "1400/1710 - remain: 0:4:1 - loss: 0.04212 - pearson: 0.6251 - lr: 9.51479219704548e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.04105 - pearson: nan\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.03277 - pearson: nan\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.03535 - pearson: 0.7088\n",
      "\n",
      "1500/1710 - remain: 0:2:46 - loss: 0.04183 - pearson: 0.6274 - lr: 9.324502475170332e-06\n",
      "1600/1710 - remain: 0:1:24 - loss: 0.04135 - pearson: 0.6316 - lr: 9.10539651203735e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.03688 - pearson: nan\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.03035 - pearson: nan\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.03244 - pearson: 0.7296\n",
      "\n",
      "1700/1710 - remain: 0:0:8 - loss: 0.04096 - pearson: 0.6341 - lr: 8.85893431612864e-06\n",
      "1710/1710 - remain: 0:0:0 - loss: 0.04094 - pearson: 0.6339 - lr: 8.832845209850547e-06\n",
      "\n",
      "Training loss: 0.04094 - pearson: 0.6339\n",
      "Validation loss: 0.02342 - pearson: 0.807\n",
      "Total time: 0:22:13\n",
      "\n",
      "Epoch 2/5\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.02142 - pearson: 0.8154\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.02058 - pearson: 0.8234\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02157 - pearson: 0.8238\n",
      "'best_value' is improved by 0.01674957166100266! New 'best_value': 0.8237566914861242. Checkpoint path: './fold_2/checkpoints/checkpoint.pth'.\n",
      "\n",
      "100/1710 - remain: 0:29:14 - loss: 0.02523 - pearson: 0.7642 - lr: 8.558194707848636e-06\n",
      "200/1710 - remain: 0:20:0 - loss: 0.02264 - pearson: 0.7945 - lr: 8.2598342420457e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.02178 - pearson: 0.8213\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.02162 - pearson: 0.8254\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02273 - pearson: 0.8261\n",
      "'best_value' is improved by 0.0023911565094144605! New 'best_value': 0.8261478479955386. Checkpoint path: './fold_2/checkpoints/checkpoint.pth'.\n",
      "\n",
      "300/1710 - remain: 0:21:18 - loss: 0.02134 - pearson: 0.8103 - lr: 7.939751931818186e-06\n",
      "400/1710 - remain: 0:17:36 - loss: 0.02048 - pearson: 0.82 - lr: 7.600080639646077e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.02011 - pearson: 0.8304\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.01977 - pearson: 0.8338\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02065 - pearson: 0.8353\n",
      "'best_value' is improved by 0.009114911386067126! New 'best_value': 0.8352627593816058. Checkpoint path: './fold_2/checkpoints/checkpoint.pth'.\n",
      "\n",
      "500/1710 - remain: 0:17:35 - loss: 0.02001 - pearson: 0.8241 - lr: 7.243083758823699e-06\n",
      "600/1710 - remain: 0:15:0 - loss: 0.01981 - pearson: 0.8282 - lr: 6.871140131380888e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01924 - pearson: 0.8306\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01921 - pearson: 0.8331\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01989 - pearson: 0.8373\n",
      "'best_value' is improved by 0.0020354317908465314! New 'best_value': 0.8372981911724523. Checkpoint path: './fold_2/checkpoints/checkpoint.pth'.\n",
      "\n",
      "700/1710 - remain: 0:14:28 - loss: 0.01952 - pearson: 0.8309 - lr: 6.486728196713679e-06\n",
      "800/1710 - remain: 0:12:21 - loss: 0.0192 - pearson: 0.8349 - lr: 6.0924094765497985e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01899 - pearson: 0.8385\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.01901 - pearson: 0.8385\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01991 - pearson: 0.8418\n",
      "'best_value' is improved by 0.004543988410966926! New 'best_value': 0.8418421795834192. Checkpoint path: './fold_2/checkpoints/checkpoint.pth'.\n",
      "\n",
      "900/1710 - remain: 0:11:30 - loss: 0.01916 - pearson: 0.8357 - lr: 5.690811506296609e-06\n",
      "1000/1710 - remain: 0:9:39 - loss: 0.01886 - pearson: 0.8382 - lr: 5.284610326508117e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01849 - pearson: 0.8428\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.01835 - pearson: 0.8439\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01903 - pearson: 0.8479\n",
      "'best_value' is improved by 0.006022786709092842! New 'best_value': 0.8478649662925121. Checkpoint path: './fold_2/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1100/1710 - remain: 0:8:37 - loss: 0.01881 - pearson: 0.8392 - lr: 4.87651265113887e-06\n",
      "1200/1710 - remain: 0:6:57 - loss: 0.01868 - pearson: 0.8403 - lr: 4.469237831406198e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01874 - pearson: 0.8411\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.0184 - pearson: 0.8441\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01916 - pearson: 0.847\n",
      "\n",
      "1300/1710 - remain: 0:5:39 - loss: 0.01858 - pearson: 0.8411 - lr: 4.065499735444305e-06\n",
      "1400/1710 - remain: 0:4:9 - loss: 0.01851 - pearson: 0.8423 - lr: 3.667988664494785e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01987 - pearson: 0.8366\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01939 - pearson: 0.8405\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01989 - pearson: 0.8451\n",
      "\n",
      "1500/1710 - remain: 0:2:50 - loss: 0.01846 - pearson: 0.8432 - lr: 3.279353426134673e-06\n",
      "1600/1710 - remain: 0:1:27 - loss: 0.01839 - pearson: 0.8437 - lr: 2.9021836839967644e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01787 - pearson: 0.8459\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01765 - pearson: 0.8493\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01838 - pearson: 0.8533\n",
      "'best_value' is improved by 0.0054109293481444665! New 'best_value': 0.8532758956406565. Checkpoint path: './fold_2/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1700/1710 - remain: 0:0:8 - loss: 0.01835 - pearson: 0.8443 - lr: 2.5389927015944937e-06\n",
      "1710/1710 - remain: 0:0:0 - loss: 0.01833 - pearson: 0.8444 - lr: 2.5035365042804726e-06\n",
      "\n",
      "Training loss: 0.01833 - pearson: 0.8444\n",
      "Validation loss: 0.01838 - pearson: 0.8533\n",
      "Total time: 0:45:26\n",
      "\n",
      "Epoch 3/5\n",
      "\n",
      "100/1710 - remain: 0:13:30 - loss: 0.01256 - pearson: 0.8943 - lr: 2.158513320853839e-06\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01836 - pearson: 0.8433\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01801 - pearson: 0.8477\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01872 - pearson: 0.8517\n",
      "\n",
      "200/1710 - remain: 0:18:7 - loss: 0.01252 - pearson: 0.8951 - lr: 1.8324243307008454e-06\n",
      "300/1710 - remain: 0:15:10 - loss: 0.01235 - pearson: 0.8966 - lr: 1.5274424217006701e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01834 - pearson: 0.8437\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01792 - pearson: 0.8485\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01864 - pearson: 0.852\n",
      "\n",
      "400/1710 - remain: 0:15:40 - loss: 0.01228 - pearson: 0.8974 - lr: 1.2455998350925042e-06\n",
      "500/1710 - remain: 0:13:37 - loss: 0.01227 - pearson: 0.8974 - lr: 9.88774623674112e-07\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01836 - pearson: 0.8443\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.01802 - pearson: 0.8483\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01873 - pearson: 0.8518\n",
      "\n",
      "600/1710 - remain: 0:13:19 - loss: 0.01221 - pearson: 0.8983 - lr: 7.586781374321844e-07\n",
      "700/1710 - remain: 0:11:36 - loss: 0.01207 - pearson: 0.8993 - lr: 5.568436199937521e-07\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01857 - pearson: 0.8453\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01824 - pearson: 0.849\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01893 - pearson: 0.8524\n",
      "\n",
      "800/1710 - remain: 0:10:56 - loss: 0.01204 - pearson: 0.8991 - lr: 3.8461599188598707e-07\n",
      "900/1710 - remain: 0:9:23 - loss: 0.01191 - pearson: 0.9002 - lr: 2.431428886834575e-07\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01821 - pearson: 0.8458\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01793 - pearson: 0.8495\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01863 - pearson: 0.8531\n",
      "\n",
      "1000/1710 - remain: 0:8:30 - loss: 0.01189 - pearson: 0.9002 - lr: 1.333670137599713e-07\n",
      "1100/1710 - remain: 0:7:5 - loss: 0.01194 - pearson: 0.8993 - lr: 5.601985660229514e-08\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01829 - pearson: 0.8457\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.018 - pearson: 0.8495\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01868 - pearson: 0.8531\n",
      "\n",
      "1200/1710 - remain: 0:6:6 - loss: 0.01186 - pearson: 0.9 - lr: 1.161681854366048e-08\n",
      "1300/1710 - remain: 0:4:47 - loss: 0.01183 - pearson: 0.9 - lr: 9.99954622160337e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01997 - pearson: 0.8266\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01957 - pearson: 0.8317\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02017 - pearson: 0.8367\n",
      "\n",
      "1400/1710 - remain: 0:3:42 - loss: 0.01191 - pearson: 0.9002 - lr: 9.97739487912983e-06\n",
      "1500/1710 - remain: 0:2:27 - loss: 0.01202 - pearson: 0.8996 - lr: 9.922076759091456e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01911 - pearson: 0.8388\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01938 - pearson: 0.8376\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02006 - pearson: 0.8421\n",
      "\n",
      "1600/1710 - remain: 0:1:18 - loss: 0.01217 - pearson: 0.899 - lr: 9.833960472745178e-06\n",
      "1700/1710 - remain: 0:0:7 - loss: 0.01233 - pearson: 0.8979 - lr: 9.713633181314904e-06\n",
      "1710/1710 - remain: 0:0:0 - loss: 0.01232 - pearson: 0.898 - lr: 9.699857883137968e-06\n",
      "\n",
      "Training loss: 0.01232 - pearson: 0.898\n",
      "Validation loss: 0.01838 - pearson: 0.8533\n",
      "Total time: 1:5:28\n",
      "\n",
      "Epoch 4/5\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.02291 - pearson: 0.829\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.02206 - pearson: 0.8364\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02251 - pearson: 0.8388\n",
      "\n",
      "100/1710 - remain: 0:25:8 - loss: 0.01264 - pearson: 0.8948 - lr: 9.545032675245814e-06\n",
      "200/1710 - remain: 0:18:8 - loss: 0.01275 - pearson: 0.8934 - lr: 9.35992172723751e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.02027 - pearson: 0.8309\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01972 - pearson: 0.8375\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02052 - pearson: 0.8395\n",
      "\n",
      "300/1710 - remain: 0:18:31 - loss: 0.01249 - pearson: 0.8977 - lr: 9.145758522448522e-06\n",
      "400/1710 - remain: 0:15:40 - loss: 0.01258 - pearson: 0.8972 - lr: 8.903970133383297e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01917 - pearson: 0.838\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01866 - pearson: 0.8438\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01932 - pearson: 0.8471\n",
      "\n",
      "500/1710 - remain: 0:15:21 - loss: 0.01268 - pearson: 0.895 - lr: 8.636167712444374e-06\n",
      "600/1710 - remain: 0:13:17 - loss: 0.01275 - pearson: 0.895 - lr: 8.344135756048513e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01987 - pearson: 0.8344\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01926 - pearson: 0.8411\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02009 - pearson: 0.8426\n",
      "\n",
      "700/1710 - remain: 0:12:35 - loss: 0.013 - pearson: 0.8927 - lr: 8.029820213668239e-06\n",
      "800/1710 - remain: 0:10:52 - loss: 0.013 - pearson: 0.8931 - lr: 7.695315521033981e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.0188 - pearson: 0.8403\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01827 - pearson: 0.8464\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01904 - pearson: 0.8495\n",
      "\n",
      "900/1710 - remain: 0:9:59 - loss: 0.01294 - pearson: 0.8924 - lr: 7.3428506439008e-06\n",
      "1000/1710 - remain: 0:8:28 - loss: 0.01295 - pearson: 0.8925 - lr: 6.974774225376823e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.02 - pearson: 0.8389\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01958 - pearson: 0.8443\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02026 - pearson: 0.8476\n",
      "\n",
      "1100/1710 - remain: 0:7:28 - loss: 0.013 - pearson: 0.8917 - lr: 6.593538935783872e-06\n",
      "1200/1710 - remain: 0:6:5 - loss: 0.01296 - pearson: 0.8918 - lr: 6.201685129334714e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01892 - pearson: 0.8428\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.0184 - pearson: 0.8485\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01913 - pearson: 0.8508\n",
      "\n",
      "1300/1710 - remain: 0:5:0 - loss: 0.01298 - pearson: 0.892 - lr: 5.801823916530332e-06\n",
      "1400/1710 - remain: 0:3:41 - loss: 0.01295 - pearson: 0.8925 - lr: 5.396619765073997e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01809 - pearson: 0.8449\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01792 - pearson: 0.8503\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01862 - pearson: 0.8537\n",
      "'best_value' is improved by 0.0004115310116499238! New 'best_value': 0.8536874266523065. Checkpoint path: './fold_2/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1500/1710 - remain: 0:2:36 - loss: 0.01288 - pearson: 0.893 - lr: 4.988772745240638e-06\n",
      "1600/1710 - remain: 0:1:20 - loss: 0.01277 - pearson: 0.8939 - lr: 4.581000538009112e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01824 - pearson: 0.846\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01773 - pearson: 0.8527\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01853 - pearson: 0.8559\n",
      "'best_value' is improved by 0.0022239203349860848! New 'best_value': 0.8559113469872925. Checkpoint path: './fold_2/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1700/1710 - remain: 0:0:7 - loss: 0.01273 - pearson: 0.8947 - lr: 4.176020325845912e-06\n",
      "1710/1710 - remain: 0:0:0 - loss: 0.01272 - pearson: 0.8947 - lr: 4.135780017681404e-06\n",
      "\n",
      "Training loss: 0.01272 - pearson: 0.8947\n",
      "Validation loss: 0.01853 - pearson: 0.8559\n",
      "Total time: 1:26:58\n",
      "\n",
      "Epoch 5/5\n",
      "\n",
      "100/1710 - remain: 0:13:31 - loss: 0.009454 - pearson: 0.9203 - lr: 3.736986603840017e-06\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01769 - pearson: 0.8485\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01733 - pearson: 0.8544\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.0181 - pearson: 0.8576\n",
      "'best_value' is improved by 0.001652234352378823! New 'best_value': 0.8575635813396714. Checkpoint path: './fold_2/checkpoints/checkpoint.pth'.\n",
      "\n",
      "200/1710 - remain: 0:20:59 - loss: 0.008645 - pearson: 0.9265 - lr: 3.346609256111345e-06\n",
      "300/1710 - remain: 0:16:57 - loss: 0.008507 - pearson: 0.9267 - lr: 2.967249246641334e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01892 - pearson: 0.847\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.01864 - pearson: 0.8519\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01931 - pearson: 0.8551\n",
      "\n",
      "400/1710 - remain: 0:16:56 - loss: 0.008447 - pearson: 0.9274 - lr: 2.601434433748771e-06\n",
      "500/1710 - remain: 0:14:34 - loss: 0.008257 - pearson: 0.9297 - lr: 2.2516024175887065e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01885 - pearson: 0.8482\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.01844 - pearson: 0.8534\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01909 - pearson: 0.8572\n",
      "\n",
      "600/1710 - remain: 0:13:59 - loss: 0.008227 - pearson: 0.9305 - lr: 1.9200842972494793e-06\n",
      "700/1710 - remain: 0:12:6 - loss: 0.008132 - pearson: 0.9318 - lr: 1.6090891375175916e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01794 - pearson: 0.8494\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01754 - pearson: 0.8549\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01818 - pearson: 0.859\n",
      "'best_value' is improved by 0.0014861687278007185! New 'best_value': 0.8590497500674721. Checkpoint path: './fold_2/checkpoints/checkpoint.pth'.\n",
      "\n",
      "800/1710 - remain: 0:11:43 - loss: 0.008109 - pearson: 0.9319 - lr: 1.3206892488158751e-06\n",
      "900/1710 - remain: 0:10:3 - loss: 0.008058 - pearson: 0.9324 - lr: 1.0568063784017952e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01765 - pearson: 0.8497\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01731 - pearson: 0.8549\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01799 - pearson: 0.859\n",
      "\n",
      "1000/1710 - remain: 0:9:2 - loss: 0.007964 - pearson: 0.9332 - lr: 8.191989048405902e-07\n",
      "1100/1710 - remain: 0:7:32 - loss: 0.007949 - pearson: 0.9335 - lr: 6.094501210826336e-07\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01797 - pearson: 0.8497\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.01756 - pearson: 0.8554\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01825 - pearson: 0.8593\n",
      "'best_value' is improved by 0.00024716082036624343! New 'best_value': 0.8592969108878383. Checkpoint path: './fold_2/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1200/1710 - remain: 0:6:35 - loss: 0.007922 - pearson: 0.9336 - lr: 4.289576842205062e-07\n",
      "1300/1710 - remain: 0:5:9 - loss: 0.007933 - pearson: 0.9337 - lr: 2.7892430222713596e-07\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01772 - pearson: 0.8501\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.01733 - pearson: 0.8557\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01802 - pearson: 0.8597\n",
      "'best_value' is improved by 0.0003873644106835439! New 'best_value': 0.8596842752985219. Checkpoint path: './fold_2/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1400/1710 - remain: 0:4:3 - loss: 0.007889 - pearson: 0.9341 - lr: 1.6034971973374337e-07\n",
      "1500/1710 - remain: 0:2:40 - loss: 0.007899 - pearson: 0.9342 - lr: 7.402405625021314e-08\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01781 - pearson: 0.8499\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.01742 - pearson: 0.8554\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.0181 - pearson: 0.8594\n",
      "\n",
      "1600/1710 - remain: 0:1:25 - loss: 0.007865 - pearson: 0.9343 - lr: 2.052254121853725e-08\n",
      "1700/1710 - remain: 0:0:7 - loss: 0.007874 - pearson: 0.9342 - lr: 2.0168098219974787e-10\n",
      "1710/1710 - remain: 0:0:0 - loss: 0.007892 - pearson: 0.934 - lr: 1.6667960894833912e-12\n",
      "\n",
      "Training loss: 0.007892 - pearson: 0.934\n",
      "Validation loss: 0.01802 - pearson: 0.8597\n",
      "Total time: 1:48:36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Fold 3/4\n",
      "\n",
      "Train samples: 27355\n",
      "Validation samples: 9118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Checkpointing: True\n",
      "Epochs: 5\n",
      "Auto Mixed Precision: True\n",
      "Gradient norm: 1.0\n",
      "Gradient scaling: True\n",
      "Gradient accumulation steps: 1\n",
      "Validation steps: 200\n",
      "Device: cuda\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "\n",
      "100/1710 - remain: 0:13:35 - loss: 0.09852 - pearson: -0.02345 - lr: 1.1578947368421053e-06\n",
      "200/1710 - remain: 0:12:42 - loss: 0.08257 - pearson: 0.1012 - lr: 2.3274853801169592e-06\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.05509 - pearson: 0.4627\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.05687 - pearson: 0.4581\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.05706 - pearson: 0.3846\n",
      "'best_value' is improved by inf! New 'best_value': 0.3845956035758801. Checkpoint path: './fold_3/checkpoints/checkpoint.pth'.\n",
      "\n",
      "300/1710 - remain: 0:16:31 - loss: 0.07386 - pearson: 0.2035 - lr: 3.497076023391813e-06\n",
      "400/1710 - remain: 0:14:15 - loss: 0.06646 - pearson: 0.2978 - lr: 4.666666666666667e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.05702 - pearson: 0.6475\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.05407 - pearson: 0.6547\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.05529 - pearson: 0.636\n",
      "'best_value' is improved by 0.251430501086749! New 'best_value': 0.6360261046626291. Checkpoint path: './fold_3/checkpoints/checkpoint.pth'.\n",
      "\n",
      "500/1710 - remain: 0:14:59 - loss: 0.06106 - pearson: 0.3687 - lr: 5.836257309941521e-06\n",
      "600/1710 - remain: 0:13:2 - loss: 0.057 - pearson: 0.4181 - lr: 7.005847953216375e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.03046 - pearson: 0.7535\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.03017 - pearson: 0.7531\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.03083 - pearson: 0.7494\n",
      "'best_value' is improved by 0.11333340852398277! New 'best_value': 0.7493595131866119. Checkpoint path: './fold_3/checkpoints/checkpoint.pth'.\n",
      "\n",
      "700/1710 - remain: 0:12:48 - loss: 0.05347 - pearson: 0.4616 - lr: 8.175438596491229e-06\n",
      "800/1710 - remain: 0:11:4 - loss: 0.05041 - pearson: 0.4946 - lr: 9.345029239766083e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.02679 - pearson: 0.7745\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.0266 - pearson: 0.7785\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02762 - pearson: 0.7784\n",
      "'best_value' is improved by 0.02908362264717712! New 'best_value': 0.778443135833789. Checkpoint path: './fold_3/checkpoints/checkpoint.pth'.\n",
      "\n",
      "900/1710 - remain: 0:10:28 - loss: 0.04848 - pearson: 0.5193 - lr: 9.99677342967605e-06\n",
      "1000/1710 - remain: 0:8:51 - loss: 0.04645 - pearson: 0.5444 - lr: 9.965477115326678e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.0242 - pearson: 0.7946\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.02393 - pearson: 0.795\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02455 - pearson: 0.795\n",
      "'best_value' is improved by 0.0165832954216949! New 'best_value': 0.7950264312554839. Checkpoint path: './fold_3/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1100/1710 - remain: 0:7:58 - loss: 0.04511 - pearson: 0.5605 - lr: 9.901093437208395e-06\n",
      "1200/1710 - remain: 0:6:27 - loss: 0.04419 - pearson: 0.5718 - lr: 9.804051414754617e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.03391 - pearson: 0.7957\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.03365 - pearson: 0.7902\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.03402 - pearson: 0.7922\n",
      "\n",
      "1300/1710 - remain: 0:5:17 - loss: 0.04276 - pearson: 0.5891 - lr: 9.67499768566465e-06\n",
      "1400/1710 - remain: 0:3:54 - loss: 0.04146 - pearson: 0.6034 - lr: 9.51479219704548e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.02319 - pearson: 0.815\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.02325 - pearson: 0.8125\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02405 - pearson: 0.8127\n",
      "'best_value' is improved by 0.017633328737478693! New 'best_value': 0.8126597599929626. Checkpoint path: './fold_3/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1500/1710 - remain: 0:2:44 - loss: 0.04028 - pearson: 0.6154 - lr: 9.324502475170332e-06\n",
      "1600/1710 - remain: 0:1:24 - loss: 0.03932 - pearson: 0.626 - lr: 9.10539651203735e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.02182 - pearson: 0.8212\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.02177 - pearson: 0.8186\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02242 - pearson: 0.8179\n",
      "'best_value' is improved by 0.005250018364008069! New 'best_value': 0.8179097783569707. Checkpoint path: './fold_3/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1700/1710 - remain: 0:0:7 - loss: 0.03838 - pearson: 0.6363 - lr: 8.85893431612864e-06\n",
      "1710/1710 - remain: 0:0:0 - loss: 0.03828 - pearson: 0.6371 - lr: 8.832845209850547e-06\n",
      "\n",
      "Training loss: 0.03828 - pearson: 0.6371\n",
      "Validation loss: 0.02242 - pearson: 0.8179\n",
      "Total time: 0:22:27\n",
      "\n",
      "Epoch 2/5\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.02201 - pearson: 0.824\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.02155 - pearson: 0.8249\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02218 - pearson: 0.8264\n",
      "'best_value' is improved by 0.008478120423486613! New 'best_value': 0.8263878987804573. Checkpoint path: './fold_3/checkpoints/checkpoint.pth'.\n",
      "\n",
      "100/1710 - remain: 0:31:7 - loss: 0.01949 - pearson: 0.8391 - lr: 8.558194707848636e-06\n",
      "200/1710 - remain: 0:20:57 - loss: 0.02012 - pearson: 0.8334 - lr: 8.2598342420457e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.0254 - pearson: 0.8163\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.02516 - pearson: 0.8159\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02583 - pearson: 0.8181\n",
      "\n",
      "300/1710 - remain: 0:20:25 - loss: 0.02011 - pearson: 0.8345 - lr: 7.939751931818186e-06\n",
      "400/1710 - remain: 0:16:56 - loss: 0.01978 - pearson: 0.8356 - lr: 7.600080639646077e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.02213 - pearson: 0.8325\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.02205 - pearson: 0.83\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02273 - pearson: 0.8315\n",
      "'best_value' is improved by 0.0051034528730796724! New 'best_value': 0.8314913516535369. Checkpoint path: './fold_3/checkpoints/checkpoint.pth'.\n",
      "\n",
      "500/1710 - remain: 0:17:13 - loss: 0.01948 - pearson: 0.839 - lr: 7.243083758823699e-06\n",
      "600/1710 - remain: 0:14:45 - loss: 0.01916 - pearson: 0.8397 - lr: 6.871140131380888e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.02141 - pearson: 0.8391\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.02156 - pearson: 0.8348\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02235 - pearson: 0.8362\n",
      "'best_value' is improved by 0.004678380788356695! New 'best_value': 0.8361697324418936. Checkpoint path: './fold_3/checkpoints/checkpoint.pth'.\n",
      "\n",
      "700/1710 - remain: 0:14:18 - loss: 0.01887 - pearson: 0.8434 - lr: 6.486728196713679e-06\n",
      "800/1710 - remain: 0:12:13 - loss: 0.01881 - pearson: 0.8432 - lr: 6.0924094765497985e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01902 - pearson: 0.8409\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.0191 - pearson: 0.838\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01987 - pearson: 0.8395\n",
      "'best_value' is improved by 0.003354611877077751! New 'best_value': 0.8395243443189714. Checkpoint path: './fold_3/checkpoints/checkpoint.pth'.\n",
      "\n",
      "900/1710 - remain: 0:11:24 - loss: 0.01875 - pearson: 0.8437 - lr: 5.690811506296609e-06\n",
      "1000/1710 - remain: 0:9:34 - loss: 0.01875 - pearson: 0.843 - lr: 5.284610326508117e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01845 - pearson: 0.8437\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.01857 - pearson: 0.8403\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.0192 - pearson: 0.8433\n",
      "'best_value' is improved by 0.00373474527296469! New 'best_value': 0.8432590895919361. Checkpoint path: './fold_3/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1100/1710 - remain: 0:8:31 - loss: 0.01863 - pearson: 0.8431 - lr: 4.87651265113887e-06\n",
      "1200/1710 - remain: 0:6:53 - loss: 0.01863 - pearson: 0.8429 - lr: 4.469237831406198e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01821 - pearson: 0.8447\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.01809 - pearson: 0.8441\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01877 - pearson: 0.8467\n",
      "'best_value' is improved by 0.003431398217086934! New 'best_value': 0.846690487809023. Checkpoint path: './fold_3/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1300/1710 - remain: 0:5:43 - loss: 0.01854 - pearson: 0.8431 - lr: 4.065499735444305e-06\n",
      "1400/1710 - remain: 0:4:12 - loss: 0.01851 - pearson: 0.8436 - lr: 3.667988664494785e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01793 - pearson: 0.8482\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.01782 - pearson: 0.8481\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01857 - pearson: 0.8501\n",
      "'best_value' is improved by 0.0033956419447283004! New 'best_value': 0.8500861297537513. Checkpoint path: './fold_3/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1500/1710 - remain: 0:2:55 - loss: 0.01833 - pearson: 0.845 - lr: 3.279353426134673e-06\n",
      "1600/1710 - remain: 0:1:29 - loss: 0.01825 - pearson: 0.8454 - lr: 2.9021836839967644e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01898 - pearson: 0.8464\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01865 - pearson: 0.847\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01945 - pearson: 0.848\n",
      "\n",
      "1700/1710 - remain: 0:0:8 - loss: 0.01816 - pearson: 0.8463 - lr: 2.5389927015944937e-06\n",
      "1710/1710 - remain: 0:0:0 - loss: 0.01817 - pearson: 0.846 - lr: 2.5035365042804726e-06\n",
      "\n",
      "Training loss: 0.01817 - pearson: 0.846\n",
      "Validation loss: 0.01857 - pearson: 0.8501\n",
      "Total time: 0:45:49\n",
      "\n",
      "Epoch 3/5\n",
      "\n",
      "100/1710 - remain: 0:13:27 - loss: 0.01273 - pearson: 0.8995 - lr: 2.158513320853839e-06\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01876 - pearson: 0.848\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.01842 - pearson: 0.8482\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01917 - pearson: 0.8495\n",
      "\n",
      "200/1710 - remain: 0:18:14 - loss: 0.01257 - pearson: 0.8959 - lr: 1.8324243307008454e-06\n",
      "300/1710 - remain: 0:15:15 - loss: 0.01228 - pearson: 0.898 - lr: 1.5274424217006701e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.018 - pearson: 0.8504\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.01784 - pearson: 0.8496\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01862 - pearson: 0.8512\n",
      "'best_value' is improved by 0.0011600242102000058! New 'best_value': 0.8512461539639513. Checkpoint path: './fold_3/checkpoints/checkpoint.pth'.\n",
      "\n",
      "400/1710 - remain: 0:17:0 - loss: 0.01212 - pearson: 0.8999 - lr: 1.2455998350925042e-06\n",
      "500/1710 - remain: 0:14:36 - loss: 0.01224 - pearson: 0.8981 - lr: 9.88774623674112e-07\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01849 - pearson: 0.8494\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.01825 - pearson: 0.8488\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01901 - pearson: 0.8506\n",
      "\n",
      "600/1710 - remain: 0:14:3 - loss: 0.01224 - pearson: 0.8981 - lr: 7.586781374321844e-07\n",
      "700/1710 - remain: 0:12:10 - loss: 0.01224 - pearson: 0.8974 - lr: 5.568436199937521e-07\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01829 - pearson: 0.85\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.018 - pearson: 0.85\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01876 - pearson: 0.8519\n",
      "'best_value' is improved by 0.0006540598760750305! New 'best_value': 0.8519002138400263. Checkpoint path: './fold_3/checkpoints/checkpoint.pth'.\n",
      "\n",
      "800/1710 - remain: 0:11:48 - loss: 0.01234 - pearson: 0.8951 - lr: 3.8461599188598707e-07\n",
      "900/1710 - remain: 0:10:4 - loss: 0.01223 - pearson: 0.8957 - lr: 2.431428886834575e-07\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01873 - pearson: 0.8497\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.01844 - pearson: 0.8496\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01921 - pearson: 0.8512\n",
      "\n",
      "1000/1710 - remain: 0:9:3 - loss: 0.01222 - pearson: 0.896 - lr: 1.333670137599713e-07\n",
      "1100/1710 - remain: 0:7:32 - loss: 0.01221 - pearson: 0.8961 - lr: 5.601985660229514e-08\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01843 - pearson: 0.85\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01815 - pearson: 0.85\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.0189 - pearson: 0.8517\n",
      "\n",
      "1200/1710 - remain: 0:6:26 - loss: 0.01217 - pearson: 0.8963 - lr: 1.161681854366048e-08\n",
      "1300/1710 - remain: 0:5:2 - loss: 0.0121 - pearson: 0.8968 - lr: 9.99954622160337e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01891 - pearson: 0.8452\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01907 - pearson: 0.8408\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01979 - pearson: 0.8429\n",
      "\n",
      "1400/1710 - remain: 0:3:53 - loss: 0.01226 - pearson: 0.8963 - lr: 9.97739487912983e-06\n",
      "1500/1710 - remain: 0:2:34 - loss: 0.01241 - pearson: 0.8952 - lr: 9.922076759091456e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.0197 - pearson: 0.8417\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01964 - pearson: 0.8404\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02054 - pearson: 0.8403\n",
      "\n",
      "1600/1710 - remain: 0:1:22 - loss: 0.01257 - pearson: 0.8943 - lr: 9.833960472745178e-06\n",
      "1700/1710 - remain: 0:0:7 - loss: 0.01271 - pearson: 0.8934 - lr: 9.713633181314904e-06\n",
      "1710/1710 - remain: 0:0:0 - loss: 0.01271 - pearson: 0.8934 - lr: 9.699857883137968e-06\n",
      "\n",
      "Training loss: 0.01271 - pearson: 0.8934\n",
      "Validation loss: 0.01876 - pearson: 0.8519\n",
      "Total time: 1:6:39\n",
      "\n",
      "Epoch 4/5\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01971 - pearson: 0.8385\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.01919 - pearson: 0.8411\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02005 - pearson: 0.8406\n",
      "\n",
      "100/1710 - remain: 0:25:14 - loss: 0.01205 - pearson: 0.9015 - lr: 9.545032675245814e-06\n",
      "200/1710 - remain: 0:18:13 - loss: 0.01254 - pearson: 0.8986 - lr: 9.35992172723751e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.02188 - pearson: 0.8331\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.02166 - pearson: 0.8339\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02259 - pearson: 0.8349\n",
      "\n",
      "300/1710 - remain: 0:18:41 - loss: 0.01306 - pearson: 0.8978 - lr: 9.145758522448522e-06\n",
      "400/1710 - remain: 0:15:44 - loss: 0.01317 - pearson: 0.8963 - lr: 8.903970133383297e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01981 - pearson: 0.8404\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.01976 - pearson: 0.8384\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02042 - pearson: 0.8411\n",
      "\n",
      "500/1710 - remain: 0:15:23 - loss: 0.01329 - pearson: 0.8936 - lr: 8.636167712444374e-06\n",
      "600/1710 - remain: 0:13:18 - loss: 0.01336 - pearson: 0.8917 - lr: 8.344135756048513e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01849 - pearson: 0.846\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.0183 - pearson: 0.8446\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01905 - pearson: 0.8464\n",
      "\n",
      "700/1710 - remain: 0:12:36 - loss: 0.01326 - pearson: 0.8925 - lr: 8.029820213668239e-06\n",
      "800/1710 - remain: 0:10:53 - loss: 0.01327 - pearson: 0.8923 - lr: 7.695315521033981e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01809 - pearson: 0.846\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01783 - pearson: 0.8464\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01854 - pearson: 0.8487\n",
      "\n",
      "900/1710 - remain: 0:10:2 - loss: 0.01315 - pearson: 0.8933 - lr: 7.3428506439008e-06\n",
      "1000/1710 - remain: 0:8:30 - loss: 0.01312 - pearson: 0.8931 - lr: 6.974774225376823e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01976 - pearson: 0.8456\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01958 - pearson: 0.8449\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02031 - pearson: 0.8455\n",
      "\n",
      "1100/1710 - remain: 0:7:31 - loss: 0.01316 - pearson: 0.8929 - lr: 6.593538935783872e-06\n",
      "1200/1710 - remain: 0:6:7 - loss: 0.01326 - pearson: 0.8922 - lr: 6.201685129334714e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01872 - pearson: 0.8461\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.01858 - pearson: 0.8465\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01932 - pearson: 0.8477\n",
      "\n",
      "1300/1710 - remain: 0:5:1 - loss: 0.01311 - pearson: 0.8934 - lr: 5.801823916530332e-06\n",
      "1400/1710 - remain: 0:3:42 - loss: 0.01309 - pearson: 0.8932 - lr: 5.396619765073997e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01851 - pearson: 0.8496\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01798 - pearson: 0.8517\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01883 - pearson: 0.8529\n",
      "'best_value' is improved by 0.0009686306621893293! New 'best_value': 0.8528688445022157. Checkpoint path: './fold_3/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1500/1710 - remain: 0:2:37 - loss: 0.01303 - pearson: 0.8934 - lr: 4.988772745240638e-06\n",
      "1600/1710 - remain: 0:1:20 - loss: 0.01298 - pearson: 0.8938 - lr: 4.581000538009112e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.02017 - pearson: 0.8483\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.01983 - pearson: 0.8502\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02083 - pearson: 0.8501\n",
      "\n",
      "1700/1710 - remain: 0:0:6 - loss: 0.01295 - pearson: 0.8941 - lr: 4.176020325845912e-06\n",
      "1710/1710 - remain: 0:0:0 - loss: 0.01296 - pearson: 0.8937 - lr: 4.135780017681404e-06\n",
      "\n",
      "Training loss: 0.01296 - pearson: 0.8937\n",
      "Validation loss: 0.01883 - pearson: 0.8529\n",
      "Total time: 1:27:51\n",
      "\n",
      "Epoch 5/5\n",
      "\n",
      "100/1710 - remain: 0:13:27 - loss: 0.009015 - pearson: 0.9264 - lr: 3.736986603840017e-06\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01816 - pearson: 0.8512\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.0175 - pearson: 0.8543\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01829 - pearson: 0.8552\n",
      "'best_value' is improved by 0.0022867699810681374! New 'best_value': 0.8551556144832838. Checkpoint path: './fold_3/checkpoints/checkpoint.pth'.\n",
      "\n",
      "200/1710 - remain: 0:21:2 - loss: 0.009159 - pearson: 0.9245 - lr: 3.346609256111345e-06\n",
      "300/1710 - remain: 0:17:1 - loss: 0.008826 - pearson: 0.9287 - lr: 2.967249246641334e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01828 - pearson: 0.8514\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01773 - pearson: 0.8544\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01859 - pearson: 0.8551\n",
      "\n",
      "400/1710 - remain: 0:16:58 - loss: 0.008715 - pearson: 0.9281 - lr: 2.601434433748771e-06\n",
      "500/1710 - remain: 0:14:33 - loss: 0.008737 - pearson: 0.927 - lr: 2.2516024175887065e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01792 - pearson: 0.8553\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.01752 - pearson: 0.8572\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01845 - pearson: 0.8571\n",
      "'best_value' is improved by 0.0019859970382425374! New 'best_value': 0.8571416115215263. Checkpoint path: './fold_3/checkpoints/checkpoint.pth'.\n",
      "\n",
      "600/1710 - remain: 0:14:42 - loss: 0.008719 - pearson: 0.9279 - lr: 1.9200842972494793e-06\n",
      "700/1710 - remain: 0:12:39 - loss: 0.008662 - pearson: 0.9284 - lr: 1.6090891375175916e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01761 - pearson: 0.8553\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01729 - pearson: 0.8568\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.0182 - pearson: 0.8569\n",
      "\n",
      "800/1710 - remain: 0:11:44 - loss: 0.008595 - pearson: 0.9285 - lr: 1.3206892488158751e-06\n",
      "900/1710 - remain: 0:10:2 - loss: 0.008596 - pearson: 0.9286 - lr: 1.0568063784017952e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01842 - pearson: 0.8536\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01809 - pearson: 0.8552\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01901 - pearson: 0.8551\n",
      "\n",
      "1000/1710 - remain: 0:9:1 - loss: 0.008527 - pearson: 0.9289 - lr: 8.191989048405902e-07\n",
      "1100/1710 - remain: 0:7:30 - loss: 0.008515 - pearson: 0.929 - lr: 6.094501210826336e-07\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01805 - pearson: 0.8549\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01767 - pearson: 0.8567\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01858 - pearson: 0.8566\n",
      "\n",
      "1200/1710 - remain: 0:6:24 - loss: 0.008476 - pearson: 0.9297 - lr: 4.289576842205062e-07\n",
      "1300/1710 - remain: 0:5:1 - loss: 0.008476 - pearson: 0.9294 - lr: 2.7892430222713596e-07\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01787 - pearson: 0.855\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01748 - pearson: 0.857\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01839 - pearson: 0.8571\n",
      "\n",
      "1400/1710 - remain: 0:3:51 - loss: 0.008471 - pearson: 0.9293 - lr: 1.6034971973374337e-07\n",
      "1500/1710 - remain: 0:2:33 - loss: 0.008505 - pearson: 0.9287 - lr: 7.402405625021314e-08\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.0178 - pearson: 0.8553\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.0174 - pearson: 0.8573\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.0183 - pearson: 0.8573\n",
      "'best_value' is improved by 0.00020025821653157916! New 'best_value': 0.8573418697380579. Checkpoint path: './fold_3/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1600/1710 - remain: 0:1:23 - loss: 0.008485 - pearson: 0.9288 - lr: 2.052254121853725e-08\n",
      "1700/1710 - remain: 0:0:7 - loss: 0.008463 - pearson: 0.9291 - lr: 2.0168098219974787e-10\n",
      "1710/1710 - remain: 0:0:0 - loss: 0.008453 - pearson: 0.9291 - lr: 1.6667960894833912e-12\n",
      "\n",
      "Training loss: 0.008453 - pearson: 0.9291\n",
      "Validation loss: 0.0183 - pearson: 0.8573\n",
      "Total time: 1:48:59\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Fold 4/4\n",
      "\n",
      "Train samples: 27355\n",
      "Validation samples: 9118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Checkpointing: True\n",
      "Epochs: 5\n",
      "Auto Mixed Precision: True\n",
      "Gradient norm: 1.0\n",
      "Gradient scaling: True\n",
      "Gradient accumulation steps: 1\n",
      "Validation steps: 200\n",
      "Device: cuda\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "\n",
      "100/1710 - remain: 0:13:51 - loss: 0.1125 - pearson: 0.04696 - lr: 1.1578947368421053e-06\n",
      "200/1710 - remain: 0:12:50 - loss: 0.08907 - pearson: 0.09661 - lr: 2.3274853801169592e-06\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.05404 - pearson: 0.5568\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.05522 - pearson: 0.5479\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.05533 - pearson: 0.5228\n",
      "'best_value' is improved by inf! New 'best_value': 0.5228491004310617. Checkpoint path: './fold_4/checkpoints/checkpoint.pth'.\n",
      "\n",
      "300/1710 - remain: 0:16:36 - loss: 0.07706 - pearson: 0.2228 - lr: 3.497076023391813e-06\n",
      "400/1710 - remain: 0:14:21 - loss: 0.06807 - pearson: 0.3253 - lr: 4.666666666666667e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.03426 - pearson: 0.7087\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.03518 - pearson: 0.6964\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.0362 - pearson: 0.686\n",
      "'best_value' is improved by 0.16310324070854365! New 'best_value': 0.6859523411396053. Checkpoint path: './fold_4/checkpoints/checkpoint.pth'.\n",
      "\n",
      "500/1710 - remain: 0:15:3 - loss: 0.06144 - pearson: 0.3951 - lr: 5.836257309941521e-06\n",
      "600/1710 - remain: 0:13:3 - loss: 0.05718 - pearson: 0.4442 - lr: 7.005847953216375e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.03418 - pearson: 0.7575\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.03417 - pearson: 0.7509\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.03483 - pearson: 0.7447\n",
      "'best_value' is improved by 0.05872543862846524! New 'best_value': 0.7446777797680706. Checkpoint path: './fold_4/checkpoints/checkpoint.pth'.\n",
      "\n",
      "700/1710 - remain: 0:12:50 - loss: 0.05331 - pearson: 0.4882 - lr: 8.175438596491229e-06\n",
      "800/1710 - remain: 0:11:5 - loss: 0.05068 - pearson: 0.5175 - lr: 9.345029239766083e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.02604 - pearson: 0.7921\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.02711 - pearson: 0.7814\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02784 - pearson: 0.7774\n",
      "'best_value' is improved by 0.03272760688422771! New 'best_value': 0.7774053866522983. Checkpoint path: './fold_4/checkpoints/checkpoint.pth'.\n",
      "\n",
      "900/1710 - remain: 0:10:25 - loss: 0.04842 - pearson: 0.5428 - lr: 9.99677342967605e-06\n",
      "1000/1710 - remain: 0:8:49 - loss: 0.0465 - pearson: 0.5632 - lr: 9.965477115326678e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.02463 - pearson: 0.802\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.02574 - pearson: 0.796\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02639 - pearson: 0.7944\n",
      "'best_value' is improved by 0.01697262221484208! New 'best_value': 0.7943780088671404. Checkpoint path: './fold_4/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1100/1710 - remain: 0:7:54 - loss: 0.04499 - pearson: 0.5808 - lr: 9.901093437208395e-06\n",
      "1200/1710 - remain: 0:6:25 - loss: 0.04339 - pearson: 0.5969 - lr: 9.804051414754617e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.02173 - pearson: 0.8169\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.02243 - pearson: 0.8088\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02319 - pearson: 0.8089\n",
      "'best_value' is improved by 0.014514959734237776! New 'best_value': 0.8088929686013782. Checkpoint path: './fold_4/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1300/1710 - remain: 0:5:21 - loss: 0.04216 - pearson: 0.6109 - lr: 9.67499768566465e-06\n",
      "1400/1710 - remain: 0:3:56 - loss: 0.04104 - pearson: 0.6222 - lr: 9.51479219704548e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.02139 - pearson: 0.8243\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.02245 - pearson: 0.8152\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.0234 - pearson: 0.8149\n",
      "'best_value' is improved by 0.0060368340074401505! New 'best_value': 0.8149298026088183. Checkpoint path: './fold_4/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1500/1710 - remain: 0:2:44 - loss: 0.03997 - pearson: 0.6327 - lr: 9.324502475170332e-06\n",
      "1600/1710 - remain: 0:1:24 - loss: 0.03907 - pearson: 0.6419 - lr: 9.10539651203735e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01899 - pearson: 0.8363\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.02007 - pearson: 0.8284\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02092 - pearson: 0.8289\n",
      "'best_value' is improved by 0.013962492389926306! New 'best_value': 0.8288922949987446. Checkpoint path: './fold_4/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1700/1710 - remain: 0:0:7 - loss: 0.03814 - pearson: 0.6512 - lr: 8.85893431612864e-06\n",
      "1710/1710 - remain: 0:0:0 - loss: 0.03804 - pearson: 0.6522 - lr: 8.832845209850547e-06\n",
      "\n",
      "Training loss: 0.03804 - pearson: 0.6522\n",
      "Validation loss: 0.02092 - pearson: 0.8289\n",
      "Total time: 0:22:24\n",
      "\n",
      "Epoch 2/5\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01861 - pearson: 0.841\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01967 - pearson: 0.8322\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02067 - pearson: 0.8304\n",
      "'best_value' is improved by 0.001540872268808724! New 'best_value': 0.8304331672675533. Checkpoint path: './fold_4/checkpoints/checkpoint.pth'.\n",
      "\n",
      "100/1710 - remain: 0:29:46 - loss: 0.01986 - pearson: 0.8391 - lr: 8.558194707848636e-06\n",
      "200/1710 - remain: 0:20:11 - loss: 0.01994 - pearson: 0.8335 - lr: 8.2598342420457e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.02188 - pearson: 0.8369\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.02338 - pearson: 0.825\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02442 - pearson: 0.8241\n",
      "\n",
      "300/1710 - remain: 0:19:48 - loss: 0.01979 - pearson: 0.8354 - lr: 7.939751931818186e-06\n",
      "400/1710 - remain: 0:16:32 - loss: 0.01932 - pearson: 0.8388 - lr: 7.600080639646077e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.02001 - pearson: 0.8468\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.02106 - pearson: 0.8359\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02195 - pearson: 0.8357\n",
      "'best_value' is improved by 0.00522114053306344! New 'best_value': 0.8356543078006168. Checkpoint path: './fold_4/checkpoints/checkpoint.pth'.\n",
      "\n",
      "500/1710 - remain: 0:16:38 - loss: 0.01899 - pearson: 0.8406 - lr: 7.243083758823699e-06\n",
      "600/1710 - remain: 0:14:14 - loss: 0.01897 - pearson: 0.8416 - lr: 6.871140131380888e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01885 - pearson: 0.8506\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01982 - pearson: 0.8393\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02069 - pearson: 0.8388\n",
      "'best_value' is improved by 0.003180592966822271! New 'best_value': 0.838834900767439. Checkpoint path: './fold_4/checkpoints/checkpoint.pth'.\n",
      "\n",
      "700/1710 - remain: 0:13:44 - loss: 0.01899 - pearson: 0.842 - lr: 6.486728196713679e-06\n",
      "800/1710 - remain: 0:11:46 - loss: 0.0189 - pearson: 0.8422 - lr: 6.0924094765497985e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01844 - pearson: 0.8526\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.0194 - pearson: 0.8426\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02019 - pearson: 0.8426\n",
      "'best_value' is improved by 0.0037739933782788837! New 'best_value': 0.8426088941457179. Checkpoint path: './fold_4/checkpoints/checkpoint.pth'.\n",
      "\n",
      "900/1710 - remain: 0:10:58 - loss: 0.01895 - pearson: 0.8398 - lr: 5.690811506296609e-06\n",
      "1000/1710 - remain: 0:9:15 - loss: 0.01899 - pearson: 0.8397 - lr: 5.284610326508117e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01754 - pearson: 0.8549\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01849 - pearson: 0.8461\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01915 - pearson: 0.8469\n",
      "'best_value' is improved by 0.004332776401137939! New 'best_value': 0.8469416705468559. Checkpoint path: './fold_4/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1100/1710 - remain: 0:8:16 - loss: 0.01895 - pearson: 0.8402 - lr: 4.87651265113887e-06\n",
      "1200/1710 - remain: 0:6:42 - loss: 0.01879 - pearson: 0.8415 - lr: 4.469237831406198e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.0184 - pearson: 0.8514\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01918 - pearson: 0.844\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01988 - pearson: 0.8451\n",
      "\n",
      "1300/1710 - remain: 0:5:27 - loss: 0.01869 - pearson: 0.8431 - lr: 4.065499735444305e-06\n",
      "1400/1710 - remain: 0:4:0 - loss: 0.01853 - pearson: 0.8444 - lr: 3.667988664494785e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01725 - pearson: 0.8562\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01802 - pearson: 0.849\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01872 - pearson: 0.85\n",
      "'best_value' is improved by 0.003026539683790186! New 'best_value': 0.8499682102306461. Checkpoint path: './fold_4/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1500/1710 - remain: 0:2:47 - loss: 0.01844 - pearson: 0.8455 - lr: 3.279353426134673e-06\n",
      "1600/1710 - remain: 0:1:25 - loss: 0.01834 - pearson: 0.8454 - lr: 2.9021836839967644e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01742 - pearson: 0.8598\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.01833 - pearson: 0.8507\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.0191 - pearson: 0.8514\n",
      "'best_value' is improved by 0.0014380263899411716! New 'best_value': 0.8514062366205872. Checkpoint path: './fold_4/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1700/1710 - remain: 0:0:7 - loss: 0.01822 - pearson: 0.8463 - lr: 2.5389927015944937e-06\n",
      "1710/1710 - remain: 0:0:0 - loss: 0.01822 - pearson: 0.8466 - lr: 2.5035365042804726e-06\n",
      "\n",
      "Training loss: 0.01822 - pearson: 0.8466\n",
      "Validation loss: 0.0191 - pearson: 0.8514\n",
      "Total time: 0:45:10\n",
      "\n",
      "Epoch 3/5\n",
      "\n",
      "100/1710 - remain: 0:13:36 - loss: 0.01101 - pearson: 0.913 - lr: 2.158513320853839e-06\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01744 - pearson: 0.8599\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01836 - pearson: 0.8507\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01917 - pearson: 0.8509\n",
      "\n",
      "200/1710 - remain: 0:18:6 - loss: 0.01158 - pearson: 0.9049 - lr: 1.8324243307008454e-06\n",
      "300/1710 - remain: 0:15:12 - loss: 0.01194 - pearson: 0.8996 - lr: 1.5274424217006701e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.0171 - pearson: 0.8616\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01803 - pearson: 0.853\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01878 - pearson: 0.8536\n",
      "'best_value' is improved by 0.00216442733443023! New 'best_value': 0.8535706639550175. Checkpoint path: './fold_4/checkpoints/checkpoint.pth'.\n",
      "\n",
      "400/1710 - remain: 0:16:40 - loss: 0.0121 - pearson: 0.8983 - lr: 1.2455998350925042e-06\n",
      "500/1710 - remain: 0:14:20 - loss: 0.01233 - pearson: 0.8963 - lr: 9.88774623674112e-07\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01712 - pearson: 0.8607\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01809 - pearson: 0.852\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01882 - pearson: 0.8528\n",
      "\n",
      "600/1710 - remain: 0:13:49 - loss: 0.01224 - pearson: 0.8974 - lr: 7.586781374321844e-07\n",
      "700/1710 - remain: 0:12:0 - loss: 0.01229 - pearson: 0.8957 - lr: 5.568436199937521e-07\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01698 - pearson: 0.8608\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01782 - pearson: 0.8528\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01857 - pearson: 0.8534\n",
      "\n",
      "800/1710 - remain: 0:11:13 - loss: 0.01228 - pearson: 0.8951 - lr: 3.8461599188598707e-07\n",
      "900/1710 - remain: 0:9:38 - loss: 0.01224 - pearson: 0.8955 - lr: 2.431428886834575e-07\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01724 - pearson: 0.8612\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01811 - pearson: 0.8527\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01888 - pearson: 0.8532\n",
      "\n",
      "1000/1710 - remain: 0:8:42 - loss: 0.01222 - pearson: 0.8963 - lr: 1.333670137599713e-07\n",
      "1100/1710 - remain: 0:7:15 - loss: 0.01216 - pearson: 0.8962 - lr: 5.601985660229514e-08\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01717 - pearson: 0.8612\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01804 - pearson: 0.8528\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.0188 - pearson: 0.8533\n",
      "\n",
      "1200/1710 - remain: 0:6:13 - loss: 0.01219 - pearson: 0.8963 - lr: 1.161681854366048e-08\n",
      "1300/1710 - remain: 0:4:52 - loss: 0.01223 - pearson: 0.8962 - lr: 9.99954622160337e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01835 - pearson: 0.8558\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01937 - pearson: 0.846\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02017 - pearson: 0.8455\n",
      "\n",
      "1400/1710 - remain: 0:3:45 - loss: 0.01235 - pearson: 0.895 - lr: 9.97739487912983e-06\n",
      "1500/1710 - remain: 0:2:30 - loss: 0.01247 - pearson: 0.8943 - lr: 9.922076759091456e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.0203 - pearson: 0.8493\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.02074 - pearson: 0.8412\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02151 - pearson: 0.8402\n",
      "\n",
      "1600/1710 - remain: 0:1:20 - loss: 0.0126 - pearson: 0.8933 - lr: 9.833960472745178e-06\n",
      "1700/1710 - remain: 0:0:7 - loss: 0.01277 - pearson: 0.8923 - lr: 9.713633181314904e-06\n",
      "1710/1710 - remain: 0:0:0 - loss: 0.01277 - pearson: 0.8924 - lr: 9.699857883137968e-06\n",
      "\n",
      "Training loss: 0.01277 - pearson: 0.8924\n",
      "Validation loss: 0.01878 - pearson: 0.8536\n",
      "Total time: 1:5:29\n",
      "\n",
      "Epoch 4/5\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01755 - pearson: 0.8519\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01867 - pearson: 0.8418\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01936 - pearson: 0.8434\n",
      "\n",
      "100/1710 - remain: 0:25:1 - loss: 0.01239 - pearson: 0.8891 - lr: 9.545032675245814e-06\n",
      "200/1710 - remain: 0:18:5 - loss: 0.01349 - pearson: 0.882 - lr: 9.35992172723751e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01823 - pearson: 0.8461\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.0191 - pearson: 0.8393\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01969 - pearson: 0.8423\n",
      "\n",
      "300/1710 - remain: 0:18:35 - loss: 0.01347 - pearson: 0.8802 - lr: 9.145758522448522e-06\n",
      "400/1710 - remain: 0:15:40 - loss: 0.0131 - pearson: 0.8862 - lr: 8.903970133383297e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01808 - pearson: 0.8568\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01908 - pearson: 0.8477\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01988 - pearson: 0.8492\n",
      "\n",
      "500/1710 - remain: 0:15:20 - loss: 0.01304 - pearson: 0.8889 - lr: 8.636167712444374e-06\n",
      "600/1710 - remain: 0:13:17 - loss: 0.01293 - pearson: 0.8914 - lr: 8.344135756048513e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01887 - pearson: 0.8507\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01982 - pearson: 0.8421\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02035 - pearson: 0.8438\n",
      "\n",
      "700/1710 - remain: 0:12:37 - loss: 0.013 - pearson: 0.8907 - lr: 8.029820213668239e-06\n",
      "800/1710 - remain: 0:10:53 - loss: 0.01303 - pearson: 0.8907 - lr: 7.695315521033981e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01873 - pearson: 0.8521\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.01935 - pearson: 0.8454\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.02017 - pearson: 0.8448\n",
      "\n",
      "900/1710 - remain: 0:10:0 - loss: 0.0131 - pearson: 0.8899 - lr: 7.3428506439008e-06\n",
      "1000/1710 - remain: 0:8:30 - loss: 0.01306 - pearson: 0.8904 - lr: 6.974774225376823e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01778 - pearson: 0.8553\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.01851 - pearson: 0.8491\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01945 - pearson: 0.8484\n",
      "\n",
      "1100/1710 - remain: 0:7:29 - loss: 0.01311 - pearson: 0.8902 - lr: 6.593538935783872e-06\n",
      "1200/1710 - remain: 0:6:6 - loss: 0.01315 - pearson: 0.8893 - lr: 6.201685129334714e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01764 - pearson: 0.8599\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01844 - pearson: 0.8524\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.0194 - pearson: 0.8507\n",
      "\n",
      "1300/1710 - remain: 0:5:0 - loss: 0.01331 - pearson: 0.8876 - lr: 5.801823916530332e-06\n",
      "1400/1710 - remain: 0:3:42 - loss: 0.01325 - pearson: 0.8884 - lr: 5.396619765073997e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01649 - pearson: 0.8654\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.01746 - pearson: 0.8563\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01857 - pearson: 0.8553\n",
      "'best_value' is improved by 0.0016948611831866245! New 'best_value': 0.8552655251382041. Checkpoint path: './fold_4/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1500/1710 - remain: 0:2:35 - loss: 0.01319 - pearson: 0.889 - lr: 4.988772745240638e-06\n",
      "1600/1710 - remain: 0:1:19 - loss: 0.0132 - pearson: 0.889 - lr: 4.581000538009112e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01697 - pearson: 0.862\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.01789 - pearson: 0.8542\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01883 - pearson: 0.8541\n",
      "\n",
      "1700/1710 - remain: 0:0:7 - loss: 0.01318 - pearson: 0.8896 - lr: 4.176020325845912e-06\n",
      "1710/1710 - remain: 0:0:0 - loss: 0.0132 - pearson: 0.8896 - lr: 4.135780017681404e-06\n",
      "\n",
      "Training loss: 0.0132 - pearson: 0.8896\n",
      "Validation loss: 0.01857 - pearson: 0.8553\n",
      "Total time: 1:26:30\n",
      "\n",
      "Epoch 5/5\n",
      "\n",
      "100/1710 - remain: 0:13:15 - loss: 0.008938 - pearson: 0.9313 - lr: 3.736986603840017e-06\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01623 - pearson: 0.866\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01698 - pearson: 0.8592\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01801 - pearson: 0.8586\n",
      "'best_value' is improved by 0.003354125025330168! New 'best_value': 0.8586196501635343. Checkpoint path: './fold_4/checkpoints/checkpoint.pth'.\n",
      "\n",
      "200/1710 - remain: 0:19:59 - loss: 0.008816 - pearson: 0.9294 - lr: 3.346609256111345e-06\n",
      "300/1710 - remain: 0:16:21 - loss: 0.008861 - pearson: 0.9276 - lr: 2.967249246641334e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01617 - pearson: 0.8658\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01715 - pearson: 0.8578\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01811 - pearson: 0.858\n",
      "\n",
      "400/1710 - remain: 0:16:31 - loss: 0.008703 - pearson: 0.9281 - lr: 2.601434433748771e-06\n",
      "500/1710 - remain: 0:14:13 - loss: 0.008687 - pearson: 0.9281 - lr: 2.2516024175887065e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01607 - pearson: 0.869\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01712 - pearson: 0.8599\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01816 - pearson: 0.8592\n",
      "'best_value' is improved by 0.0005864942511943916! New 'best_value': 0.8592061444147286. Checkpoint path: './fold_4/checkpoints/checkpoint.pth'.\n",
      "\n",
      "600/1710 - remain: 0:14:17 - loss: 0.008683 - pearson: 0.9287 - lr: 1.9200842972494793e-06\n",
      "700/1710 - remain: 0:12:19 - loss: 0.008673 - pearson: 0.9293 - lr: 1.6090891375175916e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01595 - pearson: 0.8687\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.01694 - pearson: 0.8603\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01793 - pearson: 0.8598\n",
      "'best_value' is improved by 0.0005548477485818326! New 'best_value': 0.8597609921633105. Checkpoint path: './fold_4/checkpoints/checkpoint.pth'.\n",
      "\n",
      "800/1710 - remain: 0:11:49 - loss: 0.008745 - pearson: 0.9286 - lr: 1.3206892488158751e-06\n",
      "900/1710 - remain: 0:10:6 - loss: 0.008642 - pearson: 0.9292 - lr: 1.0568063784017952e-06\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.0161 - pearson: 0.8686\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01713 - pearson: 0.8594\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01809 - pearson: 0.8591\n",
      "\n",
      "1000/1710 - remain: 0:9:4 - loss: 0.008578 - pearson: 0.9297 - lr: 8.191989048405902e-07\n",
      "1100/1710 - remain: 0:7:33 - loss: 0.008586 - pearson: 0.9293 - lr: 6.094501210826336e-07\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01603 - pearson: 0.8696\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01714 - pearson: 0.8598\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01814 - pearson: 0.8594\n",
      "\n",
      "1200/1710 - remain: 0:6:27 - loss: 0.008612 - pearson: 0.9287 - lr: 4.289576842205062e-07\n",
      "1300/1710 - remain: 0:5:3 - loss: 0.00871 - pearson: 0.9278 - lr: 2.7892430222713596e-07\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:27 - loss: 0.01594 - pearson: 0.8696\n",
      "[Validation] 200/285 - remain: 0:0:12 - loss: 0.01699 - pearson: 0.8603\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01798 - pearson: 0.8599\n",
      "'best_value' is improved by 0.00017475258324584075! New 'best_value': 0.8599357447465563. Checkpoint path: './fold_4/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1400/1710 - remain: 0:3:57 - loss: 0.008715 - pearson: 0.9274 - lr: 1.6034971973374337e-07\n",
      "1500/1710 - remain: 0:2:37 - loss: 0.00868 - pearson: 0.9274 - lr: 7.402405625021314e-08\n",
      "\n",
      "[Validation] 100/285 - remain: 0:0:28 - loss: 0.01591 - pearson: 0.8698\n",
      "[Validation] 200/285 - remain: 0:0:13 - loss: 0.01696 - pearson: 0.8606\n",
      "[Validation] 285/285 - remain: 0:0:0 - loss: 0.01795 - pearson: 0.8602\n",
      "'best_value' is improved by 0.0002946461235442399! New 'best_value': 0.8602303908701006. Checkpoint path: './fold_4/checkpoints/checkpoint.pth'.\n",
      "\n",
      "1600/1710 - remain: 0:1:25 - loss: 0.008673 - pearson: 0.9275 - lr: 2.052254121853725e-08\n",
      "1700/1710 - remain: 0:0:7 - loss: 0.008628 - pearson: 0.9277 - lr: 2.0168098219974787e-10\n",
      "1710/1710 - remain: 0:0:0 - loss: 0.008617 - pearson: 0.9278 - lr: 1.6667960894833912e-12\n",
      "\n",
      "Training loss: 0.008617 - pearson: 0.9278\n",
      "Validation loss: 0.01795 - pearson: 0.8602\n",
      "Total time: 1:48:0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CV scores: [0.8698 0.8597 0.8573 0.8602]\n",
      "CV mean: 0.8618\n",
      "CV std: 0.004775\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "oof_data_frame = pd.DataFrame()\n",
    "for fold in range(1, config.folds + 1):\n",
    "    print(f\"Fold {fold}/{config.folds}\", end=\"\\n\"*2)\n",
    "    \n",
    "    fold_directory = os.path.join(config.output_directory, f\"fold_{fold}\")    \n",
    "    make_directory(fold_directory)\n",
    "    model_path = os.path.join(fold_directory, \"model.pth\")\n",
    "    model_config_path = os.path.join(fold_directory, \"model_config.json\")\n",
    "    checkpoints_directory = os.path.join(fold_directory, \"checkpoints/\")\n",
    "    make_directory(checkpoints_directory)\n",
    "    \n",
    "    collator = Collator(tokenizer=tokenizer, max_length=config.max_length)\n",
    "    \n",
    "    train_fold = train[~train[\"fold\"].isin([fold])]\n",
    "    train_dataset = Dataset(texts=train_fold[\"anchor\"].values, \n",
    "                            pair_texts=train_fold[\"target\"].values,\n",
    "                            contexts=train_fold[\"title\"].values,\n",
    "                            targets=train_fold[\"score\"].values, \n",
    "                            max_length=config.max_length,\n",
    "                            sep=tokenizer.sep_token,\n",
    "                            tokenizer=tokenizer)\n",
    "    \n",
    "    train_loader = DataLoader(dataset=train_dataset, \n",
    "                              batch_size=config.batch_size, \n",
    "                              num_workers=config.num_workers,\n",
    "                              pin_memory=config.pin_memory,\n",
    "                              collate_fn=collator,\n",
    "                              shuffle=True, \n",
    "                              drop_last=False)\n",
    "    \n",
    "    print(f\"Train samples: {len(train_dataset)}\")\n",
    "    \n",
    "    validation_fold = train[train[\"fold\"].isin([fold])]\n",
    "    validation_dataset = Dataset(texts=validation_fold[\"anchor\"].values, \n",
    "                                 pair_texts=validation_fold[\"target\"].values,\n",
    "                                 contexts=validation_fold[\"title\"].values,\n",
    "                                 targets=validation_fold[\"score\"].values,\n",
    "                                 max_length=config.max_length,\n",
    "                                 sep=tokenizer.sep_token,\n",
    "                                 tokenizer=tokenizer)\n",
    "    \n",
    "    validation_loader = DataLoader(dataset=validation_dataset, \n",
    "                                   batch_size=config.batch_size*2, \n",
    "                                   num_workers=config.num_workers,\n",
    "                                   pin_memory=config.pin_memory,\n",
    "                                   collate_fn=collator,\n",
    "                                   shuffle=False, \n",
    "                                   drop_last=False)\n",
    "    \n",
    "    print(f\"Validation samples: {len(validation_dataset)}\")\n",
    "    \n",
    "    \n",
    "    model = Model(**config.model)\n",
    "    model.config.to_json_file(model_config_path)\n",
    "    model_parameters = model.parameters()\n",
    "    \n",
    "    optimizer = get_optimizer(**config.optimizer, model_parameters=model_parameters)\n",
    "    \n",
    "    if \"scheduler\" in config:\n",
    "        training_steps = len(train_loader) * config.epochs\n",
    "        training_steps = int(training_steps // config.gradient_accumulation_steps)\n",
    "        \n",
    "        config.scheduler.parameters.num_training_steps = training_steps\n",
    "        config.scheduler.parameters.num_warmup_steps = training_steps * config.get(\"warmup\", 0)\n",
    "        scheduler = get_scheduler(**config.scheduler, optimizer=optimizer, from_transformers=True)\n",
    "    else:\n",
    "        scheduler = None\n",
    "        \n",
    "    model_checkpoint = ModelCheckpoint(mode=\"max\", \n",
    "                                       delta=config.delta, \n",
    "                                       directory=checkpoints_directory, \n",
    "                                       overwriting=True, \n",
    "                                       filename_format=\"checkpoint.pth\", \n",
    "                                       num_candidates=1)\n",
    "\n",
    "\n",
    "    if WANDB: wandb.init(group=EXPERIMENT_NAME, name=f\"Fold {fold}\", config=config)\n",
    "    (train_loss, train_metrics), (validation_loss, validation_metrics, validation_outputs) = training_loop(model=model, \n",
    "                                                                                                           optimizer=optimizer, \n",
    "                                                                                                           scheduler=scheduler,\n",
    "                                                                                                           scheduling_after=config.scheduling_after,\n",
    "                                                                                                           train_loader=train_loader,\n",
    "                                                                                                           validation_loader=validation_loader,\n",
    "                                                                                                           epochs=config.epochs, \n",
    "                                                                                                           gradient_accumulation_steps=config.gradient_accumulation_steps, \n",
    "                                                                                                           gradient_scaling=config.gradient_scaling, \n",
    "                                                                                                           gradient_norm=config.gradient_norm, \n",
    "                                                                                                           validation_steps=config.validation_steps, \n",
    "                                                                                                           amp=config.amp,\n",
    "                                                                                                           debug=config.debug, \n",
    "                                                                                                           verbose=config.verbose, \n",
    "                                                                                                           device=config.device, \n",
    "                                                                                                           recalculate_metrics_at_end=True, \n",
    "                                                                                                           return_validation_outputs=True, \n",
    "                                                                                                           logger=[\"print\", \"wandb\"], \n",
    "                                                                                                           decimals=config.decimals)\n",
    "    \n",
    "    if WANDB: wandb.finish()\n",
    "    \n",
    "    if config.save_model:\n",
    "        model_state = model.state_dict()\n",
    "        torch.save(model_state, model_path)\n",
    "        print(f\"Model's path: {model_path}\")\n",
    "    \n",
    "    validation_fold[\"prediction\"] = validation_outputs.to(\"cpu\").numpy()\n",
    "    oof_data_frame = pd.concat([oof_data_frame, validation_fold])\n",
    "        \n",
    "    cv_monitor_value = validation_loss if config.cv_monitor_value == \"loss\" else validation_metrics.get(config.cv_monitor_value, np.nan)\n",
    "    cv_scores.append(cv_monitor_value)\n",
    "    \n",
    "    \n",
    "    del model, optimizer, validation_outputs, train_fold, validation_fold\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(end=\"\\n\"*5)\n",
    "    \n",
    "cv_scores = np.array(cv_scores).round(config.decimals)\n",
    "np.save(\"cv_scores.npy\", cv_scores)\n",
    "oof_data_frame.to_pickle(\"oof.pkl\")\n",
    "configuration_path = config.to_json(\"configuration.json\")\n",
    "\n",
    "print(f\"CV scores: {cv_scores}\")\n",
    "print(f\"CV mean: {cv_scores.mean():.{config.decimals}}\")\n",
    "print(f\"CV std: {cv_scores.std():.{config.decimals}}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2fba0c",
   "metadata": {
    "papermill": {
     "duration": 0.376261,
     "end_time": "2022-06-06T01:59:45.158367",
     "exception": false,
     "start_time": "2022-06-06T01:59:44.782106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 26210.548208,
   "end_time": "2022-06-06T01:59:48.892925",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-05T18:42:58.344717",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "024cb3356abf449a8346145acde368e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_32acaa5aa2b94c90ba276117ad7236f2",
        "IPY_MODEL_bc52ab9f999b4e3e8178fa7076512eda",
        "IPY_MODEL_c1d85f265dc743be87ea5baba1415042"
       ],
       "layout": "IPY_MODEL_30daee8af17248a792a732249b64172d"
      }
     },
     "070b9e459d5e42c890a0ddca039c6b1d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_59f28e70032d400abd753d41b0aae2a1",
        "IPY_MODEL_337a3d8af39b46358fce40ffdc6ec75f",
        "IPY_MODEL_6aa63463949c40d7998af11259468770"
       ],
       "layout": "IPY_MODEL_4ff3b5858f5747fd9479713574052326"
      }
     },
     "0b19a9556d694e47b056b5bba50d01f4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0c69325c859d4119920a26c7218d5dc6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "13db8a20295947ed8b2841228541540c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6a71a0a49fe644e0acdd80c22ed8f68e",
        "IPY_MODEL_b0695bf326114c41873f646421aebff8",
        "IPY_MODEL_cdd0e51d1cab41e3a3d0098d389e29a6"
       ],
       "layout": "IPY_MODEL_c99085825ae5491284c31c6eb802dcc6"
      }
     },
     "14692814eb004b9b9daaf7de176f1b8f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "156b0180623f45338a0ff107e0315238": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_56eda5dd90904653acff29b99a4ecdf7",
       "placeholder": "​",
       "style": "IPY_MODEL_78c4ad66ad7a41cc96ed4a9103239e2a",
       "value": " 833M/833M [00:40&lt;00:00, 23.6MB/s]"
      }
     },
     "19868c57cd5d442da7b2515eec42dfc1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "207a6aa2d1634e3c8c097632e4e04f18": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2679880cbfa4414b9d0330835cc71483": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_810a8e1724bf405cb72a73addf6740e9",
       "max": 873673253.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c31399ded10a4c92a70354422cddd07a",
       "value": 873673253.0
      }
     },
     "2adcb40e071b48da87f8862440ebaf4d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2c726d26e5fd4906b9dcf605b765b21a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8d27d492bda84084ae8378fbe7006376",
        "IPY_MODEL_2679880cbfa4414b9d0330835cc71483",
        "IPY_MODEL_156b0180623f45338a0ff107e0315238"
       ],
       "layout": "IPY_MODEL_2adcb40e071b48da87f8862440ebaf4d"
      }
     },
     "30daee8af17248a792a732249b64172d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "32acaa5aa2b94c90ba276117ad7236f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_19868c57cd5d442da7b2515eec42dfc1",
       "placeholder": "​",
       "style": "IPY_MODEL_49b69debcc9d40e7b4cda161228ebf04",
       "value": "Downloading: 100%"
      }
     },
     "337a3d8af39b46358fce40ffdc6ec75f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0c69325c859d4119920a26c7218d5dc6",
       "max": 52.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3e70477a7c52441682a2546392f0fcce",
       "value": 52.0
      }
     },
     "37658b12a71b471ab4748e88f7b5f837": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3e70477a7c52441682a2546392f0fcce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "49b69debcc9d40e7b4cda161228ebf04": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4eebde99fbb64275ac3cdd4b3c72686c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4ff3b5858f5747fd9479713574052326": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "56eda5dd90904653acff29b99a4ecdf7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "59f28e70032d400abd753d41b0aae2a1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_37658b12a71b471ab4748e88f7b5f837",
       "placeholder": "​",
       "style": "IPY_MODEL_bd885870703d4c3590c475fc060bc934",
       "value": "Downloading: 100%"
      }
     },
     "6a71a0a49fe644e0acdd80c22ed8f68e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0b19a9556d694e47b056b5bba50d01f4",
       "placeholder": "​",
       "style": "IPY_MODEL_db0f2422d671498fa1034527f2c1b8e4",
       "value": "Downloading: 100%"
      }
     },
     "6aa63463949c40d7998af11259468770": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a1b4267b81e54060be7204688ce994da",
       "placeholder": "​",
       "style": "IPY_MODEL_feae02561c134ab78804d36b0641204d",
       "value": " 52.0/52.0 [00:00&lt;00:00, 2.11kB/s]"
      }
     },
     "6bd2cf992e7549338d1dd0b2d3e8f1ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "78c4ad66ad7a41cc96ed4a9103239e2a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7a596403c3904b3cb84c0f3e13baaff9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "810a8e1724bf405cb72a73addf6740e9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8633cabcda20429fbec8214981422a19": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8d27d492bda84084ae8378fbe7006376": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4eebde99fbb64275ac3cdd4b3c72686c",
       "placeholder": "​",
       "style": "IPY_MODEL_8633cabcda20429fbec8214981422a19",
       "value": "Downloading: 100%"
      }
     },
     "a1b4267b81e54060be7204688ce994da": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b0695bf326114c41873f646421aebff8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_14692814eb004b9b9daaf7de176f1b8f",
       "max": 580.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6bd2cf992e7549338d1dd0b2d3e8f1ba",
       "value": 580.0
      }
     },
     "bc52ab9f999b4e3e8178fa7076512eda": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f16ac5f5c2e64fa68347014863ed7e37",
       "max": 2464616.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d4cc113fca3b4048b07904323c71599a",
       "value": 2464616.0
      }
     },
     "bd885870703d4c3590c475fc060bc934": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c1d85f265dc743be87ea5baba1415042": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d34e668dd7ae40818298583fb496ebbb",
       "placeholder": "​",
       "style": "IPY_MODEL_207a6aa2d1634e3c8c097632e4e04f18",
       "value": " 2.35M/2.35M [00:01&lt;00:00, 3.16MB/s]"
      }
     },
     "c31399ded10a4c92a70354422cddd07a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c99085825ae5491284c31c6eb802dcc6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cdd0e51d1cab41e3a3d0098d389e29a6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7a596403c3904b3cb84c0f3e13baaff9",
       "placeholder": "​",
       "style": "IPY_MODEL_e1f1c546a54d4dad8b9de92fff4c98b1",
       "value": " 580/580 [00:00&lt;00:00, 23.7kB/s]"
      }
     },
     "d34e668dd7ae40818298583fb496ebbb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d4cc113fca3b4048b07904323c71599a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "db0f2422d671498fa1034527f2c1b8e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e1f1c546a54d4dad8b9de92fff4c98b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f16ac5f5c2e64fa68347014863ed7e37": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "feae02561c134ab78804d36b0641204d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
